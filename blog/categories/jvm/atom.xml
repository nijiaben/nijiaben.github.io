<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: JVM | 你假笨]]></title>
  <link href="http://nijiaben.github.io/blog/categories/jvm/atom.xml" rel="self"/>
  <link href="http://nijiaben.github.io/"/>
  <updated>2016-03-27T12:03:29+08:00</updated>
  <id>http://nijiaben.github.io/</id>
  <author>
    <name><![CDATA[你假笨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之Object.wait/notify(All)完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2016/03/27/object-wait-notify/"/>
    <updated>2016-03-27T11:31:25+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/03/27/object-wait-notify</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>本文其实一直都想写，因为各种原因一直拖着没写，直到开公众号的第一天，有朋友再次问到这个问题，这次让我静心下来准备写下这篇文章，本文有些东西是我自己的理解，比如为什么JDK一开始要这么设计，初衷是什么，没怎么去找相关资料，所以只能谈谈自己的理解，所以大家看到文章之后可以谈谈自己的看法，对于实现部分我倒觉得说清楚问题不大，code is here，看明白了就知道怎么回事了。</p>

<!--more-->


<p>Object.wait/notify(All)大家都知道主要是协同线程处理的，大家用得也很多，大概逻辑和下面的用法差不多</p>

<p>```</p>

<pre><code>    new Thread(){
        public void run(){
            synchronized (lock){
                try{
                    lock.wait();
                }catch (InterruptedException e){
                    e.printStackTrace();
                }
            }
        }
    }.start();

    new Thread(){
        public void run(){
            synchronized (lock){
                lock.notify();
            }
        }
    }.start();
</code></pre>

<p>```</p>

<p>看到上面代码，你会有什么疑惑吗？至少我会有几个问题会问自己：</p>

<ul>
<li>为什么进入wait和notify的时候要加synchronized锁</li>
<li>既然加了synchronized锁，那当某个线程调用了wait的时候明明还在synchronized块里，其他线程怎么进入到锁里去执行notify的</li>
<li>为什么wait方法可能会抛出InterruptedException异常</li>
<li>如果有多个线程都进入wait状态，那某个线程调用notify唤醒线程时是否按照顺序唤起那些wait线程</li>
<li>wait的线程是在某个线程执行完notify之后立马就被唤起吗</li>
<li>notifyAll又是怎么实现全唤起的</li>
<li>wait的线程是否会影响load</li>
</ul>


<p>如果上面这些问题也都是你想了解的，那这篇文章或许能给你一个答案。</p>

<h2>为何要加synchronized锁</h2>

<p>从实现上来说，这个锁至关重要，正因为这把锁，才能让整个wait/notify玩转起来，当然我觉得其实通过其他的方式也可以实现类似的机制，不过hotspot至少是完全依赖这把锁来实现wait/notify的。</p>

<p>如果要我们来实现这种机制我们会怎么去做，我们知道wait/notify是为了线程间协作而设计的，当我们执行wait的时候让线程挂起，当执行notify的时候唤醒其中一个挂起的线程，那需要有个地方来保存对象和线程之间的映射关系(可以想象一个map，key是对象，value是一个线程列表)，当调用这个对象的wait方法时，将当前线程放到这个线程列表里，当调用这个对象的notify方法时从这个线程列表里取出一个来让其继续执行，这样看来是可行的，也比较简单，那现在的问题这种映射关系放到哪里。而synchronized正好也是为线程间协作而设计的，上面碰到的问题它也要解决，或许正因为这样wait和notify的实现就直接依赖synchronzied(monitorenter/monitorexit是jvm规范里要求要去实现的)来实现了，这只是我的理解，可能初衷不是这个原因，这其实也是这篇文章迟迟未写的一个原因吧，因为我无法取证自己的理解是对的，欢迎各位在这块谈谈自己的见解。</p>

<h2>wait方法执行后未退出同步块，其他线程如何进入同步块</h2>

<p>这个问题其实要回答很简单，因为在wait处理过程中会临时释放同步锁，不过需要注意的是当某个线程调用notify唤起了这个线程的时候，在wait方法退出之前会重新获取这把锁，只有获取了这把锁才会继续执行，想象一下，我们知道wait的方法是被monitorenter和monitorexit包围起来，当我们在执行wait方法过程中如果释放了锁，出来的时候又不拿锁，那在执行到monitorexit指令的时候会发生什么？当然这可以做兼容，不过这实现起来还是很奇怪的。</p>

<h2>为什么wait方法可能抛出InterruptedException异常</h2>

<p>这个异常大家应该都知道，当我们调用了某个线程的interrupt方法时，对应的线程会抛出这个异常，wait方法也不希望破坏这种规则，因此就算当前线程因为wait一直在阻塞，当某个线程希望它起来继续执行的时候，它还是得从阻塞态恢复过来，因此wait方法被唤醒起来的时候会去检测这个状态，当有线程interrupt了它的时候，它就会抛出这个异常从阻塞状态恢复过来。</p>

<p>这里有两点要注意：</p>

<ul>
<li>如果被interrupt的线程只是创建了，并没有start，那等他start之后进入wait态之后也是不能会恢复的</li>
<li>如果被interrupt的线程已经start了，在进入wait之前，如果有线程调用了其interrupt方法，那这个wait等于什么都没做，会直接跳出来，不会阻塞</li>
</ul>


<h2>被notify(All)的线程有规律吗</h2>

<p>这里要分情况：</p>

<ul>
<li>如果是通过notify来唤起的线程，那先进入wait的线程会先被唤起来</li>
<li>如果是通过nootifyAll唤起的线程，默认情况是最后进入的会先被唤起来，即LIFO的策略</li>
</ul>


<h2>notify执行之后立马唤醒线程吗</h2>

<p>其实这个大家可以验证一下，在notify之后写一些逻辑，看这些逻辑是在其他线程被唤起之前还是之后执行，这个是个细节问题，可能大家并没有关注到这个，其实hotspot里真正的实现是退出同步块的时候才会去真正唤醒对应的线程，不过这个也是个默认策略，也可以改的，在notify之后立马唤醒相关线程。</p>

<h2>notifyAll是怎么实现全唤起的</h2>

<p>或许大家立马想到这个简单，一个for循环就搞定了，不过在jvm里没实现这么简单，而是借助了monitorexit，上面我提到了当某个线程从wait状态恢复出来的时候，要先获取锁，然后再退出同步块，所以notifyAll的实现是调用notify的线程在退出其同步块的时候唤醒起最后一个进入wait状态的线程，然后这个线程退出同步块的时候继续唤醒其倒数第二个进入wait状态的线程，依次类推，同样这这是一个策略的问题，jvm里提供了挨个直接唤醒线程的参数，不过都很罕见就不提了。</p>

<h2>wait的线程是否会影响load</h2>

<p>这个或许是大家比较关心的话题，因为关乎系统性能问题，wait/nofity是通过jvm里的park/unpark机制来实现的，在linux下这种机制又是通过pthread_cond_wait/pthread_cond_signal来玩的，因此当线程进入到wait状态的时候其实是会放弃cpu的，也就是说这类线程是不会占用cpu资源。</p>

<h1>欢迎各位关注个人微信公众号，主要围绕JVM写一系列的原理性，性能调优的文章</h1>

<p><img src="/images/gzh.jpg" width="200" height="200"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之自定义类加载器如何拉长YGC]]></title>
    <link href="http://nijiaben.github.io/blog/2016/03/15/ygc-classloader/"/>
    <updated>2016-03-15T13:51:58+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/03/15/ygc-classloader</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>本文重点讲述毕玄大师在其公众号上发的一个GC问题<a href="http://hellojava.info/?p=438">一个jstack/jmap等不能用的case</a>（PS：话说毕大师超级喜欢在题目里用case这个词，我觉得题目还是能尽量做到顾名思义好，不然要找起相关文章来真的好难找），对于毕大师那篇文章，题目上没有提到GC的那个问题，不过进入到文章里可以看到，既然文章提到了jstack/jmap的问题，这里也简单回答下jstack/jmap无法使用的问题，其实最常见的场景是使用jstack/jmap的用户和目标进程不是同一个用户，哪怕你执行jstack/jmap的动作是root用户也无济于事，详情可以参考我的这篇文章，<a href="http://lovestblog.cn/blog/2014/06/18/jvm-attach/">JVM Attach机制实现</a>,主要是讲JVM Attach机制的，不过毕大师这里主要提到的是jmap -heap/histo这两个参数带来的问题，如果使用-heap/histo的参数，其实和大家使用-F参数是一样的，底层都是通过serviceability agent来实现的，并不是jvm attach的方式，通过sa连上去之后会挂起进程，在serviceability agent里存在bug可能导致detach的动作不会被执行，从而会让进程一直挂着，可以通过top命令验证进程是否处于T状态，如果是说明进程被挂起了，如果进程被挂起了，可以通过kill -CONT [pid]来恢复。</p>

<!--more-->


<p>再回到那个GC的问题，用的参数如下：</p>

<p><code>
-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xms512m -Xmx512m -Xmn100m -XX:+UseConcMarkSweepGC
</code></p>

<p>demo程序如下：</p>

<p>```
import com.thoughtworks.xstream.XStream;</p>

<p>public class XStreamTest {</p>

<pre><code>public static void main(String[] args) throws Exception {
    while(true){
        XStream xs = new XStream();
        xs.toString();
        xs = null;
    }
}
</code></pre>

<p>}
```</p>

<p>执行效果如下</p>

<p><code>
2016-03-14T22:48:01.502+0800: [GC [ParNew: 327680K-&gt;4258K(368640K), 0.0179071 secs] 327680K-&gt;4258K(1007616K), 0.0179448 secs] [Times: user=0.06 sys=0.01, real=0.01 secs]
2016-03-14T22:48:05.975+0800: [GC [ParNew: 331938K-&gt;10239K(368640K), 0.0336279 secs] 331938K-&gt;10239K(1007616K), 0.0336593 secs] [Times: user=0.13 sys=0.02, real=0.03 secs]
2016-03-14T22:48:12.215+0800: [GC [ParNew: 337919K-&gt;14444K(368640K), 0.0471005 secs] 337919K-&gt;14444K(1007616K), 0.0471257 secs] [Times: user=0.19 sys=0.02, real=0.05 secs]
2016-03-14T22:48:21.768+0800: [GC [ParNew: 342124K-&gt;19088K(368640K), 0.0605017 secs] 342124K-&gt;19088K(1007616K), 0.0605295 secs] [Times: user=0.26 sys=0.03, real=0.06 secs]
2016-03-14T22:48:35.180+0800: [GC [ParNew: 346768K-&gt;20633K(368640K), 0.0993470 secs] 346768K-&gt;25248K(1007616K), 0.0993777 secs] [Times: user=0.34 sys=0.04, real=0.09 secs]
</code></p>

<p>发现gc的时间越来越长，但是gc触发的时机以及回收的效果都差不多，那问题究竟在哪里呢？</p>

<h2>Demo分析</h2>

<p>虽然这个demo代码逻辑很简单，但是其实这是一个特殊的demo，并不简单，如果我们将XStream对象换成Object对象，会发现不存在这个问题，既然如此那有必要进去看看这个XStream的构造函数：</p>

<p>```
 public XStream() {</p>

<pre><code>    this((ReflectionProvider)null, (Mapper)((Mapper)null), (HierarchicalStreamDriver)(new XppDriver()));
}

/** @deprecated */
public XStream(ReflectionProvider reflectionProvider, Mapper mapper, HierarchicalStreamDriver driver) {
    this(reflectionProvider, driver, (ClassLoader)(new CompositeClassLoader()), mapper);
}

/** @deprecated */
public XStream(ReflectionProvider reflectionProvider, HierarchicalStreamDriver driver, ClassLoader classLoader, Mapper mapper) {
    this(reflectionProvider, driver, new ClassLoaderReference(classLoader), mapper, new DefaultConverterLookup());
}

public XStream(ReflectionProvider reflectionProvider, HierarchicalStreamDriver driver, ClassLoaderReference classLoader, Mapper mapper, final DefaultConverterLookup defaultConverterLookup) {
    this(reflectionProvider, driver, (ClassLoaderReference)classLoader, mapper, new ConverterLookup() {
        public Converter lookupConverterForType(Class type) {
            return defaultConverterLookup.lookupConverterForType(type);
        }
    }, new ConverterRegistry() {
        public void registerConverter(Converter converter, int priority) {
            defaultConverterLookup.registerConverter(converter, priority);
        }
    });
}

/** @deprecated */
public XStream(ReflectionProvider reflectionProvider, HierarchicalStreamDriver driver, ClassLoader classLoader, Mapper mapper, ConverterLookup converterLookup, ConverterRegistry converterRegistry) {
    this(reflectionProvider, driver, (ClassLoaderReference)(new ClassLoaderReference(classLoader)), mapper, converterLookup, converterRegistry);
}

public XStream(ReflectionProvider reflectionProvider, HierarchicalStreamDriver driver, ClassLoaderReference classLoaderReference, Mapper mapper, ConverterLookup converterLookup, ConverterRegistry converterRegistry) {
    if(reflectionProvider == null) {
        reflectionProvider = JVM.newReflectionProvider();
    }

    this.reflectionProvider = reflectionProvider;
    this.hierarchicalStreamDriver = driver;
    this.classLoaderReference = classLoaderReference;
    this.converterLookup = converterLookup;
    this.converterRegistry = converterRegistry;
    this.mapper = mapper == null?this.buildMapper():mapper;
    this.setupMappers();
    this.setupSecurity();
    this.setupAliases();
    this.setupDefaultImplementations();
    this.setupConverters();
    this.setupImmutableTypes();
    this.setMode(1003);
}
</code></pre>

<p>```</p>

<p>这个构造函数还是很复杂的，里面会创建很多的对象，上面还有一些方法实现我就不贴了，总之都是在不断构建各种大大小小的对象，一个XStream对象构建出来的时候大概好像有12M的样子。</p>

<p>那到底是哪些对象会导致ygc不断增长呢，于是可能想到逐步替换上面这些逻辑，比如将最后一个构造函数里的那些逻辑都禁掉，然后我们再跑测试看看还会不会让ygc不断恶化，最终我们会发现，如果我们直接使用如下构造函数构造对象时，如果传入的classloader是AppClassLoader，那会发现这个问题不再出现了。</p>

<p>```
 public XStream(ReflectionProvider reflectionProvider, HierarchicalStreamDriver driver, ClassLoader classLoader, Mapper mapper) {</p>

<pre><code>    this(reflectionProvider, driver, new ClassLoaderReference(classLoader), mapper, new DefaultConverterLookup());
</code></pre>

<p> }
```</p>

<p>测试代码如下：</p>

<p>```    <br/>
 public static void main(String[] args) throws Exception {</p>

<pre><code>    int i=0;
    while (true) {
        XStream xs = new XStream(null,null, new ClassLoaderReference(XStreamTest.class.getClassLoader()),null, new DefaultConverterLookup());
        xs.toString();
        xs=null;
    }
</code></pre>

<p>  }
```</p>

<p>gc日志如下：</p>

<p><code>
2016-03-14T23:10:33.537+0800: [GC [ParNew: 327680K-&gt;758K(368640K), 0.0019803 secs] 327680K-&gt;758K(1007616K), 0.0020182 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]
2016-03-14T23:10:35.189+0800: [GC [ParNew: 328438K-&gt;1066K(368640K), 0.0018641 secs] 328438K-&gt;1066K(1007616K), 0.0019055 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]
2016-03-14T23:10:36.465+0800: [GC [ParNew: 328746K-&gt;1156K(368640K), 0.0010304 secs] 328746K-&gt;1156K(1007616K), 0.0010519 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
2016-03-14T23:10:37.767+0800: [GC [ParNew: 328836K-&gt;1065K(368640K), 0.0011329 secs] 328836K-&gt;1065K(1007616K), 0.0011543 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
2016-03-14T23:10:39.035+0800: [GC [ParNew: 328745K-&gt;351K(368640K), 0.0043387 secs] 328745K-&gt;1127K(1007616K), 0.0043700 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]
2016-03-14T23:10:40.324+0800: [GC [ParNew: 328031K-&gt;160K(368640K), 0.0011579 secs] 328807K-&gt;936K(1007616K), 0.0011793 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]
2016-03-14T23:10:41.610+0800: [GC [ParNew: 327840K-&gt;31K(368640K), 0.0007010 secs] 328616K-&gt;826K(1007616K), 0.0007219 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
2016-03-14T23:10:42.919+0800: [GC [ParNew: 327711K-&gt;24K(368640K), 0.0011246 secs] 328506K-&gt;819K(1007616K), 0.0011450 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]
2016-03-14T23:10:44.196+0800: [GC [ParNew: 327704K-&gt;24K(368640K), 0.0006797 secs] 328499K-&gt;819K(1007616K), 0.0007586 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
</code></p>

<p>是不是觉得很神奇，由此可见，这个classloader至关重要。</p>

<h2>不得不说的类加载器</h2>

<p>这里着重要说的两个概念是<code>初始类加载器</code>和<code>定义类加载器</code>。举个栗子说吧，AClassLoader->BClassLoader->CClassLoader，表示AClassLoader在加载类的时候会委托BClassLoader类加载器来加载，BClassLoader加载类的时候会委托CClassLoader来加载，假如我们使用AClassLoader来加载X这个类，而X这个类最终是被CClassLoader来加载的，那么我们称CClassLoader为X类的定义类加载器，而AClassLoader为X类的初始类加载器，JVM在加载某个类的时候对AClassLoader和CClassLoader进行记录，记录的数据结构是一个叫做SystemDictionary的hashtable，其key是根据ClassLoader对象和类名算出来的hash值（其实是一个entry，可以根据这个hash值找到具体的index位置，然后构建一个包含kalssName和classloader对象的entry放到map里），而value是真正的由定义类加载器加载的Klass对象，因为初始类加载器和定义类加载器是不同的classloader，因此算出来的hash值也是不同的，因此在SystemDictionary里会有多项值的value都是指向同一个Klass对象。</p>

<p>那么JVM为什么要分这两种类加载器呢，其实主要是为了快速找到已经加载的类，比如我们已经通过AClassLoader来触发了对X类的加载，当我们再次使用AClassLoader这个类加载器来加载X这个类的时候就不需要再委托给BClassLoader去找了，因为加载过的类在JVM里有这个类加载器的直接加载的记录，只需要直接返回对应的Klass对象即可。</p>

<h2>Demo中的类加载器是否会加载类</h2>

<p>我们的demo里发现构建了一个CompositeClassLoader的类加载器，那到底有没有用这个类加载器加载类呢，我们可以设置一个断点在CompositeClassLoader的loadClass方法上，于是看到下面的堆栈：</p>

<p>```
main@1, prio=5, in group 'main', status: 'RUNNING'</p>

<pre><code>  at com.thoughtworks.xstream.core.util.CompositeClassLoader.loadClass(CompositeClassLoader.java:53)
  at java.lang.Class.forName0(Class.java:-1)
  at java.lang.Class.forName(Class.java:249)
  at com.thoughtworks.xstream.XStream.buildMapperDynamically(XStream.java:191)
  at com.thoughtworks.xstream.XStream.buildMapper(XStream.java:170)
  at com.thoughtworks.xstream.XStream.&lt;init&gt;(XStream.java:142)
  at com.thoughtworks.xstream.XStream.&lt;init&gt;(XStream.java:116)
  at com.BBBB.main(BBBB.java:15)
</code></pre>

<p>```</p>

<p>可见确实有类加载的动作，根据类加载委托机制，在这个demo中我们能肯定类是交给AppClassLoader来加载的，这样一来CompositeClassLoader就变成了初始类加载器，而AppClassLoader会是定义类加载器，都会在SystemDictionary里存在，因此当我们不断new XStream的时候会不断new CompositeClassLoader对象，加载类的时候会不断往SystemDictionary里插入记录，从而使SystemDictionary越来越膨胀，那自然而然会想到如果GC过程不断去扫描这个SystemDictionary的话，那随着SystemDictionary不断膨胀，那么GC的效率也就越低，抱着验证下猜想的方式我们可以使用perf工具来看看，如果发现cpu占比排前的函数如果都是操作SystemDictionary的，那就基本验证了我们的说法，下面是perf工具的截图，基本证实了这一点。</p>

<p><img src="/images/2016/03/ygc_classloader_perf.png"></p>

<h2>SystemDictionary为什么会影响GC过程</h2>

<p>想象一下这么个情况，我们加载了一个类，然后构建了一个对象(这个对象在eden里构建)当一个属性设置到这个类里，如果gc发生的时候，这个对象是不是要被找出来标活才行，那么自然而然我们加载的类肯定是我们一项重要的gc root，这样SystemDictionary就成为了gc过程中的被扫描对象了，事实也是如此，可以看vm的具体代码：</p>

<p>```
void SharedHeap::process_strong_roots(bool activate_scope,</p>

<pre><code>                                  bool collecting_perm_gen,
                                  ScanningOption so,
                                  OopClosure* roots,
                                  CodeBlobClosure* code_roots,
                                  OopsInGenClosure* perm_blk) {
</code></pre>

<p>  StrongRootsScope srs(this, activate_scope);
  // General strong roots.
  assert(<em>strong_roots_parity != 0, "must have called prologue code");
  // </em>n_termination for <em>process_strong_tasks should be set up stream
  // in a method not running in a GC worker.  Otherwise the GC worker
  // could be trying to change the termination condition while the task
  // is executing in another GC worker.
  if (!</em>process_strong_tasks->is_task_claimed(SH_PS_Universe_oops_do)) {</p>

<pre><code>Universe::oops_do(roots);
// Consider perm-gen discovered lists to be strong.
//将perm gen的非强引用标记为root的一部分
perm_gen()-&gt;ref_processor()-&gt;weak_oops_do(roots);
</code></pre>

<p>  }
  // Global (strong) JNI handles
  if (!_process_strong_tasks->is_task_claimed(SH_PS_JNIHandles_oops_do))</p>

<pre><code>JNIHandles::oops_do(roots);
</code></pre>

<p>  // All threads execute this; the individual threads are task groups.
  if (ParallelGCThreads > 0) {</p>

<pre><code>Threads::possibly_parallel_oops_do(roots, code_roots);
</code></pre>

<p>  } else {</p>

<pre><code>Threads::oops_do(roots, code_roots);
</code></pre>

<p>  }
  if (!_process_strong_tasks-> is_task_claimed(SH_PS_ObjectSynchronizer_oops_do))</p>

<pre><code>ObjectSynchronizer::oops_do(roots);
</code></pre>

<p>  if (!_process_strong_tasks->is_task_claimed(SH_PS_FlatProfiler_oops_do))</p>

<pre><code>FlatProfiler::oops_do(roots);
</code></pre>

<p>  if (!_process_strong_tasks->is_task_claimed(SH_PS_Management_oops_do))</p>

<pre><code>Management::oops_do(roots);
</code></pre>

<p>  if (!_process_strong_tasks->is_task_claimed(SH_PS_jvmti_oops_do))</p>

<pre><code>JvmtiExport::oops_do(roots);
</code></pre>

<p>  if (!_process_strong_tasks->is_task_claimed(SH_PS_SystemDictionary_oops_do)) {</p>

<pre><code>if (so &amp; SO_AllClasses) {
  SystemDictionary::oops_do(roots);
} else if (so &amp; SO_SystemClasses) {
  SystemDictionary::always_strong_oops_do(roots);
}
</code></pre>

<p>  }</p>

<p>  if (!_process_strong_tasks->is_task_claimed(SH_PS_StringTable_oops_do)) {</p>

<pre><code>//JavaObjectsInPerm为false，那么String intern的对象已经class对象都是存在heap里的，否则都存在perm里  
if (so &amp; SO_Strings || (!collecting_perm_gen &amp;&amp; !JavaObjectsInPerm)) {
  //虽然不回收perm，但是interned的String对象不在perm里，那么还是需要遍历下StringTable里的String对象，因为这些对象在heap里
  StringTable::oops_do(roots);
}
if (JavaObjectsInPerm) {
  // Verify the string table contents are in the perm gen
  NOT_PRODUCT(StringTable::oops_do(&amp;assert_is_perm_closure));
}
</code></pre>

<p>  }</p>

<p>  if (!_process_strong_tasks->is_task_claimed(SH_PS_CodeCache_oops_do)) {</p>

<pre><code>if (so &amp; SO_CodeCache) {
  // (Currently, CMSCollector uses this to do intermediate-strength collections.)
  assert(collecting_perm_gen, "scanning all of code cache");
  assert(code_roots != NULL, "must supply closure for code cache");
  if (code_roots != NULL) {
    CodeCache::blobs_do(code_roots);
  }
} else if (so &amp; (SO_SystemClasses|SO_AllClasses)) {
  if (!collecting_perm_gen) {
    // If we are collecting from class statics, but we are not going to
    // visit all of the CodeCache, collect from the non-perm roots if any.
    // This makes the code cache function temporarily as a source of strong
    // roots for oops, until the next major collection.
    //
    // If collecting_perm_gen is true, we require that this phase will call
    // CodeCache::do_unloading.  This will kill off nmethods with expired
    // weak references, such as stale invokedynamic targets.
    CodeCache::scavenge_root_nmethods_do(code_roots);
  }
}
// Verify that the code cache contents are not subject to
// movement by a scavenging collection.
DEBUG_ONLY(CodeBlobToOopClosure assert_code_is_non_scavengable(&amp;assert_is_non_scavengable_closure, /*do_marking=*/ false));
DEBUG_ONLY(CodeCache::asserted_non_scavengable_nmethods_do(&amp;assert_code_is_non_scavengable));
</code></pre>

<p>  }</p>

<p>  if (!collecting_perm_gen) {</p>

<pre><code>//如果是不回收perm，那找出所有perm指向new的对象  
// All threads perform this; coordination is handled internally.
rem_set()-&gt;younger_refs_iterate(perm_gen(), perm_blk);//perm的level是-1
</code></pre>

<p>  }
  _process_strong_tasks->all_tasks_completed();
}</p>

<p>```</p>

<p>看上面的<code>SH_PS_SystemDictionary_oops_do</code> task就知道了，这个就是对SystemDictionary进行扫描。</p>

<p>但是这里要说的是虽然有对SystemDictionary进行扫描，但是ygc的过程并不会对SystemDictionary进行处理，如果要对它进行处理需要开启类卸载的vm参数，CMS算法下，CMS GC和Full GC在开启CMSClassUnloadingEnabled的情况下是可能对类做卸载动作的，此时会对SystemDictionary进行清理，所以当我们在跑上面demo的时候，通过<code>jmap -dump:live,format=b,file=heap.bin &lt;pid&gt;</code>命令执行完之后，ygc的时间瞬间降下来了，不过又会慢慢回去，这是因为jmap的这个命令会做一次gc，这个gc过程会对SystemDictionary进行清理。</p>

<h2>修改VM代码验证</h2>

<p>很遗憾hotspot目前没有对ygc的每个task做一个时间的统计，因此无法直接知道是不是<code>SH_PS_SystemDictionary_oops_do</code>这个task导致了ygc的时间变长，为了证明这个结论，我特地修改了一下代码，在上面的代码上加了一行：</p>

<p>```
if (!_process_strong_tasks->is_task_claimed(SH_PS_SystemDictionary_oops_do)) {</p>

<pre><code>GCTraceTime t("SystemDictionary_OOPS_DO",PrintGCDetails,true,NULL);
if (so &amp; SO_AllClasses) {
  SystemDictionary::oops_do(roots);
} else if (so &amp; SO_SystemClasses) {
  SystemDictionary::always_strong_oops_do(roots);
}
</code></pre>

<p>  }
```</p>

<p>然后重新编译，跑我们的demo，测试结果如下：</p>

<p><code>
2016-03-14T23:57:24.293+0800: [GC2016-03-14T23:57:24.294+0800: [ParNew2016-03-14T23:57:24.296+0800: [SystemDictionary_OOPS_DO, 0.0578430 secs]
: 81920K-&gt;3184K(92160K), 0.0889740 secs] 81920K-&gt;3184K(514048K), 0.0900970 secs] [Times: user=0.27 sys=0.00, real=0.09 secs]
2016-03-14T23:57:28.467+0800: [GC2016-03-14T23:57:28.468+0800: [ParNew2016-03-14T23:57:28.468+0800: [SystemDictionary_OOPS_DO, 0.0779210 secs]
: 85104K-&gt;5175K(92160K), 0.1071520 secs] 85104K-&gt;5175K(514048K), 0.1080490 secs] [Times: user=0.65 sys=0.00, real=0.11 secs]
2016-03-14T23:57:32.984+0800: [GC2016-03-14T23:57:32.984+0800: [ParNew2016-03-14T23:57:32.984+0800: [SystemDictionary_OOPS_DO, 0.1075680 secs]
: 87095K-&gt;8188K(92160K), 0.1434270 secs] 87095K-&gt;8188K(514048K), 0.1439870 secs] [Times: user=0.90 sys=0.01, real=0.14 secs]
2016-03-14T23:57:37.900+0800: [GC2016-03-14T23:57:37.900+0800: [ParNew2016-03-14T23:57:37.901+0800: [SystemDictionary_OOPS_DO, 0.1745390 secs]
: 90108K-&gt;7093K(92160K), 0.2876260 secs] 90108K-&gt;9992K(514048K), 0.2884150 secs] [Times: user=1.44 sys=0.02, real=0.29 secs]
</code>
我们会发现YGC的时间变长的时候，SystemDictionary_OOPS_DO的时间也会相应变长多少，因此验证了我们的说法。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[消失的死锁]]></title>
    <link href="http://nijiaben.github.io/blog/2015/10/21/deadlock/"/>
    <updated>2015-10-21T18:54:01+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/10/21/deadlock</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>如果java层面发生了死锁，当我们使用<code>jstack</code>命令的时候其实是可以将死锁的信息给dump出来的，在dump结果的最后会有类似<code>Found one Java-level deadlock:</code>的关键字，接着会把发生死锁的线程的堆栈及对应的同步锁给打印出来，这次碰到一个系统就发生类似的问题，不过这个dump文档里虽然提到了如下的死锁信息：</p>

<!--more-->


<p>```</p>

<h1>Found one Java-level deadlock:</h1>

<p>"worker-1-thread-121":
  waiting to lock monitor 0x00007f3758209dc8 (object 0x0000000764cd2b20, a java.util.concurrent.ConcurrentHashMap),
  which is held by "HSFBizProcessor-4-thread-4"
"HSFBizProcessor-4-thread-4":
  waiting to lock monitor 0x00007f3758289260 (object 0x000000076073ddc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-5"
"HSFBizProcessor-4-thread-5":
  waiting to lock monitor 0x00007f3758253420 (object 0x00000007608e6fc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-4"
```</p>

<p>但是我们在堆栈里搜索对应的锁的时候并没发现，也就是上面提到的</p>

<p><code>
object 0x00000007608e6fc8 which is held by "HSFBizProcessor-4-thread-4"
</code></p>

<p>我们在<code>HSFBizProcessor-4-thread-4</code>这个线程的堆栈里并没有看到对应的持锁信息。</p>

<p>附上线程dump详情</p>

<p>```</p>

<h1>Found one Java-level deadlock:</h1>

<p>"worker-1-thread-121":
  waiting to lock monitor 0x00007f3758209dc8 (object 0x0000000764cd2b20, a java.util.concurrent.ConcurrentHashMap),
  which is held by "HSFBizProcessor-4-thread-4"
"HSFBizProcessor-4-thread-4":
  waiting to lock monitor 0x00007f3758289260 (object 0x000000076073ddc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-5"
"HSFBizProcessor-4-thread-5":
  waiting to lock monitor 0x00007f3758253420 (object 0x00000007608e6fc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-4"</p>

<h1>Java stack information for the threads listed above:</h1>

<p>"worker-1-thread-121":</p>

<pre><code>at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:180)
- waiting to lock &lt;0x0000000764cd2b20&gt; (a java.util.concurrent.ConcurrentHashMap)
at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:455)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:317)
......
at java.util.concurrent.FutureTask.run(FutureTask.java:138)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)
</code></pre>

<p>"HSFBizProcessor-4-thread-4":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x000000076073ddc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at org.springframework.scripting.groovy.GroovyScriptFactory.executeScript(GroovyScriptFactory.java:238)
......
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)
</code></pre>

<p>"HSFBizProcessor-4-thread-5":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x00000007608e6fc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.DependentPolicy.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.PolicyHandler.doBuddyClassLoading(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:169)
at groovy.lang.MetaClassRegistry$MetaClassCreationHandle.createWithCustomLookup(MetaClassRegistry.java:127)
at groovy.lang.MetaClassRegistry$MetaClassCreationHandle.create(MetaClassRegistry.java:122)
......
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)
</code></pre>

<p>Found 1 deadlock.
```</p>

<h2>类加载的问题？</h2>

<p>首先应该怀疑类加载的问题，因为我们看到导致死锁的对象是一个classloader对象：</p>

<p><code>
waiting to lock monitor 0x00007f3758289260 (object 0x000000076073ddc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
</code></p>

<p>然后我们再来分析下堆栈</p>

<h3>HSFBizProcessor-4-thread-4</h3>

<p>```
"HSFBizProcessor-4-thread-4":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x000000076073ddc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at org.springframework.scripting.groovy.GroovyScriptFactory.executeScript(GroovyScriptFactory.java:238)
at org.springframework.scripting.groovy.GroovyScriptFactory.getScriptedObject(GroovyScriptFactory.java:185)
</code></pre>

<p>```</p>

<p>我这里只把关键的线程栈贴出来，从栈顶知道正在等一把锁：</p>

<p>```</p>

<pre><code>- waiting to lock &lt;0x000000076073ddc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
</code></pre>

<p>```</p>

<p>这把锁的对象是一个ClassLoader对象，我们找到对应的代码，确实存在synchronized的操作：</p>

<p>```
private Class&lt;?> findLoadedClass(String classname) {</p>

<pre><code>if ((LOCK_CLASSNAME) || (this.isParallelClassLoader)) {
  boolean initialLock = lockClassName(classname);
  try {
    return this.classloader.publicFindLoaded(classname);
  } finally {
    if (initialLock)
      unlockClassName(classname);
  }
}
synchronized (this.classloader) {
  return this.classloader.publicFindLoaded(classname);
}
</code></pre>

<p>  }</p>

<p>```</p>

<p>另外我们还知道它正在执行loadClass的动作，并且是从groovy调用来的，同样找到对应的代码：</p>

<p>```
protected Object executeScript(ScriptSource scriptSource, Class scriptClass)</p>

<pre><code>throws ScriptCompilationException
</code></pre>

<p>  {</p>

<pre><code>try
{
  GroovyObject goo = (GroovyObject)scriptClass.newInstance();//line 238

  if (this.groovyObjectCustomizer != null)
  {
    this.groovyObjectCustomizer.customize(goo);
  }

  if ((goo instanceof Script))
  {
    return ((Script)goo).run();
  }

  return goo;
}
catch (InstantiationException ex)
{
  throw new ScriptCompilationException(
    scriptSource, "Could not instantiate Groovy script class: " + scriptClass.getName(), ex);
}
catch (IllegalAccessException ex) {
  throw new ScriptCompilationException(
    scriptSource, "Could not access Groovy script constructor: " + scriptClass.getName(), ex);
}
</code></pre>

<p>  }
```</p>

<p>执行到第238行的时候</p>

<p><code>
GroovyObject goo = (GroovyObject)scriptClass.newInstance();//line 238
</code></p>

<p>突然发现调用了</p>

<p><code>
java.lang.ClassLoader.loadClass(ClassLoader.java:247)
</code></p>

<p>而我们看到上面第238行的逻辑其实就是实例化一个对象，然后进行强转，我们看看对应的字节码：</p>

<p><code>
 0: aload_2
 1: invokevirtual #164                // Method java/lang/Class.newInstance:()Ljava/lang/Object;
 4: checkcast     #168                // class groovy/lang/GroovyObject
 7: astore_3
</code></p>

<p>其实就对应这么几条字节码指令，其实在jvm里当我们执行checkcast指令的时候会触发类加载的动作：</p>

<p>```
void TemplateTable::checkcast() {</p>

<pre><code>...
call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::quicken_io_cc));
...
</code></pre>

<p>}</p>

<p>IRT_ENTRY(void, InterpreterRuntime::quicken_io_cc(JavaThread* thread))
  // Force resolving; quicken the bytecode
  int which = get_index_u2(thread, Bytecodes::_checkcast);
  constantPoolOop cpool = method(thread)->constants();
  // We'd expect to assert that we're only here to quicken bytecodes, but in a multithreaded
  // program we might have seen an unquick'd bytecode in the interpreter but have another
  // thread quicken the bytecode before we get here.
  // assert( cpool->tag_at(which).is_unresolved_klass(), "should only come here to quicken bytecodes" );
  klassOop klass = cpool->klass_at(which, CHECK);
  thread->set_vm_result(klass);
IRT_END</p>

<p>klassOop klass_at(int which, TRAPS) {</p>

<pre><code>constantPoolHandle h_this(THREAD, this);
return klass_at_impl(h_this, which, CHECK_NULL);
</code></pre>

<p>}</p>

<p>klassOop constantPoolOopDesc::klass_at_impl(constantPoolHandle this_oop, int which, TRAPS) {</p>

<pre><code>...
klassOop k_oop = SystemDictionary::resolve_or_fail(name, loader, h_prot, true, THREAD);
...
</code></pre>

<p>}</p>

<p>//SystemDictionary::resolve_or_fail最终会调用到下面这个方法
klassOop SystemDictionary::resolve_instance_class_or_null(Symbol* name, Handle class_loader, Handle protection_domain, TRAPS) {
  ...
  // Class is not in SystemDictionary so we have to do loading.
  // Make sure we are synchronized on the class loader before we proceed
  Handle lockObject = compute_loader_lock_object(class_loader, THREAD);
  check_loader_lock_contention(lockObject, THREAD);
  ObjectLocker ol(lockObject, THREAD, DoObjectLock);
  ...
  //此时会调用ClassLoader.loadClass来加载类了
  ...
}</p>

<p>Handle SystemDictionary::compute_loader_lock_object(Handle class_loader, TRAPS) {
  // If class_loader is NULL we synchronize on _system_loader_lock_obj
  if (class_loader.is_null()) {</p>

<pre><code>return Handle(THREAD, _system_loader_lock_obj);
</code></pre>

<p>  } else {</p>

<pre><code>return class_loader;
</code></pre>

<p>  }
}
```</p>

<p><code>SystemDictionary::resolve_instance_class_or_null</code>这个方法非常关键了，在里面我们看到会获取一把锁ObjectLocker，其相当于我们java代码里的<code>synchronized</code>关键字，而对象对应的是lockObject，这个对象是上面的<code>SystemDictionary::compute_loader_lock_object</code>方法返回的，从代码可知只要不是bootstrapClassloader加载的类就会返回当前classloader对象，也就是说当我们在加载一个类的时候其实是会持有当前类加载对象的锁的，在获取了这把锁之后就会调用ClassLoader.loadClass来加载类了。这其实就解释了<code>HSFBizProcessor-4-thread-4</code>这个线程为什么持有了
<code>
object 0x00000007608e6fc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader
</code>
这个类加载的锁，不过遗憾的是因为这把锁不是java层面来显示加载的，因此我们在<code>jstack</code>线程dump的输出里居然看不到这把锁的存在.</p>

<h3>HSFBizProcessor-4-thread-5</h3>

<p>先上堆栈：</p>

<p>```
"HSFBizProcessor-4-thread-5":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x00000007608e6fc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.DependentPolicy.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.PolicyHandler.doBuddyClassLoading(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:169)
</code></pre>

<p>```</p>

<p>这个线程栈其实和之前那个线程差不多，只是等的锁不一样，另外触发类加载的动作是<code>Class.forName</code>，获取大家也猜到了，其实是在下面两行堆栈之间同样获取了一把类加载器的锁</p>

<p>```</p>

<pre><code>at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at java.lang.Class.forName0(Native Method)
</code></pre>

<p>```</p>

<p>这里的代码我也不细贴了，最终调用的jvm里的方法都是一样的，获取锁的逻辑也是一样的</p>

<h2>总结</h2>

<p>想象下这种场景，两个线程分别使用不同的classloader对两个类进行类加载，然而由于osgi类加载机制的缘故，在loadClass过程中可能会委托给别的classloader去加载，而正巧，这两个线程在获取当前classloader的锁之后，然后分别委托对方的classloader去加载，可以看到文章开头列的那个findLoadedClass方法，而synchronized的那个classloader正好是对方的classloader，从而导致了死锁</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之javaagent原理完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/09/14/javaagent/"/>
    <updated>2015-09-14T13:17:50+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/09/14/javaagent</id>
    <content type="html"><![CDATA[<p><code>注:文章首发于InfoQ：</code><a href="http://www.infoq.com/cn/articles/javaagent-illustrated">JVM源码分析之javaagent原理完全解读</a></p>

<h2>概述</h2>

<p>本文重点讲述javaagent的具体实现，因为它面向的是我们java程序员，而且agent都是用java编写的，不需要太多的c/c++编程基础，不过这篇文章里也会讲到JVMTIAgent(c实现的)，因为javaagent的运行还是依赖于一个特殊的JVMTIAgent。</p>

<!-- more -->


<p>对于javaagent或许大家都听过，甚至使用过，常见的用法大致如下：</p>

<p><code>
java -javaagent:myagent.jar=mode=test Test
</code></p>

<p>我们通过-javaagent来指定我们编写的agent的jar路径（./myagent.jar）及要传给agent的参数（mode=test），这样在启动的时候这个agent就可以做一些我们想要它做的事了。</p>

<p>javaagent的主要的功能如下：</p>

<ul>
<li>可以在加载class文件之前做拦截把字节码做修改</li>
<li>可以在运行期将已经加载的类的字节码做变更，但是这种情况下会有很多的限制，后面会详细说</li>
<li>还有其他的一些小众的功能

<ul>
<li>获取所有已经被加载过的类</li>
<li>获取所有已经被初始化过了的类（执行过了clinit方法，是上面的一个子集）</li>
<li>获取某个对象的大小</li>
<li>将某个jar加入到bootstrapclasspath里作为高优先级被bootstrapClassloader加载</li>
<li>将某个jar加入到classpath里供AppClassloard去加载</li>
<li>设置某些native方法的前缀，主要在查找native方法的时候做规则匹配</li>
</ul>
</li>
</ul>


<p>想象一下可以让程序按照我们预期的逻辑去执行，听起来是不是挺酷的。</p>

<h2>JVMTI</h2>

<p><a href="http://docs.oracle.com/javase/7/docs/platform/jvmti/jvmti.html">JVMTI</a>全称JVM Tool Interface，是jvm暴露出来的一些供用户扩展的接口集合，JVMTI是基于事件驱动的，JVM每执行到一定的逻辑就会调用一些事件的回调接口（如果有的话），这些接口可以供开发者去扩展自己的逻辑。</p>

<p>比如说我们最常见的想在某个类的字节码文件读取之后类定义之前能修改相关的字节码，从而使创建的class对象是我们修改之后的字节码内容，那我们就可以实现一个回调函数赋给JvmtiEnv（JVMTI的运行时，通常一个JVMTIAgent对应一个jvmtiEnv，但是也可以对应多个）的回调方法集合里的ClassFileLoadHook，这样在接下来的类文件加载过程中都会调用到这个函数里来了，大致实现如下:</p>

<p>```</p>

<pre><code>jvmtiEventCallbacks callbacks;
jvmtiEnv *          jvmtienv = jvmti(agent);
jvmtiError          jvmtierror;
memset(&amp;callbacks, 0, sizeof(callbacks));
callbacks.ClassFileLoadHook = &amp;eventHandlerClassFileLoadHook;
jvmtierror = (*jvmtienv)-&gt;SetEventCallbacks( jvmtienv,
                                             &amp;callbacks,
                                             sizeof(callbacks));
</code></pre>

<p>```</p>

<h2>JVMTIAgent</h2>

<p>JVMTIAgent其实就是一个动态库，利用JVMTI暴露出来的一些接口来干一些我们想做但是正常情况下又做不到的事情，不过为了和普通的动态库进行区分，它一般会实现如下的一个或者多个函数：</p>

<p>```
JNIEXPORT jint JNICALL
Agent_OnLoad(JavaVM <em>vm, char </em>options, void *reserved);</p>

<p>JNIEXPORT jint JNICALL
Agent_OnAttach(JavaVM<em> vm, char</em> options, void* reserved);</p>

<p>JNIEXPORT void JNICALL
Agent_OnUnload(JavaVM *vm);</p>

<p>```</p>

<ul>
<li><code>Agent_OnLoad</code>函数，如果agent是在启动的时候加载的，也就是在vm参数里通过-agentlib来指定，那在启动过程中就会去执行这个agent里的<code>Agent_OnLoad</code>函数。</li>
<li><code>Agent_OnAttach</code>函数，如果agent不是在启动的时候加载的，是我们先attach到目标进程上，然后给对应的目标进程发送load命令来加载agent，在加载过程中就会调用<code>Agent_OnAttach</code>函数。</li>
<li><code>Agent_OnUnload</code>函数，在agent做卸载的时候调用，不过貌似基本上很少实现它。</li>
</ul>


<p>其实我们每天都在和JVMTIAgent打交道，只是你可能没有意识到而已，比如我们经常使用eclipse等工具对java代码做调试，其实就利用了jre自带的jdwp agent来实现的，只是由于eclipse等工具在没让你察觉的情况下将相关参数(类似<code>-agentlib:jdwp=transport=dt_socket,suspend=y,address=localhost:61349</code>)给自动加到程序启动参数列表里了，其中agentlib参数就是用来跟要加载的agent的名字，比如这里的jdwp(不过这不是动态库的名字，而JVM是会做一些名称上的扩展，比如在linux下会去找<code>libjdwp.so</code>的动态库进行加载，也就是在名字的基础上加前缀<code>lib</code>,再加后缀<code>.so</code>)，接下来会跟一堆相关的参数，会将这些参数传给<code>Agent_OnLoad</code>或者<code>Agent_OnAttach</code>函数里对应的<code>options</code>参数。</p>

<h2>javaagent</h2>

<p>说到javaagent必须要讲的是一个叫做instrument的JVMTIAgent（linux下对应的动态库是libinstrument.so），因为就是它来实现javaagent的功能的，另外instrument agent还有个别名叫JPLISAgent(Java Programming Language Instrumentation Services Agent)，从这名字里也完全体现了其最本质的功能：就是专门为java语言编写的插桩服务提供支持的。</p>

<h3>instrument agent</h3>

<p>instrument agent实现了<code>Agent_OnLoad</code>和<code>Agent_OnAttach</code>两方法，也就是说我们在用它的时候既支持启动的时候来加载agent，也支持在运行期来动态来加载这个agent，其中启动时加载agent还可以通过类似<code>-javaagent:myagent.jar</code>的方式来间接加载instrument agent，运行期动态加载agent依赖的是jvm的attach机制<a href="http://lovestblog.cn/blog/2014/06/18/jvm-attach/">JVM Attach机制实现</a>，通过发送load命令来加载agent。</p>

<p>instrument agent的核心数据结构如下：
```
struct _JPLISAgent {</p>

<pre><code>JavaVM *                mJVM;                   /* handle to the JVM */
JPLISEnvironment        mNormalEnvironment;     /* for every thing but retransform stuff */
JPLISEnvironment        mRetransformEnvironment;/* for retransform stuff only */
jobject                 mInstrumentationImpl;   /* handle to the Instrumentation instance */
jmethodID               mPremainCaller;         /* method on the InstrumentationImpl that does the premain stuff (cached to save lots of lookups) */
jmethodID               mAgentmainCaller;       /* method on the InstrumentationImpl for agents loaded via attach mechanism */
jmethodID               mTransform;             /* method on the InstrumentationImpl that does the class file transform */
jboolean                mRedefineAvailable;     /* cached answer to "does this agent support redefine" */
jboolean                mRedefineAdded;         /* indicates if can_redefine_classes capability has been added */
jboolean                mNativeMethodPrefixAvailable; /* cached answer to "does this agent support prefixing" */
jboolean                mNativeMethodPrefixAdded;     /* indicates if can_set_native_method_prefix capability has been added */
char const *            mAgentClassName;        /* agent class name */
char const *            mOptionsString;         /* -javaagent options string */
</code></pre>

<p>};</p>

<p>struct _JPLISEnvironment {</p>

<pre><code>jvmtiEnv *              mJVMTIEnv;              /* the JVM TI environment */
JPLISAgent *            mAgent;                 /* corresponding agent */
jboolean                mIsRetransformer;       /* indicates if special environment */
</code></pre>

<p>};</p>

<p>```</p>

<p>这里解释下几个重要项：
* mNormalEnvironment：主要提供正常的类transform及redefine功能的。
* mRetransformEnvironment：主要提供类retransform功能的。
* mInstrumentationImpl：这个对象非常重要，也是我们java agent和JVM进行交互的入口，或许写过javaagent的人在写<code>premain</code>以及<code>agentmain</code>方法的时候注意到了有个Instrumentation的参数，这个参数其实就是这里的对象。
* mPremainCaller：指向<code>sun.instrument.InstrumentationImpl.loadClassAndCallPremain</code>方法，如果agent是在启动的时候加载的，那该方法会被调用。
* mAgentmainCaller：指向<code>sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain</code>方法，该方法在通过attach的方式动态加载agent的时候调用。
* mTransform：指向<code>sun.instrument.InstrumentationImpl.transform</code>方法。
* mAgentClassName：在我们javaagent的MANIFEST.MF里指定的<code>Agent-Class</code>。
* mOptionsString：传给agent的一些参数。
* mRedefineAvailable：是否开启了redefine功能，在javaagent的MANIFEST.MF里设置<code>Can-Redefine-Classes:true</code>。
* mNativeMethodPrefixAvailable：是否支持native方法前缀设置，通样在javaagent的MANIFEST.MF里设置<code>Can-Set-Native-Method-Prefix:true</code>。
* mIsRetransformer：如果在javaagent的MANIFEST.MF文件里定义了<code>Can-Retransform-Classes:true</code>，那将会设置mRetransformEnvironment的mIsRetransformer为true。</p>

<h3>启动时加载instrument agent</h3>

<p>正如『概述』里提到的方式，就是启动的时候加载instrument agent，具体过程都在<code>InvocationAdapter.c</code>的<code>Agent_OnLoad</code>方法里，简单描述下过程：</p>

<ul>
<li>创建并初始化JPLISAgent</li>
<li>监听VMInit事件，在vm初始化完成之后做下面的事情：

<ul>
<li>创建InstrumentationImpl对象</li>
<li>监听ClassFileLoadHook事件</li>
<li>调用InstrumentationImpl的<code>loadClassAndCallPremain</code>方法，在这个方法里会去调用javaagent里MANIFEST.MF里指定的<code>Premain-Class</code>类的premain方法</li>
</ul>
</li>
<li>解析javaagent里MANIFEST.MF里的参数，并根据这些参数来设置JPLISAgent里的一些内容</li>
</ul>


<h3>运行时加载instrument agent</h3>

<p>运行时加载的方式，大致按照下面的方式来操作：
<code>
VirtualMachine vm = VirtualMachine.attach(pid);
vm.loadAgent(agentPath, agentArgs);
</code></p>

<p>上面会通过jvm的attach机制来请求目标jvm加载对应的agent，过程大致如下：</p>

<ul>
<li>创建并初始化JPLISAgent</li>
<li>解析javaagent里MANIFEST.MF里的参数</li>
<li>创建InstrumentationImpl对象</li>
<li>监听ClassFileLoadHook事件</li>
<li>调用InstrumentationImpl的<code>loadClassAndCallAgentmain</code>方法，在这个方法里会去调用javaagent里MANIFEST.MF里指定的<code>Agent-Class</code>类的<code>agentmain</code>方法</li>
</ul>


<h3>instrument agent的ClassFileLoadHook回调实现</h3>

<p>不管是启动时还是运行时加载的instrument agent都关注着同一个jvmti事件---<code>ClassFileLoadHook</code>，这个事件是在读取字节码文件之后回调时用的，这样可以对原来的字节码做修改，那这里面究竟是怎样实现的呢？</p>

<p>```
void JNICALL
eventHandlerClassFileLoadHook(  jvmtiEnv *              jvmtienv,</p>

<pre><code>                            JNIEnv *                jnienv,
                            jclass                  class_being_redefined,
                            jobject                 loader,
                            const char*             name,
                            jobject                 protectionDomain,
                            jint                    class_data_len,
                            const unsigned char*    class_data,
                            jint*                   new_class_data_len,
                            unsigned char**         new_class_data) {
JPLISEnvironment * environment  = NULL;

environment = getJPLISEnvironment(jvmtienv);

/* if something is internally inconsistent (no agent), just silently return without touching the buffer */
if ( environment != NULL ) {
    jthrowable outstandingException = preserveThrowable(jnienv);
    transformClassFile( environment-&gt;mAgent,
                        jnienv,
                        loader,
                        name,
                        class_being_redefined,
                        protectionDomain,
                        class_data_len,
                        class_data,
                        new_class_data_len,
                        new_class_data,
                        environment-&gt;mIsRetransformer);
    restoreThrowable(jnienv, outstandingException);
}
</code></pre>

<p>}
```</p>

<p>先根据jvmtiEnv取得对应的JPLISEnvironment，因为上面我已经说到其实有两个JPLISEnvironment（并且有两个jvmtiEnv），其中一个专门做retransform的，而另外一个用来做其他的事情，根据不同的用途我们在注册具体的ClassFileTransformer的时候也是分开的，对于作为retransform用的ClassFileTransformer我们会注册到一个单独的TransformerManager里。</p>

<p>接着调用transformClassFile方法，由于函数实现比较长，我这里就不贴代码了，大致意思就是调用InstrumentationImpl对象的transform方法，根据最后那个参数来决定选哪个TransformerManager里的ClassFileTransformer对象们做transform操作。</p>

<p>```
 private byte[]</p>

<pre><code>transform(  ClassLoader         loader,
            String              classname,
            Class               classBeingRedefined,
            ProtectionDomain    protectionDomain,
            byte[]              classfileBuffer,
            boolean             isRetransformer) {
    TransformerManager mgr = isRetransformer?
                                    mRetransfomableTransformerManager :
                                    mTransformerManager;
    if (mgr == null) {
        return null; // no manager, no transform
    } else {
        return mgr.transform(   loader,
                                classname,
                                classBeingRedefined,
                                protectionDomain,
                                classfileBuffer);
    }
}
</code></pre>

<p>  public byte[]</p>

<pre><code>transform(  ClassLoader         loader,
            String              classname,
            Class               classBeingRedefined,
            ProtectionDomain    protectionDomain,
            byte[]              classfileBuffer) {
    boolean someoneTouchedTheBytecode = false;

    TransformerInfo[]  transformerList = getSnapshotTransformerList();

    byte[]  bufferToUse = classfileBuffer;

    // order matters, gotta run 'em in the order they were added
    for ( int x = 0; x &lt; transformerList.length; x++ ) {
        TransformerInfo         transformerInfo = transformerList[x];
        ClassFileTransformer    transformer = transformerInfo.transformer();
        byte[]                  transformedBytes = null;

        try {
            transformedBytes = transformer.transform(   loader,
                                                        classname,
                                                        classBeingRedefined,
                                                        protectionDomain,
                                                        bufferToUse);
        }
        catch (Throwable t) {
            // don't let any one transformer mess it up for the others.
            // This is where we need to put some logging. What should go here? FIXME
        }

        if ( transformedBytes != null ) {
            someoneTouchedTheBytecode = true;
            bufferToUse = transformedBytes;
        }
    }

    // if someone modified it, return the modified buffer.
    // otherwise return null to mean "no transforms occurred"
    byte [] result;
    if ( someoneTouchedTheBytecode ) {
        result = bufferToUse;
    }
    else {
        result = null;
    }

    return result;
}   
</code></pre>

<p>```</p>

<p>以上是最终调到的java代码，可以看到已经调用到我们自己编写的javaagent代码里了，我们一般是实现一个ClassFileTransformer类，然后创建一个对象注册了对应的TransformerManager里。</p>

<h2>Class Transform的实现</h2>

<p>这里说的class transform其实是狭义的，主要是针对第一次类文件加载的时候就要求被transform的场景，在加载类文件的时候发出ClassFileLoad的事件，然后交给instrumenat agent来调用javaagent里注册的ClassFileTransformer实现字节码的修改。</p>

<h2>Class Redefine的实现</h2>

<p>类重新定义，这是Instrumentation提供的基础功能之一，主要用在已经被加载过的类上，想对其进行修改，要做这件事，我们必须要知道两个东西，一个是要修改哪个类，另外一个是那个类你想修改成怎样的结构，有了这两信息之后于是你就可以通过InstrumentationImpl的下面的redefineClasses方法去操作了：</p>

<p>```
public void</p>

<pre><code>redefineClasses(ClassDefinition[]   definitions)
        throws  ClassNotFoundException {
    if (!isRedefineClassesSupported()) {
        throw new UnsupportedOperationException("redefineClasses is not supported in this environment");
    }
    if (definitions == null) {
        throw new NullPointerException("null passed as 'definitions' in redefineClasses");
    }
    for (int i = 0; i &lt; definitions.length; ++i) {
        if (definitions[i] == null) {
            throw new NullPointerException("element of 'definitions' is null in redefineClasses");
        }
    }
    if (definitions.length == 0) {
        return; // short-circuit if there are no changes requested
    }

    redefineClasses0(mNativeAgent, definitions);
}
</code></pre>

<p>```</p>

<p>在JVM里对应的实现是创建一个<code>VM_RedefineClasses</code>的<code>VM_Operation</code>，注意执行它的时候会stop the world的：</p>

<p><code>
jvmtiError
JvmtiEnv::RedefineClasses(jint class_count, const jvmtiClassDefinition* class_definitions) {
//TODO: add locking
  VM_RedefineClasses op(class_count, class_definitions, jvmti_class_load_kind_redefine);
  VMThread::execute(&amp;op);
  return (op.check_error());
} /* end RedefineClasses */
</code></p>

<p>这个过程我尽量用语言来描述清楚，不详细贴代码了，因为代码量实在有点大：</p>

<ul>
<li>挨个遍历要批量重定义的jvmtiClassDefinition</li>
<li>然后读取新的字节码，如果有关注ClassFileLoadHook事件的，还会走对应的transform来对新的字节码再做修改</li>
<li>字节码解析好，创建一个klassOop对象</li>
<li>对比新老类，并要求如下：

<ul>
<li>父类是同一个</li>
<li>实现的接口数也要相同，并且是相同的接口</li>
<li>类访问符必须一致</li>
<li>字段数和字段名要一致</li>
<li>新增或删除的方法必须是private static/final的</li>
<li>可以修改方法</li>
</ul>
</li>
<li>对新类做字节码校验</li>
<li>合并新老类的常量池</li>
<li>如果老类上有断点，那都清除掉</li>
<li>对老类做jit去优化</li>
<li>对新老方法匹配的方法的jmethodid做更新，将老的jmethodId更新到新的method上</li>
<li>新类的常量池的holer指向老的类</li>
<li>将新类和老类的一些属性做交换，比如常量池，methods，内部类</li>
<li>初始化新的vtable和itable</li>
<li>交换annotation的method,field,paramenter</li>
<li>遍历所有当前类的子类，修改他们的vtable及itable</li>
</ul>


<p>上面是基本的过程，总的来说就是只更新了类里内容，相当于只更新了指针指向的内容，并没有更新指针，避免了遍历大量已有类对象对它们进行更新带来的开销。</p>

<h2>Class Retransform的实现</h2>

<p>retransform class可以简单理解为回滚操作，具体回滚到哪个版本，这个需要看情况而定，下面不管那种情况都有一个前提，那就是javaagent已经要求要有retransform的能力了：</p>

<ul>
<li>如果类是在第一次加载的的时候就做了transform，那么做retransform的时候会将代码回滚到transform之后的代码</li>
<li>如果类是在第一次加载的的时候没有任何变化，那么做retransform的时候会将代码回滚到最原始的类文件里的字节码</li>
<li>如果类已经被加载了，期间类可能做过多次redefine(比如被另外一个agent做过)，但是接下来加载一个新的agent要求有retransform的能力了，然后对类做redefine的动作，那么retransform的时候会将代码回滚到上一个agent最后一次做redefine后的字节码</li>
</ul>


<p>我们从InstrumentationImpl的<code>retransformClasses</code>方法参数看猜到应该是做回滚操作，因为我们只指定了class</p>

<p>```</p>

<pre><code>public void
retransformClasses(Class&lt;?&gt;[] classes) {
    if (!isRetransformClassesSupported()) {
        throw new UnsupportedOperationException(
          "retransformClasses is not supported in this environment");
    }
    retransformClasses0(mNativeAgent, classes);
}
</code></pre>

<p>```</p>

<p>不过retransform的实现其实也是通过redefine的功能来实现，在类加载的时候有比较小的差别，主要体现在究竟会走哪些transform上，如果当前是做retransform的话，那将忽略那些注册到正常的TransformerManager里的ClassFileTransformer，而只会走专门为retransform而准备的TransformerManager的ClassFileTransformer，不然想象一下字节码又被无声无息改成某个中间态了。</p>

<p>```
private:
  void post_all_envs() {</p>

<pre><code>if (_load_kind != jvmti_class_load_kind_retransform) {
  // for class load and redefine,
  // call the non-retransformable agents
  JvmtiEnvIterator it;
  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {
    if (!env-&gt;is_retransformable() &amp;&amp; env-&gt;is_enabled(JVMTI_EVENT_CLASS_FILE_LOAD_HOOK)) {
      // non-retransformable agents cannot retransform back,
      // so no need to cache the original class file bytes
      post_to_env(env, false);
    }
  }
}
JvmtiEnvIterator it;
for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {
  // retransformable agents get all events
  if (env-&gt;is_retransformable() &amp;&amp; env-&gt;is_enabled(JVMTI_EVENT_CLASS_FILE_LOAD_HOOK)) {
    // retransformable agents need to cache the original class file
    // bytes if changes are made via the ClassFileLoadHook
    post_to_env(env, true);
  }
}
</code></pre>

<p>  }
```</p>

<h2>javaagent的其他小众功能</h2>

<p>javaagent除了做字节码上面的修改之外，其实还有一些小功能，有时候还是挺有用的</p>

<ul>
<li><p>获取所有已经被加载的类
<code>
  Class[] getAllLoadedClasses();
</code></p></li>
<li><p>获取所有已经被初始化过了的类
<code>
Class[] getInitiatedClasses(ClassLoader loader);
</code></p></li>
<li><p>获取某个对象的大小
<code>
long getObjectSize(Object objectToSize);
</code></p></li>
<li><p>将某个jar加入到bootstrapclasspath里优先其他jar被加载
<code>
void appendToBootstrapClassLoaderSearch(JarFile jarfile);
</code></p></li>
<li><p>将某个jar加入到classpath里供appclassloard去加载
<code>
void appendToSystemClassLoaderSearch(JarFile jarfile);
</code></p></li>
<li>设置某些native方法的前缀，主要在找native方法的时候做规则匹配
<code>
void setNativeMethodPrefix(ClassFileTransformer transformer, String prefix);
</code></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[进程物理内存远大于Xmx的问题分析]]></title>
    <link href="http://nijiaben.github.io/blog/2015/08/21/rssxmx/"/>
    <updated>2015-08-21T18:58:53+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/08/21/rssxmx</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>最近经常被问到一个问题，"为什么我们系统进程占用的物理内存(Res/Rss)会远远大于设置的Xmx值"，比如Xmx设置1.7G，但是top看到的Res的值却达到了3.0G，随着进程的运行，Res的值还在递增，直到达到某个值，被OS当做bad process直接被kill掉了。</p>

<!-- more -->


<p>```
top - 16:57:47 up 73 days,  4:12,  8 users,  load average: 6.78, 9.68, 13.31
Tasks: 130 total,   1 running, 123 sleeping,   6 stopped,   0 zombie
Cpu(s): 89.9%us,  5.6%sy,  0.0%ni,  2.0%id,  0.7%wa,  0.7%hi,  1.2%si,  0.0%st</p>

<pre><code>...
</code></pre>

<p>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
22753 admin     20   0 4252m 3.0g  17m S 192.8 52.7 151:47.59 /opt/taobao/java/bin/java -server -Xms1700m -Xmx1700m -Xmn680m -Xss256k -XX:PermSize=128m -XX:MaxPermSize=128m -XX:+UseStringCache -XX:+
   40 root      20   0     0    0    0 D  0.3  0.0   5:53.07 [kswapd0]
```</p>

<h2>物理内存大于Xmx可能吗</h2>

<p>先说下Xmx，这个vm配置只包括我们熟悉的新生代和老生代的最大值，不包括持久代，也不包括CodeCache，还有我们常听说的堆外内存从名字上一看也知道没有包括在内，当然还有其他内存也不会算在内等，因此理论上我们看到物理内存大于Xmx也是可能的，不过超过太多估计就可能有问题了。</p>

<h2>物理内存和虚拟内存间的映射关系</h2>

<p>我们知道os在内存上面的设计是花了心思的，为了让资源得到最大合理利用，在物理内存之上搞一层虚拟地址，同一台机器上每个进程可访问的虚拟地址空间大小都是一样的，为了屏蔽掉复杂的到物理内存的映射，该工作os直接做了，当需要物理内存的时候，当前虚拟地址又没有映射到物理内存上的时候，就会发生缺页中断，由内核去为之准备一块物理内存，所以即使我们分配了一块1G的虚拟内存，物理内存上不一定有一块1G的空间与之对应，那到底这块虚拟内存块到底映射了多少物理内存呢，这个我们在linux下可以通过<code>/proc/&lt;pid&gt;/smaps</code>这个文件看到，其中的Size表示虚拟内存大小，而Rss表示的是物理内存，所以从这层意义上来说和虚拟内存块对应的物理内存块不应该超过此虚拟内存块的空间范围</p>

<p><code>
8dc00000-100000000 rwxp 00000000 00:00 0
Size:            1871872 kB
Rss:             1798444 kB
Pss:             1798444 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:   1798444 kB
Referenced:      1798392 kB
Anonymous:       1798444 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
</code>
此次为了排查这个问题，我特地写了个简单的分析工具来分析这个问题，将连续的虚拟内存块合并做统计，一般来说连续分配的内存块还是有一定关系的，当然也不能完全肯定这种关系，得到的效果大致如下：</p>

<p>```
from->to    vs rss rss_percentage(rss/total_rss) merge_block_count</p>

<p>0x8dc00000->0x30c9a20000      1871872      1487480      53.77%     1
0x7faf7a4c5000->0x7fffa7dd9000      1069464      735996      26.60%     440
0x7faf50c75000->0x7faf6c02a000      445996      226860      8.20%     418
0x7faf6c027000->0x7faf78010000      196452      140640      5.08%     492
0x418e8000->0x100000000      90968      90904      3.29%     1
0x7faf48000000->0x7faf50c78000      131072      35120      1.27%     4
0x7faf28000000->0x7faf3905e000      196608      20708      0.75%     6
0x7faf38000000->0x7faf4ad83000      196608      17036      0.62%     6
0x7faf78009000->0x7faf7a4c6000      37612      10440      0.38%     465
0x30c9e00000->0x30ca202000      3656      716      0.03%     5
0x7faf20000000->0x7faf289c7000      65536      132      0.00%     2
0x30c9a00000->0x30c9c20000      128      108      0.00%     1
0x30ca600000->0x30cae83000      2164      76      0.00%     5
0x30cbe00000->0x30cca16000      2152      68      0.00%     5
0x7fffa7dc3000->0x7fffa7e00000      92      48      0.00%     1
0x30cca00000->0x7faf21dba000      2148      32      0.00%     5
0x30cb200000->0x30cbe16000      2080      28      0.00%     4
0x30cae00000->0x30cb207000      2576      20      0.00%     4
0x30ca200000->0x30ca617000      2064      16      0.00%     4
0x40000000->0x4010a000      36      12      0.00%     2
0x30c9c1f000->0x30c9f89000      12      12      0.00%     3
0x40108000->0x471be000      8      8      0.00%     1
0x7fffa7dff000->0x0      4      4      0.00%     0
```</p>

<p>当然这只是一个简单的分析，如果更有价值需要我们挖掘更多的点出来，比如每个内存块是属于哪块memory pool，到底是什么地方分配的等，不过需要jvm支持(<code>注：上面的第一条，其实就是new+old+perm对应的虚拟内存及其物理内存映射情况</code>)。</p>

<h2>进程满足什么条件会被os因为oom而被kill</h2>

<p>当一个进程无故消失的时候，我们一般看<code>/var/log/message</code>里是否有<code>Out of memory: Kill process</code>关键字(如果是java进程我们先看是否有crash日志)，如果有就说明是被os因为oom而被kill了：</p>

<p>```
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238016] java invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238022] java cpuset=/ mems_allowed=0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238024] Pid: 25371, comm: java Not tainted 2.6.32-220.23.2.ali878.el6.x86_64 #1
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238026] Call Trace:
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238039]  [<ffffffff810c35e1>] ? cpuset_print_task_mems_allowed+0x91/0xb0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238068]  [<ffffffff81114d70>] ? dump_header+0x90/0x1b0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238074]  [<ffffffff810e1b2e>] ? <strong>delayacct_freepages_end+0x2e/0x30
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238079]  [<ffffffff81213ffc>] ? security_real_capable_noaudit+0x3c/0x70
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238082]  [<ffffffff811151fa>] ? oom_kill_process+0x8a/0x2c0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238084]  [<ffffffff81115131>] ? select_bad_process+0xe1/0x120
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238087]  [<ffffffff81115650>] ? out_of_memory+0x220/0x3c0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238093]  [<ffffffff81125929>] ? </strong>alloc_pages_nodemask+0x899/0x930
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238099]  [<ffffffff81159b6a>] ? alloc_pages_current+0xaa/0x110
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238102]  [<ffffffff81111ea7>] ? <strong>page_cache_alloc+0x87/0x90
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238105]  [<ffffffff81127f4b>] ? </strong>do_page_cache_readahead+0xdb/0x270
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238108]  [<ffffffff81128101>] ? ra_submit+0x21/0x30
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238110]  [<ffffffff81113e17>] ? filemap_fault+0x5b7/0x600
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238113]  [<ffffffff8113ca64>] ? <strong>do_fault+0x54/0x510
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238116]  [<ffffffff811140a0>] ? </strong>generic_file_aio_write+0x240/0x470
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238118]  [<ffffffff8113d017>] ? handle_pte_fault+0xf7/0xb50
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238121]  [<ffffffff8111438e>] ? generic_file_aio_write+0xbe/0xe0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238133]  [<ffffffffa008a171>] ? ext4_file_write+0x61/0x1e0 [ext4]
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238135]  [<ffffffff8113dc54>] ? handle_mm_fault+0x1e4/0x2b0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238138]  [<ffffffff81177c7a>] ? do_sync_write+0xfa/0x140
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238143]  [<ffffffff81042c69>] ? __do_page_fault+0x139/0x480
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238147]  [<ffffffff8118ad22>] ? vfs_ioctl+0x22/0xa0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238151]  [<ffffffff814e4f8e>] ? do_page_fault+0x3e/0xa0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238154]  [<ffffffff814e2345>] ? page_fault+0x25/0x30</p>

<p>...</p>

<p>Aug 19 08:32:38 mybank-ant kernel: : [6176841.247969] [24673]  1801 24673  1280126   926068   1       0             0 java
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247971] [25084]  1801 25084     3756      101   0       0             0 top
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247973] [25094]  1801 25094    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247975] [25098]  1801 25098    25233       31   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247977] [25100]  1801 25100    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247979] [25485]  1801 25485    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247981] [26055]  1801 26055    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247984] [26069]  1801 26069    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247986] [26081]  1801 26081    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247988] [26147]  1801 26147    25233       32   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247990] Out of memory: Kill process 24673 (java) score 946 or sacrifice child
Aug 19 08:32:38 mybank-ant kernel: : [6176841.249016] Killed process 24673, UID 1801, (java) total-vm:5120504kB, anon-rss:3703788kB, file-rss:484kB
```</p>

<p>从上面我们看到了一个堆栈，也就是内核里选择被kill进程的过程，这个过程会对进程进行一系列的计算，每个进程都会给它们计算一个score，这个分数会记录在<code>/proc/&lt;pid&gt;/oom_score</code>里，通常这个分数越高，就越危险，被kill的可能性就越大，下面将内核相关的代码贴出来，有兴趣的可以看看，其中代码注释上也写了挺多相关的东西了：</p>

<p>```
/<em>
 * Simple selection loop. We chose the process with the highest
 * number of 'points'. We expect the caller will lock the tasklist.
 *
 * (not docbooked, we don't want this one cluttering up the manual)
 </em>/
static struct task_struct <em>select_bad_process(unsigned long </em>ppoints,</p>

<pre><code>                    struct mem_cgroup *mem)
</code></pre>

<p>{</p>

<pre><code>struct task_struct *p;
struct task_struct *chosen = NULL;
struct timespec uptime;
*ppoints = 0;

do_posix_clock_monotonic_gettime(&amp;uptime);
for_each_process(p) {
    unsigned long points;

    /*
     * skip kernel threads and tasks which have already released
     * their mm.
     */
    if (!p-&gt;mm)
        continue;
    /* skip the init task */
    if (is_global_init(p))
        continue;
    if (mem &amp;&amp; !task_in_mem_cgroup(p, mem))
        continue;

    /*
     * This task already has access to memory reserves and is
     * being killed. Don't allow any other task access to the
     * memory reserve.
     *
     * Note: this may have a chance of deadlock if it gets
     * blocked waiting for another task which itself is waiting
     * for memory. Is there a better alternative?
     */
    if (test_tsk_thread_flag(p, TIF_MEMDIE))
        return ERR_PTR(-1UL);

    /*
     * This is in the process of releasing memory so wait for it
     * to finish before killing some other task by mistake.
     *
     * However, if p is the current task, we allow the 'kill' to
     * go ahead if it is exiting: this will simply set TIF_MEMDIE,
     * which will allow it to gain access to memory reserves in
     * the process of exiting and releasing its resources.
     * Otherwise we could get an easy OOM deadlock.
     */
    if (p-&gt;flags &amp; PF_EXITING) {
        if (p != current)
            return ERR_PTR(-1UL);

        chosen = p;
        *ppoints = ULONG_MAX;
    }

    if (p-&gt;signal-&gt;oom_adj == OOM_DISABLE)
        continue;

    points = badness(p, uptime.tv_sec);
    if (points &gt; *ppoints || !chosen) {
        chosen = p;
        *ppoints = points;
    }
}

return chosen;
</code></pre>

<p>}</p>

<p>/<em>*
 * badness - calculate a numeric value for how bad this task has been
 * @p: task struct of which task we should calculate
 * @uptime: current uptime in seconds
 *
 * The formula used is relatively simple and documented inline in the
 * function. The main rationale is that we want to select a good task
 * to kill when we run out of memory.
 *
 * Good in this context means that:
 * 1) we lose the minimum amount of work done
 * 2) we recover a large amount of memory
 * 3) we don't kill anything innocent of eating tons of memory
 * 4) we want to kill the minimum amount of processes (one)
 * 5) we try to kill the process the user expects us to kill, this
 *    algorithm has been meticulously tuned to meet the principle
 *    of least surprise ... (be careful when you change it)
 </em>/</p>

<p>unsigned long badness(struct task_struct *p, unsigned long uptime)
{</p>

<pre><code>unsigned long points, cpu_time, run_time;
struct mm_struct *mm;
struct task_struct *child;
int oom_adj = p-&gt;signal-&gt;oom_adj;
struct task_cputime task_time;
unsigned long utime;
unsigned long stime;

if (oom_adj == OOM_DISABLE)
    return 0;

task_lock(p);
mm = p-&gt;mm;
if (!mm) {
    task_unlock(p);
    return 0;
}

/*
 * The memory size of the process is the basis for the badness.
 */
points = mm-&gt;total_vm;

/*
 * After this unlock we can no longer dereference local variable `mm'
 */
task_unlock(p);

/*
 * swapoff can easily use up all memory, so kill those first.
 */
if (p-&gt;flags &amp; PF_OOM_ORIGIN)
    return ULONG_MAX;

/*
 * Processes which fork a lot of child processes are likely
 * a good choice. We add half the vmsize of the children if they
 * have an own mm. This prevents forking servers to flood the
 * machine with an endless amount of children. In case a single
 * child is eating the vast majority of memory, adding only half
 * to the parents will make the child our kill candidate of choice.
 */
list_for_each_entry(child, &amp;p-&gt;children, sibling) {
    task_lock(child);
    if (child-&gt;mm != mm &amp;&amp; child-&gt;mm)
        points += child-&gt;mm-&gt;total_vm/2 + 1;
    task_unlock(child);
}

/*
 * CPU time is in tens of seconds and run time is in thousands
     * of seconds. There is no particular reason for this other than
     * that it turned out to work very well in practice.
 */
thread_group_cputime(p, &amp;task_time);
utime = cputime_to_jiffies(task_time.utime);
stime = cputime_to_jiffies(task_time.stime);
cpu_time = (utime + stime) &gt;&gt; (SHIFT_HZ + 3);


if (uptime &gt;= p-&gt;start_time.tv_sec)
    run_time = (uptime - p-&gt;start_time.tv_sec) &gt;&gt; 10;
else
    run_time = 0;

if (cpu_time)
    points /= int_sqrt(cpu_time);
if (run_time)
    points /= int_sqrt(int_sqrt(run_time));

/*
 * Niced processes are most likely less important, so double
 * their badness points.
 */
if (task_nice(p) &gt; 0)
    points *= 2;

/*
 * Superuser processes are usually more important, so we make it
 * less likely that we kill those.
 */
if (has_capability_noaudit(p, CAP_SYS_ADMIN) ||
    has_capability_noaudit(p, CAP_SYS_RESOURCE))
    points /= 4;

/*
 * We don't want to kill a process with direct hardware access.
 * Not only could that mess up the hardware, but usually users
 * tend to only have this flag set on applications they think
 * of as important.
 */
if (has_capability_noaudit(p, CAP_SYS_RAWIO))
    points /= 4;

/*
 * If p's nodes don't overlap ours, it may still help to kill p
 * because p may have allocated or otherwise mapped memory on
 * this node before. However it will be less likely.
 */
if (!has_intersects_mems_allowed(p))
    points /= 8;

/*
 * Adjust the score by oom_adj.
 */
if (oom_adj) {
    if (oom_adj &gt; 0) {
        if (!points)
            points = 1;
        points &lt;&lt;= oom_adj;
    } else
        points &gt;&gt;= -(oom_adj);
}
</code></pre>

<h1>ifdef DEBUG</h1>

<pre><code>printk(KERN_DEBUG "OOMkill: task %d (%s) got %lu points\n",
p-&gt;pid, p-&gt;comm, points);
</code></pre>

<h1>endif</h1>

<pre><code>return points;
</code></pre>

<p>}
```</p>

<h2>物理内存到底去哪了？</h2>

<h3>DirectByteBuffer冰山对象？</h3>

<p>这是我们查这个问题首先要想到的一个地方，是否是因为什么地方不断创建DirectByteBuffer对象，但是由于没有被回收导致了内存泄露呢，之前有篇文章已经详细介绍了这种特殊对象<a href="http://lovestblog.cn/blog/2015/05/12/direct-buffer/">JVM源码分析之堆外内存完全解读</a>，对阿里内部的童鞋，可以直接使用zprofiler的heap视图里的堆外内存分析功能拿到统计结果，知道后台到底绑定了多少堆外内存还没有被回收：</p>

<p><code>
object  position    limit   capacity
 java.nio.DirectByteBuffer @ 0x760afaed0    133 133 6380562
 java.nio.DirectByteBuffer @ 0x790d51ae0    0   262144  262144
 java.nio.DirectByteBuffer @ 0x790d20b80    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x790d20b40    0   262144  262144
 java.nio.DirectByteBuffer @ 0x790d20b00    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x771ba3608    0   262144  262144
 java.nio.DirectByteBuffer @ 0x771ba35c8    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x7c5c9e250    0   131072  131072
 java.nio.DirectByteBuffer @ 0x7c5c9e210    74670   74670   131072
 java.nio.DirectByteBuffer @ 0x7c185cd10    0   131072  131072
 java.nio.DirectByteBuffer @ 0x7c185ccd0    98965   98965   131072
 java.nio.DirectByteBuffer @ 0x7b181c980    65627   65627   131072
 java.nio.DirectByteBuffer @ 0x7a40d6e40    0   131072  131072
 java.nio.DirectByteBuffer @ 0x794ac3320    0   131072  131072
 java.nio.DirectByteBuffer @ 0x794a7a418    80490   80490   131072
 java.nio.DirectByteBuffer @ 0x77279e1d8    0   131072  131072
 java.nio.DirectByteBuffer @ 0x77279dde8    65627   65627   131072
 java.nio.DirectByteBuffer @ 0x76ea84000    0   131072  131072
 java.nio.DirectByteBuffer @ 0x76ea83fc0    82549   82549   131072
 java.nio.DirectByteBuffer @ 0x764d8d678    0   0   131072
 java.nio.DirectByteBuffer @ 0x764d8d638    0   0   131072
 java.nio.DirectByteBuffer @ 0x764d8d5f8    0   0   131072
 java.nio.DirectByteBuffer @ 0x761a76340    0   131072  131072
 java.nio.DirectByteBuffer @ 0x761a76300    74369   74369   131072
 java.nio.DirectByteBuffer @ 0x7607423d0    0   131072  131072
 总共: 25 / 875 条目; 还有850条,双击展开 1267762 3826551 12083282
</code></p>

<h3>某个动态库里频繁分配？</h3>

<p>对于动态库里频繁分配的问题，主要得使用google的perftools工具了，该工具网上介绍挺多的，就不对其用法做详细介绍了，通过该工具我们能得到native方法分配内存的情况，该工具主要利用了unix的一个环境变量LD_PRELOAD，它允许你要加载的动态库优先加载起来，相当于一个Hook了，于是可以针对同一个函数可以选择不同的动态库里的实现了，比如googleperftools就是将malloc方法替换成了tcmalloc的实现，这样就可以跟踪内存分配路径了，得到的效果类似如下：</p>

<p>```
Total: 1670.0 MB
  1616.3  96.8%  96.8%   1616.3  96.8% zcalloc</p>

<pre><code>40.3   2.4%  99.2%     40.3   2.4% os::malloc
 9.4   0.6%  99.8%      9.4   0.6% init
 1.6   0.1%  99.9%      1.7   0.1% readCEN
 1.3   0.1%  99.9%      1.3   0.1% ObjectSynchronizer::omAlloc
 0.5   0.0% 100.0%   1591.0  95.3% Java_java_util_zip_Deflater_init
 0.1   0.0% 100.0%      0.1   0.0% _dl_allocate_tls
 0.1   0.0% 100.0%      0.2   0.0% addMetaName
 0.1   0.0% 100.0%      0.2   0.0% allocZip
 0.1   0.0% 100.0%      0.1   0.0% instanceKlass::add_dependent_nmethod
 0.1   0.0% 100.0%      0.1   0.0% newEntry
 0.0   0.0% 100.0%      0.0   0.0% strdup
 0.0   0.0% 100.0%     25.8   1.5% Java_java_util_zip_Inflater_init
 0.0   0.0% 100.0%      0.0   0.0% growMetaNames
 0.0   0.0% 100.0%      0.0   0.0% _dl_new_object
 0.0   0.0% 100.0%      0.0   0.0% pthread_cond_wait@GLIBC_2.2.5
 0.0   0.0% 100.0%      1.4   0.1% Thread::Thread
 0.0   0.0% 100.0%      0.0   0.0% pthread_cond_timedwait@GLIBC_2.2.5
 0.0   0.0% 100.0%      0.0   0.0% JLI_MemAlloc
 0.0   0.0% 100.0%      0.0   0.0% read_alias_file
 0.0   0.0% 100.0%      0.0   0.0% _nl_intern_locale_data
 0.0   0.0% 100.0%      0.0   0.0% nss_parse_service_list
 0.0   0.0% 100.0%      0.0   0.0% getprotobyname
 0.0   0.0% 100.0%      0.0   0.0% getpwuid
 0.0   0.0% 100.0%      0.0   0.0% _dl_check_map_versions
 0.0   0.0% 100.0%   1590.5  95.2% deflateInit2_
</code></pre>

<p>```</p>

<p>从上面的输出中我们看到了<code>zcalloc</code>函数总共分配了1616.3M的内存，还有<code>Java_java_util_zip_Deflater_init</code>分配了1591.0M内存，<code>deflateInit2_</code>分配了1590.5M，然而总共才分配了1670.0M内存，所以这几个函数肯定是调用者和被调用者的关系：</p>

<p>```
JNIEXPORT jlong JNICALL
Java_java_util_zip_Deflater_init(JNIEnv *env, jclass cls, jint level,</p>

<pre><code>                             jint strategy, jboolean nowrap)
</code></pre>

<p>{</p>

<pre><code>z_stream *strm = calloc(1, sizeof(z_stream));

if (strm == 0) {
    JNU_ThrowOutOfMemoryError(env, 0);
    return jlong_zero;
} else {
    char *msg;
    switch (deflateInit2(strm, level, Z_DEFLATED,
                         nowrap ? -MAX_WBITS : MAX_WBITS,
                         DEF_MEM_LEVEL, strategy)) {
      case Z_OK:
        return ptr_to_jlong(strm);
      case Z_MEM_ERROR:
        free(strm);
        JNU_ThrowOutOfMemoryError(env, 0);
        return jlong_zero;
      case Z_STREAM_ERROR:
        free(strm);
        JNU_ThrowIllegalArgumentException(env, 0);
        return jlong_zero;
      default:
        msg = strm-&gt;msg;
        free(strm);
        JNU_ThrowInternalError(env, msg);
        return jlong_zero;
    }
}
</code></pre>

<p>}</p>

<p>int ZEXPORT deflateInit2_(strm, level, method, windowBits, memLevel, strategy,</p>

<pre><code>              version, stream_size)
z_streamp strm;
int  level;
int  method;
int  windowBits;
int  memLevel;
int  strategy;
const char *version;
int stream_size;
</code></pre>

<p>{</p>

<pre><code>deflate_state *s;
int wrap = 1;
static const char my_version[] = ZLIB_VERSION;

ushf *overlay;
/* We overlay pending_buf and d_buf+l_buf. This works since the average
 * output size for (length,distance) codes is &lt;= 24 bits.
 */

if (version == Z_NULL || version[0] != my_version[0] ||
    stream_size != sizeof(z_stream)) {
    return Z_VERSION_ERROR;
}
if (strm == Z_NULL) return Z_STREAM_ERROR;

strm-&gt;msg = Z_NULL;
if (strm-&gt;zalloc == (alloc_func)0) {
    strm-&gt;zalloc = zcalloc;
    strm-&gt;opaque = (voidpf)0;
}
if (strm-&gt;zfree == (free_func)0) strm-&gt;zfree = zcfree;
</code></pre>

<h1>ifdef FASTEST</h1>

<pre><code>if (level != 0) level = 1;
</code></pre>

<h1>else</h1>

<pre><code>if (level == Z_DEFAULT_COMPRESSION) level = 6;
</code></pre>

<h1>endif</h1>

<pre><code>if (windowBits &lt; 0) { /* suppress zlib wrapper */
    wrap = 0;
    windowBits = -windowBits;
}
</code></pre>

<h1>ifdef GZIP</h1>

<pre><code>else if (windowBits &gt; 15) {
    wrap = 2;       /* write gzip wrapper instead */
    windowBits -= 16;
}
</code></pre>

<h1>endif</h1>

<pre><code>if (memLevel &lt; 1 || memLevel &gt; MAX_MEM_LEVEL || method != Z_DEFLATED ||
    windowBits &lt; 8 || windowBits &gt; 15 || level &lt; 0 || level &gt; 9 ||
    strategy &lt; 0 || strategy &gt; Z_FIXED) {
    return Z_STREAM_ERROR;
}
if (windowBits == 8) windowBits = 9;  /* until 256-byte window bug fixed */
s = (deflate_state *) ZALLOC(strm, 1, sizeof(deflate_state));
if (s == Z_NULL) return Z_MEM_ERROR;
strm-&gt;state = (struct internal_state FAR *)s;
s-&gt;strm = strm;

s-&gt;wrap = wrap;
s-&gt;gzhead = Z_NULL;
s-&gt;w_bits = windowBits;
s-&gt;w_size = 1 &lt;&lt; s-&gt;w_bits;
s-&gt;w_mask = s-&gt;w_size - 1;

s-&gt;hash_bits = memLevel + 7;
s-&gt;hash_size = 1 &lt;&lt; s-&gt;hash_bits;
s-&gt;hash_mask = s-&gt;hash_size - 1;
s-&gt;hash_shift =  ((s-&gt;hash_bits+MIN_MATCH-1)/MIN_MATCH);

s-&gt;window = (Bytef *) ZALLOC(strm, s-&gt;w_size, 2*sizeof(Byte));
s-&gt;prev   = (Posf *)  ZALLOC(strm, s-&gt;w_size, sizeof(Pos));
s-&gt;head   = (Posf *)  ZALLOC(strm, s-&gt;hash_size, sizeof(Pos));

s-&gt;lit_bufsize = 1 &lt;&lt; (memLevel + 6); /* 16K elements by default */

overlay = (ushf *) ZALLOC(strm, s-&gt;lit_bufsize, sizeof(ush)+2);
s-&gt;pending_buf = (uchf *) overlay;
s-&gt;pending_buf_size = (ulg)s-&gt;lit_bufsize * (sizeof(ush)+2L);

if (s-&gt;window == Z_NULL || s-&gt;prev == Z_NULL || s-&gt;head == Z_NULL ||
    s-&gt;pending_buf == Z_NULL) {
    s-&gt;status = FINISH_STATE;
    strm-&gt;msg = (char*)ERR_MSG(Z_MEM_ERROR);
    deflateEnd (strm);
    return Z_MEM_ERROR;
}
s-&gt;d_buf = overlay + s-&gt;lit_bufsize/sizeof(ush);
s-&gt;l_buf = s-&gt;pending_buf + (1+sizeof(ush))*s-&gt;lit_bufsize;

s-&gt;level = level;
s-&gt;strategy = strategy;
s-&gt;method = (Byte)method;

return deflateReset(strm);
</code></pre>

<p>}
```</p>

<p>上述代码也验证了他们这种关系。</p>

<p>那现在的问题就是找出哪里调用<code>Java_java_util_zip_Deflater_init</code>了，从这方法的命名上知道它是一个java的native方法实现，对应的是<code>java.util.zip.Deflater</code>这个类的<code>init</code>方法，所以要知道<code>init</code>方法哪里被调用了，跟踪调用栈我们会想到btrace工具，但是btrace是通过插桩的方式来实现的，对于native方法是无法插桩的，于是我们看调用它的地方，找到对应的方法，然后进行btrace脚本编写：</p>

<p>```
import com.sun.btrace.annotations.<em>;
import static com.sun.btrace.BTraceUtils.</em>;</p>

<p>@BTrace public class Test {</p>

<pre><code>@OnMethod(
    clazz="java.util.zip.Deflater",
    method="&lt;init&gt;"
)
public static void onnewThread(int i,boolean b) {
    jstack();
 }
</code></pre>

<p>}</p>

<p>```</p>

<p>于是跟踪对应的进程，我们能抓到调用Deflater构造函数的堆栈</p>

<p><code>
org.apache.commons.compress.compressors.deflate.DeflateCompressorOutputStream.&lt;init&gt;(DeflateCompressorOutputStream.java:47)
com.xxx.unimsg.parse.util.CompressUtil.deflateCompressAndEncode(CompressUtil.java:199)
com.xxx.unimsg.parse.util.CompressUtil.compress(CompressUtil.java:80)
com.xxx.unimsg.UnifyMessageHelper.compressXml(UnifyMessageHelper.java:65)
com.xxx.core.model.utils.UnifyMessageUtil.compressXml(UnifyMessageUtil.java:56)
com.xxx.repository.convert.BatchInDetailConvert.convertDO(BatchInDetailConvert.java:57)
com.xxx.repository.impl.IncomingDetailRepositoryImpl$1.store(IncomingDetailRepositoryImpl.java:43)
com.xxx.repository.helper.IdempotenceHelper.store(IdempotenceHelper.java:27)
com.xxx.repository.impl.IncomingDetailRepositoryImpl.store(IncomingDetailRepositoryImpl.java:40)
sun.reflect.GeneratedMethodAccessor274.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
java.lang.reflect.Method.invoke(Method.java:597)
org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:309)
org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
com.alipay.finsupport.component.monitor.MethodMonitorInterceptor.invoke(MethodMonitorInterceptor.java:45)
org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
...
</code></p>

<p>从上面的堆栈我们找出了调用<code>java.util.zip.Deflate.init()</code>的地方</p>

<h2>问题解决</h2>

<p>上面已经定位了具体的代码了，于是再细致跟踪了下对应的代码，其实并不是代码实现上的问题，而是代码设计上没有考虑到流量很大的场景，当流量很大的时候，不管自己系统是否能承受这么大的压力，都来者不拒，拿到数据就做deflate，而这个过程是需要分配堆外内存的，当量达到一定程度的时候此时会发生oom killer，另外我们在分析过程中发现其实物理内存是有下降的</p>

<p><code>
30071.txt:     0.0   0.0% 100.0%     96.7  57.0% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    196.0  72.6% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    290.3  78.5% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    392.7  83.6% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    592.8  88.5% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    700.7  91.0% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    799.1  91.9% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    893.9  92.2% Java_java_util_zip_Deflater_init
30071.txt:     0.0   0.0%  99.9%    114.2  63.7% Java_java_util_zip_Deflater_init
30071.txt:     0.0   0.0% 100.0%    105.1  52.1% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    479.7  87.4% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    782.2  90.1% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    986.9  92.3% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1086.3  92.9% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1185.1  93.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    941.5  92.1% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0% 100.0%   1288.8  94.1% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1394.8  94.9% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1492.5  95.1% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1591.0  95.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    874.6  90.0% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    950.7  92.8% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    858.4  92.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    818.4  91.9% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    858.7  91.2% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    271.5  77.9% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1260.4  93.1% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    976.4  90.6% Java_java_util_zip_Deflater_init
</code></p>

<p>这也就说明了其实代码使用上并没有错，因此建议将deflate放到队列里去做，比如限制队列大小是100，每次最多100个数据可以被deflate，处理一个放进一个，以至于不会被活活撑死。</p>
]]></content>
  </entry>
  
</feed>
