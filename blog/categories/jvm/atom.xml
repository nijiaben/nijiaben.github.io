<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: JVM | 你假笨]]></title>
  <link href="http://nijiaben.github.io/blog/categories/jvm/atom.xml" rel="self"/>
  <link href="http://nijiaben.github.io/"/>
  <updated>2015-08-21T19:05:31+08:00</updated>
  <id>http://nijiaben.github.io/</id>
  <author>
    <name><![CDATA[你假笨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[进程物理内存远大于Xmx的问题分析]]></title>
    <link href="http://nijiaben.github.io/blog/2015/08/21/rssxmx/"/>
    <updated>2015-08-21T18:58:53+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/08/21/rssxmx</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>最近经常被问到一个问题，"为什么我们系统进程占用的物理内存(Res/Rss)会远远大于设置的Xmx值"，比如Xmx设置1.7G，但是top看到的Res的值却达到了3.0G，随着进程的运行，Res的值还在递增，直到达到某个值，被OS当做bad process直接被kill掉了。</p>

<!-- more -->


<p>```
top - 16:57:47 up 73 days,  4:12,  8 users,  load average: 6.78, 9.68, 13.31
Tasks: 130 total,   1 running, 123 sleeping,   6 stopped,   0 zombie
Cpu(s): 89.9%us,  5.6%sy,  0.0%ni,  2.0%id,  0.7%wa,  0.7%hi,  1.2%si,  0.0%st</p>

<pre><code>...
</code></pre>

<p>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
22753 admin     20   0 4252m 3.0g  17m S 192.8 52.7 151:47.59 /opt/taobao/java/bin/java -server -Xms1700m -Xmx1700m -Xmn680m -Xss256k -XX:PermSize=128m -XX:MaxPermSize=128m -XX:+UseStringCache -XX:+
   40 root      20   0     0    0    0 D  0.3  0.0   5:53.07 [kswapd0]
```</p>

<h2>物理内存大于Xmx可能吗</h2>

<p>先说下Xmx，这个vm配置只包括我们熟悉的新生代和老生代的最大值，不包括持久代，也不包括CodeCache，还有我们常听说的堆外内存从名字上一看也知道没有包括在内，当然还有其他内存也不会算在内等，因此理论上我们看到物理内存大于Xmx也是可能的，不过超过太多估计就可能有问题了。</p>

<h2>物理内存和虚拟内存间的映射关系</h2>

<p>我们知道os在内存上面的设计是花了心思的，为了让资源得到最大合理利用，在物理内存之上搞一层虚拟地址，同一台机器上每个进程可访问的虚拟地址空间大小都是一样的，为了屏蔽掉复杂的到物理内存的映射，该工作os直接做了，当需要物理内存的时候，当前虚拟地址又没有映射到物理内存上的时候，就会发生缺页中断，由内核去为之准备一块物理内存，所以即使我们分配了一块1G的虚拟内存，物理内存上不一定有一块1G的空间与之对应，那到底这块虚拟内存块到底映射了多少物理内存呢，这个我们在linux下可以通过<code>/proc/&lt;pid&gt;/smaps</code>这个文件看到，其中的Size表示虚拟内存大小，而Rss表示的是物理内存，所以从这层意义上来说和虚拟内存块对应的物理内存块不应该超过此虚拟内存块的空间范围</p>

<p><code>
8dc00000-100000000 rwxp 00000000 00:00 0
Size:            1871872 kB
Rss:             1798444 kB
Pss:             1798444 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:   1798444 kB
Referenced:      1798392 kB
Anonymous:       1798444 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
</code>
此次为了排查这个问题，我特地写了个简单的分析工具来分析这个问题，将连续的虚拟内存块合并做统计，一般来说连续分配的内存块还是有一定关系的，当然也不能完全肯定这种关系，得到的效果大致如下：</p>

<p>```
from->to    vs rss rss_percentage(rss/total_rss) merge_block_count</p>

<p>0x8dc00000->0x30c9a20000      1871872      1487480      53.77%     1
0x7faf7a4c5000->0x7fffa7dd9000      1069464      735996      26.60%     440
0x7faf50c75000->0x7faf6c02a000      445996      226860      8.20%     418
0x7faf6c027000->0x7faf78010000      196452      140640      5.08%     492
0x418e8000->0x100000000      90968      90904      3.29%     1
0x7faf48000000->0x7faf50c78000      131072      35120      1.27%     4
0x7faf28000000->0x7faf3905e000      196608      20708      0.75%     6
0x7faf38000000->0x7faf4ad83000      196608      17036      0.62%     6
0x7faf78009000->0x7faf7a4c6000      37612      10440      0.38%     465
0x30c9e00000->0x30ca202000      3656      716      0.03%     5
0x7faf20000000->0x7faf289c7000      65536      132      0.00%     2
0x30c9a00000->0x30c9c20000      128      108      0.00%     1
0x30ca600000->0x30cae83000      2164      76      0.00%     5
0x30cbe00000->0x30cca16000      2152      68      0.00%     5
0x7fffa7dc3000->0x7fffa7e00000      92      48      0.00%     1
0x30cca00000->0x7faf21dba000      2148      32      0.00%     5
0x30cb200000->0x30cbe16000      2080      28      0.00%     4
0x30cae00000->0x30cb207000      2576      20      0.00%     4
0x30ca200000->0x30ca617000      2064      16      0.00%     4
0x40000000->0x4010a000      36      12      0.00%     2
0x30c9c1f000->0x30c9f89000      12      12      0.00%     3
0x40108000->0x471be000      8      8      0.00%     1
0x7fffa7dff000->0x0      4      4      0.00%     0
```</p>

<p>当然这只是一个简单的分析，如果更有价值需要我们挖掘更多的点出来，比如每个内存块是属于哪块memory pool，到底是什么地方分配的等，不过需要jvm支持(<code>注：上面的第一条，其实就是new+old+perm对应的虚拟内存及其物理内存映射情况</code>)。</p>

<h2>进程满足什么条件会被os因为oom而被kill</h2>

<p>当一个进程无故消失的时候，我们一般看<code>/var/log/message</code>里是否有<code>Out of memory: Kill process</code>关键字(如果是java进程我们先看是否有crash日志)，如果有就说明是被os因为oom而被kill了：</p>

<p>```
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238016] java invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238022] java cpuset=/ mems_allowed=0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238024] Pid: 25371, comm: java Not tainted 2.6.32-220.23.2.ali878.el6.x86_64 #1
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238026] Call Trace:
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238039]  [<ffffffff810c35e1>] ? cpuset_print_task_mems_allowed+0x91/0xb0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238068]  [<ffffffff81114d70>] ? dump_header+0x90/0x1b0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238074]  [<ffffffff810e1b2e>] ? <strong>delayacct_freepages_end+0x2e/0x30
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238079]  [<ffffffff81213ffc>] ? security_real_capable_noaudit+0x3c/0x70
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238082]  [<ffffffff811151fa>] ? oom_kill_process+0x8a/0x2c0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238084]  [<ffffffff81115131>] ? select_bad_process+0xe1/0x120
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238087]  [<ffffffff81115650>] ? out_of_memory+0x220/0x3c0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238093]  [<ffffffff81125929>] ? </strong>alloc_pages_nodemask+0x899/0x930
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238099]  [<ffffffff81159b6a>] ? alloc_pages_current+0xaa/0x110
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238102]  [<ffffffff81111ea7>] ? <strong>page_cache_alloc+0x87/0x90
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238105]  [<ffffffff81127f4b>] ? </strong>do_page_cache_readahead+0xdb/0x270
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238108]  [<ffffffff81128101>] ? ra_submit+0x21/0x30
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238110]  [<ffffffff81113e17>] ? filemap_fault+0x5b7/0x600
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238113]  [<ffffffff8113ca64>] ? <strong>do_fault+0x54/0x510
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238116]  [<ffffffff811140a0>] ? </strong>generic_file_aio_write+0x240/0x470
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238118]  [<ffffffff8113d017>] ? handle_pte_fault+0xf7/0xb50
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238121]  [<ffffffff8111438e>] ? generic_file_aio_write+0xbe/0xe0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238133]  [<ffffffffa008a171>] ? ext4_file_write+0x61/0x1e0 [ext4]
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238135]  [<ffffffff8113dc54>] ? handle_mm_fault+0x1e4/0x2b0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238138]  [<ffffffff81177c7a>] ? do_sync_write+0xfa/0x140
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238143]  [<ffffffff81042c69>] ? __do_page_fault+0x139/0x480
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238147]  [<ffffffff8118ad22>] ? vfs_ioctl+0x22/0xa0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238151]  [<ffffffff814e4f8e>] ? do_page_fault+0x3e/0xa0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238154]  [<ffffffff814e2345>] ? page_fault+0x25/0x30</p>

<p>...</p>

<p>Aug 19 08:32:38 mybank-ant kernel: : [6176841.247969] [24673]  1801 24673  1280126   926068   1       0             0 java
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247971] [25084]  1801 25084     3756      101   0       0             0 top
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247973] [25094]  1801 25094    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247975] [25098]  1801 25098    25233       31   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247977] [25100]  1801 25100    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247979] [25485]  1801 25485    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247981] [26055]  1801 26055    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247984] [26069]  1801 26069    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247986] [26081]  1801 26081    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247988] [26147]  1801 26147    25233       32   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247990] Out of memory: Kill process 24673 (java) score 946 or sacrifice child
Aug 19 08:32:38 mybank-ant kernel: : [6176841.249016] Killed process 24673, UID 1801, (java) total-vm:5120504kB, anon-rss:3703788kB, file-rss:484kB
```</p>

<p>从上面我们看到了一个堆栈，也就是内核里选择被kill进程的过程，这个过程会对进程进行一系列的计算，每个进程都会给它们计算一个score，这个分数会记录在<code>/proc/&lt;pid&gt;/oom_score</code>里，通常这个分数越高，就越危险，被kill的可能性就越大，下面将内核相关的代码贴出来，有兴趣的可以看看，其中代码注释上也写了挺多相关的东西了：</p>

<p>```
/<em>
 * Simple selection loop. We chose the process with the highest
 * number of 'points'. We expect the caller will lock the tasklist.
 *
 * (not docbooked, we don't want this one cluttering up the manual)
 </em>/
static struct task_struct <em>select_bad_process(unsigned long </em>ppoints,</p>

<pre><code>                    struct mem_cgroup *mem)
</code></pre>

<p>{</p>

<pre><code>struct task_struct *p;
struct task_struct *chosen = NULL;
struct timespec uptime;
*ppoints = 0;

do_posix_clock_monotonic_gettime(&amp;uptime);
for_each_process(p) {
    unsigned long points;

    /*
     * skip kernel threads and tasks which have already released
     * their mm.
     */
    if (!p-&gt;mm)
        continue;
    /* skip the init task */
    if (is_global_init(p))
        continue;
    if (mem &amp;&amp; !task_in_mem_cgroup(p, mem))
        continue;

    /*
     * This task already has access to memory reserves and is
     * being killed. Don't allow any other task access to the
     * memory reserve.
     *
     * Note: this may have a chance of deadlock if it gets
     * blocked waiting for another task which itself is waiting
     * for memory. Is there a better alternative?
     */
    if (test_tsk_thread_flag(p, TIF_MEMDIE))
        return ERR_PTR(-1UL);

    /*
     * This is in the process of releasing memory so wait for it
     * to finish before killing some other task by mistake.
     *
     * However, if p is the current task, we allow the 'kill' to
     * go ahead if it is exiting: this will simply set TIF_MEMDIE,
     * which will allow it to gain access to memory reserves in
     * the process of exiting and releasing its resources.
     * Otherwise we could get an easy OOM deadlock.
     */
    if (p-&gt;flags &amp; PF_EXITING) {
        if (p != current)
            return ERR_PTR(-1UL);

        chosen = p;
        *ppoints = ULONG_MAX;
    }

    if (p-&gt;signal-&gt;oom_adj == OOM_DISABLE)
        continue;

    points = badness(p, uptime.tv_sec);
    if (points &gt; *ppoints || !chosen) {
        chosen = p;
        *ppoints = points;
    }
}

return chosen;
</code></pre>

<p>}</p>

<p>/<em>*
 * badness - calculate a numeric value for how bad this task has been
 * @p: task struct of which task we should calculate
 * @uptime: current uptime in seconds
 *
 * The formula used is relatively simple and documented inline in the
 * function. The main rationale is that we want to select a good task
 * to kill when we run out of memory.
 *
 * Good in this context means that:
 * 1) we lose the minimum amount of work done
 * 2) we recover a large amount of memory
 * 3) we don't kill anything innocent of eating tons of memory
 * 4) we want to kill the minimum amount of processes (one)
 * 5) we try to kill the process the user expects us to kill, this
 *    algorithm has been meticulously tuned to meet the principle
 *    of least surprise ... (be careful when you change it)
 </em>/</p>

<p>unsigned long badness(struct task_struct *p, unsigned long uptime)
{</p>

<pre><code>unsigned long points, cpu_time, run_time;
struct mm_struct *mm;
struct task_struct *child;
int oom_adj = p-&gt;signal-&gt;oom_adj;
struct task_cputime task_time;
unsigned long utime;
unsigned long stime;

if (oom_adj == OOM_DISABLE)
    return 0;

task_lock(p);
mm = p-&gt;mm;
if (!mm) {
    task_unlock(p);
    return 0;
}

/*
 * The memory size of the process is the basis for the badness.
 */
points = mm-&gt;total_vm;

/*
 * After this unlock we can no longer dereference local variable `mm'
 */
task_unlock(p);

/*
 * swapoff can easily use up all memory, so kill those first.
 */
if (p-&gt;flags &amp; PF_OOM_ORIGIN)
    return ULONG_MAX;

/*
 * Processes which fork a lot of child processes are likely
 * a good choice. We add half the vmsize of the children if they
 * have an own mm. This prevents forking servers to flood the
 * machine with an endless amount of children. In case a single
 * child is eating the vast majority of memory, adding only half
 * to the parents will make the child our kill candidate of choice.
 */
list_for_each_entry(child, &amp;p-&gt;children, sibling) {
    task_lock(child);
    if (child-&gt;mm != mm &amp;&amp; child-&gt;mm)
        points += child-&gt;mm-&gt;total_vm/2 + 1;
    task_unlock(child);
}

/*
 * CPU time is in tens of seconds and run time is in thousands
     * of seconds. There is no particular reason for this other than
     * that it turned out to work very well in practice.
 */
thread_group_cputime(p, &amp;task_time);
utime = cputime_to_jiffies(task_time.utime);
stime = cputime_to_jiffies(task_time.stime);
cpu_time = (utime + stime) &gt;&gt; (SHIFT_HZ + 3);


if (uptime &gt;= p-&gt;start_time.tv_sec)
    run_time = (uptime - p-&gt;start_time.tv_sec) &gt;&gt; 10;
else
    run_time = 0;

if (cpu_time)
    points /= int_sqrt(cpu_time);
if (run_time)
    points /= int_sqrt(int_sqrt(run_time));

/*
 * Niced processes are most likely less important, so double
 * their badness points.
 */
if (task_nice(p) &gt; 0)
    points *= 2;

/*
 * Superuser processes are usually more important, so we make it
 * less likely that we kill those.
 */
if (has_capability_noaudit(p, CAP_SYS_ADMIN) ||
    has_capability_noaudit(p, CAP_SYS_RESOURCE))
    points /= 4;

/*
 * We don't want to kill a process with direct hardware access.
 * Not only could that mess up the hardware, but usually users
 * tend to only have this flag set on applications they think
 * of as important.
 */
if (has_capability_noaudit(p, CAP_SYS_RAWIO))
    points /= 4;

/*
 * If p's nodes don't overlap ours, it may still help to kill p
 * because p may have allocated or otherwise mapped memory on
 * this node before. However it will be less likely.
 */
if (!has_intersects_mems_allowed(p))
    points /= 8;

/*
 * Adjust the score by oom_adj.
 */
if (oom_adj) {
    if (oom_adj &gt; 0) {
        if (!points)
            points = 1;
        points &lt;&lt;= oom_adj;
    } else
        points &gt;&gt;= -(oom_adj);
}
</code></pre>

<h1>ifdef DEBUG</h1>

<pre><code>printk(KERN_DEBUG "OOMkill: task %d (%s) got %lu points\n",
p-&gt;pid, p-&gt;comm, points);
</code></pre>

<h1>endif</h1>

<pre><code>return points;
</code></pre>

<p>}
```</p>

<h2>物理内存到底去哪了？</h2>

<h3>DirectByteBuffer冰山对象？</h3>

<p>这是我们查这个问题首先要想到的一个地方，是否是因为什么地方不断创建DirectByteBuffer对象，但是由于没有被回收导致了内存泄露呢，之前有篇文章已经详细介绍了这种特殊对象<a href="http://lovestblog.cn/blog/2015/05/12/direct-buffer/">JVM源码分析之堆外内存完全解读</a>，对阿里内部的童鞋，可以直接使用zprofiler的heap视图里的堆外内存分析功能拿到统计结果，知道后台到底绑定了多少堆外内存还没有被回收：</p>

<p><code>
object  position    limit   capacity
 java.nio.DirectByteBuffer @ 0x760afaed0    133 133 6380562
 java.nio.DirectByteBuffer @ 0x790d51ae0    0   262144  262144
 java.nio.DirectByteBuffer @ 0x790d20b80    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x790d20b40    0   262144  262144
 java.nio.DirectByteBuffer @ 0x790d20b00    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x771ba3608    0   262144  262144
 java.nio.DirectByteBuffer @ 0x771ba35c8    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x7c5c9e250    0   131072  131072
 java.nio.DirectByteBuffer @ 0x7c5c9e210    74670   74670   131072
 java.nio.DirectByteBuffer @ 0x7c185cd10    0   131072  131072
 java.nio.DirectByteBuffer @ 0x7c185ccd0    98965   98965   131072
 java.nio.DirectByteBuffer @ 0x7b181c980    65627   65627   131072
 java.nio.DirectByteBuffer @ 0x7a40d6e40    0   131072  131072
 java.nio.DirectByteBuffer @ 0x794ac3320    0   131072  131072
 java.nio.DirectByteBuffer @ 0x794a7a418    80490   80490   131072
 java.nio.DirectByteBuffer @ 0x77279e1d8    0   131072  131072
 java.nio.DirectByteBuffer @ 0x77279dde8    65627   65627   131072
 java.nio.DirectByteBuffer @ 0x76ea84000    0   131072  131072
 java.nio.DirectByteBuffer @ 0x76ea83fc0    82549   82549   131072
 java.nio.DirectByteBuffer @ 0x764d8d678    0   0   131072
 java.nio.DirectByteBuffer @ 0x764d8d638    0   0   131072
 java.nio.DirectByteBuffer @ 0x764d8d5f8    0   0   131072
 java.nio.DirectByteBuffer @ 0x761a76340    0   131072  131072
 java.nio.DirectByteBuffer @ 0x761a76300    74369   74369   131072
 java.nio.DirectByteBuffer @ 0x7607423d0    0   131072  131072
 总共: 25 / 875 条目; 还有850条,双击展开 1267762 3826551 12083282
</code></p>

<h3>某个动态库里频繁分配？</h3>

<p>对于动态库里频繁分配的问题，主要得使用google的perftools工具了，该工具网上介绍挺多的，就不对其用法做详细介绍了，通过该工具我们能得到native方法分配内存的情况，该工具主要利用了unix的一个环境变量LD_PRELOAD，它允许你要加载的动态库优先加载起来，相当于一个Hook了，于是可以针对同一个函数可以选择不同的动态库里的实现了，比如googleperftools就是将malloc方法替换成了tcmalloc的实现，这样就可以跟踪内存分配路径了，得到的效果类似如下：</p>

<p>```
Total: 1670.0 MB
  1616.3  96.8%  96.8%   1616.3  96.8% zcalloc</p>

<pre><code>40.3   2.4%  99.2%     40.3   2.4% os::malloc
 9.4   0.6%  99.8%      9.4   0.6% init
 1.6   0.1%  99.9%      1.7   0.1% readCEN
 1.3   0.1%  99.9%      1.3   0.1% ObjectSynchronizer::omAlloc
 0.5   0.0% 100.0%   1591.0  95.3% Java_java_util_zip_Deflater_init
 0.1   0.0% 100.0%      0.1   0.0% _dl_allocate_tls
 0.1   0.0% 100.0%      0.2   0.0% addMetaName
 0.1   0.0% 100.0%      0.2   0.0% allocZip
 0.1   0.0% 100.0%      0.1   0.0% instanceKlass::add_dependent_nmethod
 0.1   0.0% 100.0%      0.1   0.0% newEntry
 0.0   0.0% 100.0%      0.0   0.0% strdup
 0.0   0.0% 100.0%     25.8   1.5% Java_java_util_zip_Inflater_init
 0.0   0.0% 100.0%      0.0   0.0% growMetaNames
 0.0   0.0% 100.0%      0.0   0.0% _dl_new_object
 0.0   0.0% 100.0%      0.0   0.0% pthread_cond_wait@GLIBC_2.2.5
 0.0   0.0% 100.0%      1.4   0.1% Thread::Thread
 0.0   0.0% 100.0%      0.0   0.0% pthread_cond_timedwait@GLIBC_2.2.5
 0.0   0.0% 100.0%      0.0   0.0% JLI_MemAlloc
 0.0   0.0% 100.0%      0.0   0.0% read_alias_file
 0.0   0.0% 100.0%      0.0   0.0% _nl_intern_locale_data
 0.0   0.0% 100.0%      0.0   0.0% nss_parse_service_list
 0.0   0.0% 100.0%      0.0   0.0% getprotobyname
 0.0   0.0% 100.0%      0.0   0.0% getpwuid
 0.0   0.0% 100.0%      0.0   0.0% _dl_check_map_versions
 0.0   0.0% 100.0%   1590.5  95.2% deflateInit2_
</code></pre>

<p>```</p>

<p>从上面的输出中我们看到了<code>zcalloc</code>函数总共分配了1616.3M的内存，还有<code>Java_java_util_zip_Deflater_init</code>分配了1591.0M内存，<code>deflateInit2_</code>分配了1590.5M，然而总共才分配了1670.0M内存，所以这几个函数肯定是调用者和被调用者的关系：</p>

<p>```
JNIEXPORT jlong JNICALL
Java_java_util_zip_Deflater_init(JNIEnv *env, jclass cls, jint level,</p>

<pre><code>                             jint strategy, jboolean nowrap)
</code></pre>

<p>{</p>

<pre><code>z_stream *strm = calloc(1, sizeof(z_stream));

if (strm == 0) {
    JNU_ThrowOutOfMemoryError(env, 0);
    return jlong_zero;
} else {
    char *msg;
    switch (deflateInit2(strm, level, Z_DEFLATED,
                         nowrap ? -MAX_WBITS : MAX_WBITS,
                         DEF_MEM_LEVEL, strategy)) {
      case Z_OK:
        return ptr_to_jlong(strm);
      case Z_MEM_ERROR:
        free(strm);
        JNU_ThrowOutOfMemoryError(env, 0);
        return jlong_zero;
      case Z_STREAM_ERROR:
        free(strm);
        JNU_ThrowIllegalArgumentException(env, 0);
        return jlong_zero;
      default:
        msg = strm-&gt;msg;
        free(strm);
        JNU_ThrowInternalError(env, msg);
        return jlong_zero;
    }
}
</code></pre>

<p>}</p>

<p>int ZEXPORT deflateInit2_(strm, level, method, windowBits, memLevel, strategy,</p>

<pre><code>              version, stream_size)
z_streamp strm;
int  level;
int  method;
int  windowBits;
int  memLevel;
int  strategy;
const char *version;
int stream_size;
</code></pre>

<p>{</p>

<pre><code>deflate_state *s;
int wrap = 1;
static const char my_version[] = ZLIB_VERSION;

ushf *overlay;
/* We overlay pending_buf and d_buf+l_buf. This works since the average
 * output size for (length,distance) codes is &lt;= 24 bits.
 */

if (version == Z_NULL || version[0] != my_version[0] ||
    stream_size != sizeof(z_stream)) {
    return Z_VERSION_ERROR;
}
if (strm == Z_NULL) return Z_STREAM_ERROR;

strm-&gt;msg = Z_NULL;
if (strm-&gt;zalloc == (alloc_func)0) {
    strm-&gt;zalloc = zcalloc;
    strm-&gt;opaque = (voidpf)0;
}
if (strm-&gt;zfree == (free_func)0) strm-&gt;zfree = zcfree;
</code></pre>

<h1>ifdef FASTEST</h1>

<pre><code>if (level != 0) level = 1;
</code></pre>

<h1>else</h1>

<pre><code>if (level == Z_DEFAULT_COMPRESSION) level = 6;
</code></pre>

<h1>endif</h1>

<pre><code>if (windowBits &lt; 0) { /* suppress zlib wrapper */
    wrap = 0;
    windowBits = -windowBits;
}
</code></pre>

<h1>ifdef GZIP</h1>

<pre><code>else if (windowBits &gt; 15) {
    wrap = 2;       /* write gzip wrapper instead */
    windowBits -= 16;
}
</code></pre>

<h1>endif</h1>

<pre><code>if (memLevel &lt; 1 || memLevel &gt; MAX_MEM_LEVEL || method != Z_DEFLATED ||
    windowBits &lt; 8 || windowBits &gt; 15 || level &lt; 0 || level &gt; 9 ||
    strategy &lt; 0 || strategy &gt; Z_FIXED) {
    return Z_STREAM_ERROR;
}
if (windowBits == 8) windowBits = 9;  /* until 256-byte window bug fixed */
s = (deflate_state *) ZALLOC(strm, 1, sizeof(deflate_state));
if (s == Z_NULL) return Z_MEM_ERROR;
strm-&gt;state = (struct internal_state FAR *)s;
s-&gt;strm = strm;

s-&gt;wrap = wrap;
s-&gt;gzhead = Z_NULL;
s-&gt;w_bits = windowBits;
s-&gt;w_size = 1 &lt;&lt; s-&gt;w_bits;
s-&gt;w_mask = s-&gt;w_size - 1;

s-&gt;hash_bits = memLevel + 7;
s-&gt;hash_size = 1 &lt;&lt; s-&gt;hash_bits;
s-&gt;hash_mask = s-&gt;hash_size - 1;
s-&gt;hash_shift =  ((s-&gt;hash_bits+MIN_MATCH-1)/MIN_MATCH);

s-&gt;window = (Bytef *) ZALLOC(strm, s-&gt;w_size, 2*sizeof(Byte));
s-&gt;prev   = (Posf *)  ZALLOC(strm, s-&gt;w_size, sizeof(Pos));
s-&gt;head   = (Posf *)  ZALLOC(strm, s-&gt;hash_size, sizeof(Pos));

s-&gt;lit_bufsize = 1 &lt;&lt; (memLevel + 6); /* 16K elements by default */

overlay = (ushf *) ZALLOC(strm, s-&gt;lit_bufsize, sizeof(ush)+2);
s-&gt;pending_buf = (uchf *) overlay;
s-&gt;pending_buf_size = (ulg)s-&gt;lit_bufsize * (sizeof(ush)+2L);

if (s-&gt;window == Z_NULL || s-&gt;prev == Z_NULL || s-&gt;head == Z_NULL ||
    s-&gt;pending_buf == Z_NULL) {
    s-&gt;status = FINISH_STATE;
    strm-&gt;msg = (char*)ERR_MSG(Z_MEM_ERROR);
    deflateEnd (strm);
    return Z_MEM_ERROR;
}
s-&gt;d_buf = overlay + s-&gt;lit_bufsize/sizeof(ush);
s-&gt;l_buf = s-&gt;pending_buf + (1+sizeof(ush))*s-&gt;lit_bufsize;

s-&gt;level = level;
s-&gt;strategy = strategy;
s-&gt;method = (Byte)method;

return deflateReset(strm);
</code></pre>

<p>}
```</p>

<p>上述代码也验证了他们这种关系。</p>

<p>那现在的问题就是找出哪里调用<code>Java_java_util_zip_Deflater_init</code>了，从这方法的命名上知道它是一个java的native方法实现，对应的是<code>java.util.zip.Deflater</code>这个类的<code>init</code>方法，所以要知道<code>init</code>方法哪里被调用了，跟踪调用栈我们会想到btrace工具，但是btrace是通过插桩的方式来实现的，对于native方法是无法插桩的，于是我们看调用它的地方，找到对应的方法，然后进行btrace脚本编写：</p>

<p>```
import com.sun.btrace.annotations.<em>;
import static com.sun.btrace.BTraceUtils.</em>;</p>

<p>@BTrace public class Test {</p>

<pre><code>@OnMethod(
    clazz="java.util.zip.Deflater",
    method="&lt;init&gt;"
)
public static void onnewThread(int i,boolean b) {
    jstack();
 }
</code></pre>

<p>}</p>

<p>```</p>

<p>于是跟踪对应的进程，我们能抓到调用Deflater构造函数的堆栈</p>

<p><code>
org.apache.commons.compress.compressors.deflate.DeflateCompressorOutputStream.&lt;init&gt;(DeflateCompressorOutputStream.java:47)
com.xxx.unimsg.parse.util.CompressUtil.deflateCompressAndEncode(CompressUtil.java:199)
com.xxx.unimsg.parse.util.CompressUtil.compress(CompressUtil.java:80)
com.xxx.unimsg.UnifyMessageHelper.compressXml(UnifyMessageHelper.java:65)
com.xxx.core.model.utils.UnifyMessageUtil.compressXml(UnifyMessageUtil.java:56)
com.xxx.repository.convert.BatchInDetailConvert.convertDO(BatchInDetailConvert.java:57)
com.xxx.repository.impl.IncomingDetailRepositoryImpl$1.store(IncomingDetailRepositoryImpl.java:43)
com.xxx.repository.helper.IdempotenceHelper.store(IdempotenceHelper.java:27)
com.xxx.repository.impl.IncomingDetailRepositoryImpl.store(IncomingDetailRepositoryImpl.java:40)
sun.reflect.GeneratedMethodAccessor274.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
java.lang.reflect.Method.invoke(Method.java:597)
org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:309)
org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
com.alipay.finsupport.component.monitor.MethodMonitorInterceptor.invoke(MethodMonitorInterceptor.java:45)
org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
...
</code></p>

<p>从上面的堆栈我们找出了调用<code>java.util.zip.Deflate.init()</code>的地方</p>

<h2>问题解决</h2>

<p>上面已经定位了具体的代码了，于是再细致跟踪了下对应的代码，其实并不是代码实现上的问题，而是代码设计上没有考虑到流量很大的场景，当流量很大的时候，不管自己系统是否能承受这么大的压力，都来者不拒，拿到数据就做deflate，而这个过程是需要分配堆外内存的，当量达到一定程度的时候此时会发生oom killer，另外我们在分析过程中发现其实物理内存是有下降的</p>

<p><code>
30071.txt:     0.0   0.0% 100.0%     96.7  57.0% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    196.0  72.6% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    290.3  78.5% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    392.7  83.6% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    592.8  88.5% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    700.7  91.0% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    799.1  91.9% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    893.9  92.2% Java_java_util_zip_Deflater_init
30071.txt:     0.0   0.0%  99.9%    114.2  63.7% Java_java_util_zip_Deflater_init
30071.txt:     0.0   0.0% 100.0%    105.1  52.1% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    479.7  87.4% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    782.2  90.1% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    986.9  92.3% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1086.3  92.9% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1185.1  93.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    941.5  92.1% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0% 100.0%   1288.8  94.1% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1394.8  94.9% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1492.5  95.1% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1591.0  95.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    874.6  90.0% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    950.7  92.8% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    858.4  92.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    818.4  91.9% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    858.7  91.2% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    271.5  77.9% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1260.4  93.1% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    976.4  90.6% Java_java_util_zip_Deflater_init
</code></p>

<p>这也就说明了其实代码使用上并没有错，因此建议将deflate放到队列里去做，比如限制队列大小是100，每次最多100个数据可以被deflate，处理一个放进一个，以至于不会被活活撑死。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之FinalReference完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/07/09/final-reference/"/>
    <updated>2015-07-09T14:35:31+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/07/09/final-reference</id>
    <content type="html"><![CDATA[<p><code>注:文章首发于InfoQ：</code><a href="" title="http://www.infoq.com/cn/articles/jvm-source-code-analysis-finalreference">JVM源码分析之FinalReference</a></p>

<h2>概述</h2>

<p>JAVA对象引用体系除了强引用之外，出于对性能、可扩展性等方面考虑还特地实现了四种其他引用：SoftReference、WeakReference、PhantomReference、FinalReference，本文主要想讲的是FinalReference，因为我们在使用内存分析工具比如zprofiler、mat等在分析一些oom的heap的时候，经常能看到 <code>java.lang.ref.Finalizer</code>占用的内存大小远远排在前面，而这个类占用的内存大小又和我们这次的主角<code>FinalReference</code>有着密不可分的关系。</p>

<!--more-->


<p>对于FinalReference及关联的内容，我们可能有如下印象：
* 自己代码里从没有使用过
* 线程dump之后，我们能看到一个叫做<code>Finalizer</code>的java线程
* 偶尔能注意到<code>java.lang.ref.Finalizer</code>的存在
* 我们在类里可能会写finalize方法</p>

<p>那FinalReference到底存在的意义是什么，以怎样的形式和我们的代码相关联呢，这是本文要理清的问题。</p>

<h2>JDK中的FinalReference</h2>

<p>首先我们看看FinalReference在JDK里的实现：</p>

<p>```
class FinalReference<T> extends Reference<T> {</p>

<pre><code>public FinalReference(T referent, ReferenceQueue&lt;? super T&gt; q) {
    super(referent, q);
}
</code></pre>

<p>}
```</p>

<p>大家应该注意到了类访问权限是package的，这也就意味着我们不能直接去对其进行扩展，但是JDK里对此类进行了扩展实现<code>java.lang.ref.Finalizer</code>，这个类也是我们在概述里提到的，而此类的访问权限也是package的，并且是final的，意味着真的不能被扩展了，接下来的重点我们围绕<code>java.lang.ref.Finalizer</code>展开(PS：后续讲Finalizer相关的其实也就是在说FinalReference)</p>

<p>```
final class Finalizer extends FinalReference { /* Package-private; must be in</p>

<pre><code>                                              same package as the Reference
                                              class */

/* A native method that invokes an arbitrary object's finalize method is
   required since the finalize method is protected
 */
static native void invokeFinalizeMethod(Object o) throws Throwable;

private static ReferenceQueue queue = new ReferenceQueue();
private static Finalizer unfinalized = null;
private static final Object lock = new Object();

private Finalizer
    next = null,
    prev = null;

private Finalizer(Object finalizee) {
    super(finalizee, queue);
    add();
}

/* Invoked by VM */
static void register(Object finalizee) {
    new Finalizer(finalizee);
}  

private void add() {
    synchronized (lock) {
        if (unfinalized != null) {
            this.next = unfinalized;
            unfinalized.prev = this;
        }
        unfinalized = this;
    }
}

...
</code></pre>

<p>   }</p>

<p>```</p>

<h3>Finalizer的构造函数</h3>

<p>从构造函数上我们获得下面的几个关键信息
* private：意味着我们在外面无法自己构建这类对象
* finalizee参数：FinalReference指向的对象引用
* 调用add方法：将当前对象插入到Finalizer对象链里，链里的对象和Finalizer类静态相关联，言外之意是在这个链里的对象都无法被gc掉，除非将这种引用关系剥离掉（因为Finalizer类无法被unload）</p>

<p>虽然外面无法创建Finalizer对象，但是注意到有一个register的静态方法，在方法里会创建这种对象，同时将这个对象加入到Finalizer对象链里，这个方法是被vm调用的，那么问题来了，vm在什么情况下会调用这个方法呢？</p>

<h2>Finalizer对象何时被注册到Finalizer对象链里</h2>

<p>类其实有挺多的修饰，比如final，abstract，public等等，如果一个类有final修饰，我们就说这个类是一个final类，上面列的都是语法层面我们可以显示标记的，在jvm里其实还给类标记其他一些符号，比如finalizer，表示这个类是一个finalizer类（为了和java.lang.ref.Fianlizer类进行区分，下文要提到的finalizer类的地方都说成f类），gc在处理这种类的对象的时候要做一些特殊的处理，如在这个对象被回收之前会调用一下它的finalize方法。</p>

<h3>如何判断一个类是不是一个f类</h3>

<p>在讲这个问题之前，我们先来看下<code>java.lang.Object</code>里的一个方法</p>

<p>```</p>

<pre><code>protected void finalize() throws Throwable { }
</code></pre>

<p>```</p>

<p>在Object类里定义了一个名为finalize的空方法，这意味着Java世界里的所有类都会继承这个方法，甚至可以覆写该方法，并且根据方法覆写原则，如果子类覆盖此方法，方法访问权限都是至少是protected级别的，这样其子类就算没有覆写此方法也会继承此方法。</p>

<p>而判断当前类是否是一个f类的标准并不仅仅是当前类是否含有一个参数为空，返回值为void的名为finalize的方法，而另外一个要求是<code>finalize方法必须非空</code>，因此我们的Object类虽然含有一个finalize方法，但是并不是一个f类，Object的对象在被gc回收的时候其实并不会去调用它的finalize方法。</p>

<p>需要注意的是我们的类在被加载过程中其实就已经被标记为是否为f类了（遍历所有方法，包括父类的方法，只要有一个非空的参数为空返回void的finalize方法就认为是一个f类）。</p>

<h3>f类的对象何时传到Finalizer.register方法</h3>

<p>对象的创建其实是被拆分成多个步骤的，比如<code>A a=new A(2)</code>这样一条语句对应的字节码如下：</p>

<p><code>
0: new           #1                  // class A
3: dup
4: iconst_2
5: invokespecial #11                 // Method "&lt;init&gt;":(I)V
</code>
先执行new分配好对象空间，然后再执行invokespecial调用构造函数，jvm里其实可以让用户选择在这两个时机中的任意一个将当前对象传递给Finalizer.register方法来注册到Finalizer对象链里，这个选择依赖于RegisterFinalizersAtInit这个vm参数是否被设置，默认值为true，也就是在调用构造函数返回之前调用Finalizer.register方法，如果通过-XX:-RegisterFinalizersAtInit关闭了该参数，那将在对象空间分配好之后就将这个对象注册进去。</p>

<p>另外需要提一点的是当我们通过clone的方式复制一个对象的时候，如果当前类是一个f类，那么在clone完成的时候将调用Finalizer.register方法进行注册。</p>

<h3>hotspot如何实现f类对象在构造函数执行完毕后调用Finalizer.register</h3>

<p>这个实现比较有意思，在这里简单提一下，我们知道一个构造函数执行的时候，会去调用父类的构造函数，主要是为了能对继承自父类的属性也能做初始化，那么任何一个对象的初始化最终都会调用到Object的空构造函数里（任何空的构造函数其实并不空，会含有三条字节码指令，如下代码所示），为了不对所有的类的构造函数都做埋点调用Finalizer.register方法，hotspot的实现是在Object这个类在做初始化的时候将构造函数里的<code>return</code>指令替换为<code>_return_register_finalizer</code>指令，该指令并不是标准的字节码指令，是hotspot扩展的指令，这样在处理该指令的时候调用Finalizer.register方法，这样就在侵入性很小的情况下完美地解决了这个问题。</p>

<p><code>
0: aload_0
1: invokespecial #21                 // Method java/lang/Object."&lt;init&gt;":()V
4: return
</code></p>

<h2>f类对象的GC回收</h2>

<h3>FinalizerThread线程</h3>

<p>在Finalizer类的clinit方法（静态块）里我们看到它会创建了一个FinalizerThread的守护线程，这个线程的优先级并不是最高的，意味着在cpu很紧张的情况下其被调度的优先级可能会受到影响</p>

<p>```
  private static class FinalizerThread extends Thread {</p>

<pre><code>    private volatile boolean running;
    FinalizerThread(ThreadGroup g) {
        super(g, "Finalizer");
    }
    public void run() {
        if (running)
            return;
        running = true;
        for (;;) {
            try {
                Finalizer f = (Finalizer)queue.remove();
                f.runFinalizer();
            } catch (InterruptedException x) {
                continue;
            }
        }
    }
}

static {
    ThreadGroup tg = Thread.currentThread().getThreadGroup();
    for (ThreadGroup tgn = tg;
         tgn != null;
         tg = tgn, tgn = tg.getParent());
    Thread finalizer = new FinalizerThread(tg);
    finalizer.setPriority(Thread.MAX_PRIORITY - 2);
    finalizer.setDaemon(true);
    finalizer.start();
}
</code></pre>

<p>```
这个线程主要就是从queue里取Finalizer对象，然后执行该对象的runFinalizer方法，这个方法主要是将Finalizer对象从Finalizer对象链里剥离出来，这样意味着下次gc发生的时候就可能将其关联的f对象gc掉了，最后将这个Finalizer对象关联的f对象传给了一个native方法invokeFinalizeMethod</p>

<p>```
private void runFinalizer() {</p>

<pre><code>    synchronized (this) {
        if (hasBeenFinalized()) return;
        remove();
    }
    try {
        Object finalizee = this.get();
        if (finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) {
            invokeFinalizeMethod(finalizee);
            /* Clear stack slot containing this variable, to decrease
               the chances of false retention with a conservative GC */
            finalizee = null;
        }
    } catch (Throwable x) { }
    super.clear();
}
</code></pre>

<p> static native void invokeFinalizeMethod(Object o) throws Throwable;</p>

<p>```
其实invokeFinalizeMethod方法就是调了这个f对象的finalize方法，看到这里大家应该恍然大悟了，整个过程都串起来了</p>

<p>```
JNIEXPORT void JNICALL
Java_java_lang_ref_Finalizer_invokeFinalizeMethod(JNIEnv *env, jclass clazz,</p>

<pre><code>                                              jobject ob)
</code></pre>

<p>{</p>

<pre><code>jclass cls;
jmethodID mid;

cls = (*env)-&gt;GetObjectClass(env, ob);
if (cls == NULL) return;
mid = (*env)-&gt;GetMethodID(env, cls, "finalize", "()V");
if (mid == NULL) return;
(*env)-&gt;CallVoidMethod(env, ob, mid);
</code></pre>

<p>}
```</p>

<h3>f对象的finalize方法抛出异常会导致FinalizeThread退出吗</h3>

<p>不知道大家有没有想过如果f对象的finalize方法抛了一个没捕获的异常，这个FinalizerThread会不会退出呢，细心的读者看上面的代码其实就可以找到答案，在runFinalizer方法里对Throwable的异常都进行了捕获，因此不可能出现FinalizerThread因异常未捕获而退出的情况。</p>

<h3>f对象的finalize方法会执行多次吗</h3>

<p>如果我们在f对象的finalize方法里重新将当前对象赋值出去，变成可达对象，当这个f对象再次变成不可达的时候还会被执行finalize方法吗？答案是否定的，因为在执行完第一次finalize方法之后，这个f对象已经和之前的Finalizer对象关系剥离了，也就是下次gc的时候不会再发现Finalizer对象指向该f对象了，自然也就不会调用这个f对象的finalize方法了。</p>

<h3>Finalizer对象何时被放到ReferenceQueue里</h3>

<p>除了这里要说的环节之外，整个过程大家应该都比较清楚了。</p>

<p>当gc发生的时候，gc算法会判断f类对象是不是只被Finalizer类引用（f类对象被Finalizer对象引用，然后放到Finalizer对象链里），如果这个类仅仅被Finalizer对象引用的时候，说明这个对象在不久的将来会被回收了现在可以执行它的finalize方法了，于是会将这个Finalizer对象放到Finalizer类的ReferenceQueue里，但是这个f类对象其实并没有被回收，因为Finalizer这个类还对他们持有引用，在gc完成之前，jvm会调用ReferenceQueue里的lock对象的notify方法（当ReferenceQueue为空的时候，FinalizerThread线程会调用ReferenceQueue的lock对象的wait方法直到被jvm唤醒），此时就会执行上面FinalizeThread线程里看到的其他逻辑了。</p>

<h2>Finalizer导致的内存泄露</h2>

<p>这里举一个简单的例子，我们使用挺广的socket通信，SocksSocketImpl的父类其实就实现了finalize方法:
```
/<em>*
 * Cleans up if the user forgets to close it.
 </em>/
protected void finalize() throws IOException {</p>

<pre><code>close();
</code></pre>

<p>}
```
其实这么做的主要目的是万一用户忘记关闭socket了，那么在这个对象被回收的时候能主动关闭socket来释放一些系统资源，但是如果真的是用户忘记关闭了，那这些socket对象可能因为FinalizeThread迟迟没有执行到这些socket对象的finalize方法，而导致内存泄露，这种问题我们碰到过多次，因此对于这类情况除了大家好好注意貌似没有什么更好的方法了，该做的事真不能省.</p>

<h2>Finalizer的客观评价</h2>

<p>上面的过程基本对Finalizer的实现细节进行完整剖析了，java里我们看到有构造函数，但是并没有看到析构函数一说，Finalizer其实是实现了析构函数的概念，我们在对象被回收前可以执行一些『收拾性』的逻辑，应该说是一个特殊场景的补充，但是这种概念的实现给我们的f对象生命周期以及gc等带来了一些影响：
* f对象因为Finalizer的引用而变成了一个临时的强引用，即使没有其他的强引用了，还是无法立即被回收
* f对象至少经历两次GC才能被回收，因为只有在FinalizerThread执行完了f对象的finalize方法的情况下才有可能被下次gc回收，而有可能期间已经经历过多次gc了，但是一直还没执行f对象的finalize方法
* cpu资源比较稀缺的情况下FinalizerThread线程有可能因为优先级比较低而延迟执行f对象的finalize方法
* 因为f对象的finalize方法迟迟没有执行，有可能会导致大部分f对象进入到old分代，此时容易引发old分代的gc，甚至fullgc，gc暂停时间明显变长
* f对象的finalize方法被调用了，但是这个对象其实还并没有被回收，虽然可能在不久的将来会被回收</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之堆外内存完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/05/12/direct-buffer/"/>
    <updated>2015-05-12T13:49:57+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/05/12/direct-buffer</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<h3>广义的堆外内存</h3>

<p>说到堆外内存，那大家肯定想到堆内内存，这也是我们大家接触最多的，我们在jvm参数里通常设置-Xmx来指定我们的堆的最大值，不过这还不是我们理解的Java堆，-Xmx的值是新生代和老生代的和的最大值，我们在jvm参数里通常还会加一个参数-XX:MaxPermSize来指定持久代的最大值，那么我们认识的Java堆的最大值其实是-Xmx和-XX:MaxPermSize的总和，在分代算法下，新生代，老生代和持久代是连续的虚拟地址，因为它们是一起分配的，那么剩下的都可以认为是堆外内存(广义的)了，这些包括了jvm本身在运行过程中分配的内存，codecache，jni里分配的内存，DirectByteBuffer分配的内存等等</p>

<h3>狭义的堆外内存</h3>

<p>而作为java开发者，我们常说的堆外内存溢出了，其实是狭义的堆外内存，这个主要是指java.nio.DirectByteBuffer在创建的时候分配内存，我们这篇文章里也主要是讲狭义的堆外内存，因为它和我们平时碰到的问题比较密切</p>

<!--more-->


<h2>JDK/JVM里DirectByteBuffer的实现</h2>

<p>DirectByteBuffer通常用在通信过程中做缓冲池，在mina，netty等nio框架中屡见不鲜，先来看看JDK里的实现：</p>

<p>```</p>

<pre><code>DirectByteBuffer(int cap) {                   // package-private

    super(-1, 0, cap, cap);
    boolean pa = VM.isDirectMemoryPageAligned();
    int ps = Bits.pageSize();
    long size = Math.max(1L, (long)cap + (pa ? ps : 0));
    Bits.reserveMemory(size, cap);

    long base = 0;
    try {
        base = unsafe.allocateMemory(size);
    } catch (OutOfMemoryError x) {
        Bits.unreserveMemory(size, cap);
        throw x;
    }
    unsafe.setMemory(base, size, (byte) 0);
    if (pa &amp;&amp; (base % ps != 0)) {
        // Round up to page boundary
        address = base + ps - (base &amp; (ps - 1));
    } else {
        address = base;
    }
    cleaner = Cleaner.create(this, new Deallocator(base, size, cap));
    att = null;



}
</code></pre>

<p>```
通过上面的构造函数我们知道，真正的内存分配是使用的Bits.reserveMemory方法</p>

<p>```</p>

<pre><code>static void reserveMemory(long size, int cap) {
    synchronized (Bits.class) {
        if (!memoryLimitSet &amp;&amp; VM.isBooted()) {
            maxMemory = VM.maxDirectMemory();
            memoryLimitSet = true;
        }
        // -XX:MaxDirectMemorySize limits the total capacity rather than the
        // actual memory usage, which will differ when buffers are page
        // aligned.
        if (cap &lt;= maxMemory - totalCapacity) {
            reservedMemory += size;
            totalCapacity += cap;
            count++;
            return;
        }
    }

    System.gc();
    try {
        Thread.sleep(100);
    } catch (InterruptedException x) {
        // Restore interrupt status
        Thread.currentThread().interrupt();
    }
    synchronized (Bits.class) {
        if (totalCapacity + cap &gt; maxMemory)
            throw new OutOfMemoryError("Direct buffer memory");
        reservedMemory += size;
        totalCapacity += cap;
        count++;
    }

}
</code></pre>

<p>```
通过上面的代码我们知道可以通过-XX:MaxDirectMemorySize来指定最大的堆外内存，那么我们首先引入两个问题</p>

<ul>
<li>堆外内存默认是多大</li>
<li>为什么要主动调用System.gc()</li>
</ul>


<h3>堆外内存默认是多大</h3>

<p>如果我们没有通过-XX:MaxDirectMemorySize来指定最大的堆外内存，那么默认的最大堆外内存是多少呢，我们还是通过代码来分析</p>

<p>上面的代码里我们看到调用了sun.misc.VM.maxDirectMemory()</p>

<p>```
 private static long directMemory = 64 * 1024 * 1024;</p>

<pre><code>// Returns the maximum amount of allocatable direct buffer memory.
// The directMemory variable is initialized during system initialization
// in the saveAndRemoveProperties method.
//
public static long maxDirectMemory() {
    return directMemory;
}
</code></pre>

<p>```
看到上面的代码之后是不是误以为默认的最大值是64M？其实不是的，说到这个值得从java.lang.System这个类的初始化说起</p>

<p>```
 /**</p>

<pre><code> * Initialize the system class.  Called after thread initialization.
 */
private static void initializeSystemClass() {

    // VM might invoke JNU_NewStringPlatform() to set those encoding
    // sensitive properties (user.home, user.name, boot.class.path, etc.)
    // during "props" initialization, in which it may need access, via
    // System.getProperty(), to the related system encoding property that
    // have been initialized (put into "props") at early stage of the
    // initialization. So make sure the "props" is available at the
    // very beginning of the initialization and all system properties to
    // be put into it directly.
    props = new Properties();
    initProperties(props);  // initialized by the VM

    // There are certain system configurations that may be controlled by
    // VM options such as the maximum amount of direct memory and
    // Integer cache size used to support the object identity semantics
    // of autoboxing.  Typically, the library will obtain these values
    // from the properties set by the VM.  If the properties are for
    // internal implementation use only, these properties should be
    // removed from the system properties.
    //
    // See java.lang.Integer.IntegerCache and the
    // sun.misc.VM.saveAndRemoveProperties method for example.
    //
    // Save a private copy of the system properties object that
    // can only be accessed by the internal implementation.  Remove
    // certain system properties that are not intended for public access.
    sun.misc.VM.saveAndRemoveProperties(props);

     ......

    sun.misc.VM.booted();
}
</code></pre>

<p><code>``
上面这个方法在jvm启动的时候对System这个类做初始化的时候执行的，因此执行时间非常早，我们看到里面调用了</code>sun.misc.VM.saveAndRemoveProperties(props)`:</p>

<p>```</p>

<pre><code>public static void saveAndRemoveProperties(Properties props) {
    if (booted)
        throw new IllegalStateException("System initialization has completed");

    savedProps.putAll(props);

    // Set the maximum amount of direct memory.  This value is controlled
    // by the vm option -XX:MaxDirectMemorySize=&lt;size&gt;.
    // The maximum amount of allocatable direct buffer memory (in bytes)
    // from the system property sun.nio.MaxDirectMemorySize set by the VM.
    // The system property will be removed.
    String s = (String)props.remove("sun.nio.MaxDirectMemorySize");
    if (s != null) {
        if (s.equals("-1")) {
            // -XX:MaxDirectMemorySize not given, take default
            directMemory = Runtime.getRuntime().maxMemory();
        } else {
            long l = Long.parseLong(s);
            if (l &gt; -1)
                directMemory = l;
        }
    }

    // Check if direct buffers should be page aligned
    s = (String)props.remove("sun.nio.PageAlignDirectMemory");
    if ("true".equals(s))
        pageAlignDirectMemory = true;

    // Set a boolean to determine whether ClassLoader.loadClass accepts
    // array syntax.  This value is controlled by the system property
    // "sun.lang.ClassLoader.allowArraySyntax".
    s = props.getProperty("sun.lang.ClassLoader.allowArraySyntax");
    allowArraySyntax = (s == null
                           ? defaultAllowArraySyntax
                           : Boolean.parseBoolean(s));

    // Remove other private system properties
    // used by java.lang.Integer.IntegerCache
    props.remove("java.lang.Integer.IntegerCache.high");

    // used by java.util.zip.ZipFile
    props.remove("sun.zip.disableMemoryMapping");

    // used by sun.launcher.LauncherHelper
    props.remove("sun.java.launcher.diag");
}
</code></pre>

<p>```</p>

<p>如果我们通过-Dsun.nio.MaxDirectMemorySize指定了这个属性，只要它不等于-1，那效果和加了-XX:MaxDirectMemorySize一样的，如果两个参数都没指定，那么最大堆外内存的值来自于<code>directMemory = Runtime.getRuntime().maxMemory()</code>，这是一个native方法</p>

<p>```
JNIEXPORT jlong JNICALL
Java_java_lang_Runtime_maxMemory(JNIEnv *env, jobject this)
{</p>

<pre><code>return JVM_MaxMemory();
</code></pre>

<p>}</p>

<p>JVM_ENTRY_NO_ENV(jlong, JVM_MaxMemory(void))
  JVMWrapper("JVM_MaxMemory");
  size_t n = Universe::heap()->max_capacity();
  return convert_size_t_to_jlong(n);
JVM_END</p>

<p>```
其中在我们使用CMS GC的情况下的实现如下，其实是新生代的最大值-一个survivor的大小+老生代的最大值，也就是我们设置的-Xmx的值里除去一个survivor的大小就是默认的堆外内存的大小了</p>

<p>```
size_t GenCollectedHeap::max_capacity() const {
  size_t res = 0;
  for (int i = 0; i &lt; _n_gens; i++) {</p>

<pre><code>res += _gens[i]-&gt;max_capacity();
</code></pre>

<p>  }
  return res;
}</p>

<p>size_t DefNewGeneration::max_capacity() const {
  const size_t alignment = GenCollectedHeap::heap()->collector_policy()->min_alignment();
  const size_t reserved_bytes = reserved().byte_size();
  return reserved_bytes - compute_survivor_size(reserved_bytes, alignment);
}</p>

<p>size_t Generation::max_capacity() const {
  return reserved().byte_size();
}
```</p>

<h3>为什么要主动调用System.gc</h3>

<p>既然要调用System.gc，那肯定是想通过触发一次gc操作来回收堆外内存，不过我想先说的是堆外内存不会对gc造成什么影响(这里的System.gc除外)，但是堆外内存的回收其实依赖于我们的gc机制，首先我们要知道在java层面和我们在堆外分配的这块内存关联的只有与之关联的DirectByteBuffer对象了，它记录了这块内存的基地址以及大小，那么既然和gc也有关，那就是gc能通过操作DirectByteBuffer对象来间接操作对应的堆外内存了。DirectByteBuffer对象在创建的时候关联了一个PhantomReference，说到PhantomReference它其实主要是用来跟踪对象何时被回收的，它不能影响gc决策，但是gc过程中如果发现某个对象除了只有PhantomReference引用它之外，并没有其他的地方引用它了，那将会把这个引用放到java.lang.ref.Reference.pending队列里，在gc完毕的时候通知ReferenceHandler这个守护线程去执行一些后置处理，而DirectByteBuffer关联的PhantomReference是PhantomReference的一个子类，在最终的处理里会通过Unsafe的free接口来释放DirectByteBuffer对应的堆外内存块</p>

<p>JDK里ReferenceHandler的实现：</p>

<p>```
 private static class ReferenceHandler extends Thread {</p>

<pre><code>    ReferenceHandler(ThreadGroup g, String name) {
        super(g, name);
    }

    public void run() {
        for (;;) {

            Reference r;
            synchronized (lock) {
                if (pending != null) {
                    r = pending;
                    Reference rn = r.next;
                    pending = (rn == r) ? null : rn;
                    r.next = r;
                } else {
                    try {
                        lock.wait();
                    } catch (InterruptedException x) { }
                    continue;
                }
            }

            // Fast path for cleaners
            if (r instanceof Cleaner) {
                ((Cleaner)r).clean();
                continue;
            }

            ReferenceQueue q = r.queue;
            if (q != ReferenceQueue.NULL) q.enqueue(r);
        }
    }
}
</code></pre>

<p>```</p>

<p>可见如果pending为空的时候，会通过lock.wait()一直等在那里，其中唤醒的动作是在jvm里做的，当gc完成之后会调用如下的方法VM_GC_Operation::doit_epilogue()，在方法末尾会调用lock的notify操作，至于pending队列什么时候将引用放进去的，其实是在gc的引用处理逻辑中放进去的，针对引用的处理后面可以专门写篇文章来介绍</p>

<p>```
void VM_GC_Operation::doit_epilogue() {
  assert(Thread::current()->is_Java_thread(), "just checking");
  // Release the Heap_lock first.
  SharedHeap* sh = SharedHeap::heap();
  if (sh != NULL) sh->_thread_holds_heap_lock_for_gc = false;
  Heap_lock->unlock();
  release_and_notify_pending_list_lock();
}</p>

<p>void VM_GC_Operation::release_and_notify_pending_list_lock() {
instanceRefKlass::release_and_notify_pending_list_lock(&amp;_pending_list_basic_lock);
}</p>

<p>```</p>

<p>对于System.gc的实现，之前写了一篇文章来重点介绍，<a href="http://lovestblog.cn/blog/2015/05/07/system-gc/">JVM源码分析之SystemGC完全解读</a>，它会对新生代的老生代都会进行内存回收，这样会比较彻底地回收DirectByteBuffer对象以及他们关联的堆外内存，我们dump内存发现DirectByteBuffer对象本身其实是很小的，但是它后面可能关联了一个非常大的堆外内存，因此我们通常称之为『冰山对象』，我们做ygc的时候会将新生代里的不可达的DirectByteBuffer对象及其堆外内存回收了，但是无法对old里的DirectByteBuffer对象及其堆外内存进行回收，这也是我们通常碰到的最大的问题，如果有大量的DirectByteBuffer对象移到了old，但是又一直没有做cms gc或者full gc，而只进行ygc，那么我们的物理内存可能被慢慢耗光，但是我们还不知道发生了什么，因为heap明明剩余的内存还很多(前提是我们禁用了System.gc)。</p>

<h2>为什么要使用堆外内存</h2>

<p>DirectByteBuffer在创建的时候会通过Unsafe的native方法来直接使用malloc分配一块内存，这块内存是heap之外的，那么自然也不会对gc造成什么影响(System.gc除外)，因为gc耗时的操作主要是操作heap之内的对象，对这块内存的操作也是直接通过Unsafe的native方法来操作的，相当于DirectByteBuffer仅仅是一个壳，还有我们通信过程中如果数据是在Heap里的，最终也还是会copy一份到堆外，然后再进行发送，所以为什么不直接使用堆外内存呢。对于需要频繁操作的内存，并且仅仅是临时存在一会的，都建议使用堆外内存，并且做成缓冲池，不断循环利用这块内存。</p>

<h2>为什么不能大面积使用堆外内存</h2>

<p>如果我们大面积使用堆外内存并且没有限制，那迟早会导致内存溢出，毕竟程序是跑在一台资源受限的机器上，因为这块内存的回收不是你直接能控制的，当然你可以通过别的一些途径，比如反射，直接使用Unsafe接口等，但是这些务必给你带来了一些烦恼，Java与生俱来的优势被你完全抛弃了---开发不需要关注内存的回收，由gc算法自动去实现。另外上面的gc机制与堆外内存的关系也说了，如果一直触发不了cms gc或者full gc，那么后果可能很严重。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之SystemGC完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/05/07/system-gc/"/>
    <updated>2015-05-07T20:02:51+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/05/07/system-gc</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>JVM的GC一般情况下是JVM本身根据一定的条件触发的，不过我们还是可以做一些人为的触发，比如通过jvmti做强制GC，通过System.gc触发，还可以通过jmap来触发等，针对每个场景其实我们都可以写篇文章来做一个介绍，本文重点介绍下System.gc的原理</p>

<!--more-->


<p>或许大家已经知道如下相关的知识</p>

<ul>
<li>system.gc其实是做一次full gc</li>
<li>system.gc会暂停整个进程</li>
<li>system.gc一般情况下我们要禁掉，使用-XX:+DisableExplicitGC</li>
<li>system.gc在cms gc下我们通过-XX:+ExplicitGCInvokesConcurrent来做一次稍微高效点的GC(效果比Full GC要好些)</li>
<li>system.gc最常见的场景是RMI/NIO下的堆外内存分配等</li>
</ul>


<p>如果你已经知道上面这些了其实也说明你对System.gc有过一定的了解，至少踩过一些坑，但是你是否更深层次地了解过它，比如</p>

<ul>
<li>为什么CMS GC下-XX:+ExplicitGCInvokesConcurrent这个参数加了之后会比真正的Full GC好？</li>
<li>它如何做到暂停整个进程？</li>
<li>堆外内存分配为什么有时候要配合System.gc？</li>
</ul>


<p>如果你上面这些疑惑也都知道，那说明你很懂System.gc了，那么接下来的文字你可以不用看啦</p>

<h2>JDK里的System.gc的实现</h2>

<p>先贴段代码吧（java.lang.System）</p>

<p>```</p>

<pre><code>/**
 * Runs the garbage collector.
 * &lt;p&gt;
 * Calling the &lt;code&gt;gc&lt;/code&gt; method suggests that the Java Virtual
 * Machine expend effort toward recycling unused objects in order to
 * make the memory they currently occupy available for quick reuse.
 * When control returns from the method call, the Java Virtual
 * Machine has made a best effort to reclaim space from all discarded
 * objects.
 * &lt;p&gt;
 * The call &lt;code&gt;System.gc()&lt;/code&gt; is effectively equivalent to the
 * call:
 * &lt;blockquote&gt;&lt;pre&gt;
 * Runtime.getRuntime().gc()
 * &lt;/pre&gt;&lt;/blockquote&gt;
 *
 * @see     java.lang.Runtime#gc()
 */
public static void gc() {
    Runtime.getRuntime().gc();
}
</code></pre>

<p>```
发现主要调用的是Runtime里的gc方法（java.lang.Runtime）</p>

<p>```</p>

<pre><code>/**
 * Runs the garbage collector.
 * Calling this method suggests that the Java virtual machine expend
 * effort toward recycling unused objects in order to make the memory
 * they currently occupy available for quick reuse. When control
 * returns from the method call, the virtual machine has made
 * its best effort to recycle all discarded objects.
 * &lt;p&gt;
 * The name &lt;code&gt;gc&lt;/code&gt; stands for "garbage
 * collector". The virtual machine performs this recycling
 * process automatically as needed, in a separate thread, even if the
 * &lt;code&gt;gc&lt;/code&gt; method is not invoked explicitly.
 * &lt;p&gt;
 * The method {@link System#gc()} is the conventional and convenient
 * means of invoking this method.
 */
public native void gc();
</code></pre>

<p>```
这里看到gc方法是native的，在java层面只能到此结束了，代码只有这么多，要了解更多，可以看方法上面的注释，不过我们需要更深层次地来了解其实现，那还是准备好进入到jvm里去看看</p>

<h2>Hotspot里System.gc的实现</h2>

<h3>如何找到native里的实现</h3>

<p>上面提到了Runtime.gc是一个本地方法，那需要先在jvm里找到对应的实现，这里稍微提一下jvm里native方法最常见的也是最简单的查找，jdk里一般含有native方法的类，一般都会有一个对应的c文件，比如上面的java.lang.Runtime这个类，会有一个Runtime.c的文件和它对应，native方法的具体实现都在里面了，如果你有source，可能会猜到和下面的方法对应</p>

<p>```
JNIEXPORT void JNICALL
Java_java_lang_Runtime_gc(JNIEnv *env, jobject this)
{</p>

<pre><code>JVM_GC();
</code></pre>

<p>}
```
其实没错的，就是这个方法，jvm要查找到这个native方法其实很简单的，看方法名可能也猜到规则了，Java_pkgName_className_methodName，其中pkgName里的"."替换成"_"，这样就能找到了，当然规则不仅仅只有这么一个，还有其他的，这里不细说了，有机会写篇文章详细介绍下其中细节</p>

<h3>DisableExplicitGC参数</h3>

<p>上面的方法里是调用JVM_GC()，实现如下</p>

<p>```
JVM_ENTRY_NO_ENV(void, JVM_GC(void))
  JVMWrapper("JVM_GC");
  if (!DisableExplicitGC) {</p>

<pre><code>Universe::heap()-&gt;collect(GCCause::_java_lang_system_gc);
</code></pre>

<p>  }
JVM_END
<code>``
看到这里我们已经解释其中一个疑惑了，就是</code>DisableExplicitGC`这个参数是在哪里生效的，起的什么作用，如果这个参数设置为true的话，那么将直接跳过下面的逻辑，我们通过-XX:+ DisableExplicitGC就是将这个属性设置为true，而这个属性默认情况下是true还是false呢</p>

<p>```
product(bool, DisableExplicitGC, false,                                   \</p>

<pre><code>      "Tells whether calling System.gc() does a full GC")    
</code></pre>

<p>```</p>

<h3>ExplicitGCInvokesConcurrent参数</h3>

<p>这里主要针对CMSGC下来做分析，所以我们上面看到调用了heap的collect方法，我们找到对应的逻辑</p>

<p>```
void GenCollectedHeap::collect(GCCause::Cause cause) {
  if (should_do_concurrent_full_gc(cause)) {</p>

<h1>ifndef SERIALGC</h1>

<pre><code>// mostly concurrent full collection
collect_mostly_concurrent(cause);
</code></pre>

<h1>else  // SERIALGC</h1>

<pre><code>ShouldNotReachHere();
</code></pre>

<h1>endif // SERIALGC</h1>

<p>  } else {</p>

<h1>ifdef ASSERT</h1>

<pre><code>if (cause == GCCause::_scavenge_alot) {
  // minor collection only
  collect(cause, 0);
} else {
  // Stop-the-world full collection
  collect(cause, n_gens() - 1);
}
</code></pre>

<h1>else</h1>

<pre><code>// Stop-the-world full collection
collect(cause, n_gens() - 1);
</code></pre>

<h1>endif</h1>

<p>  }
}</p>

<p>bool GenCollectedHeap::should_do_concurrent_full_gc(GCCause::Cause cause) {
  return UseConcMarkSweepGC &amp;&amp;</p>

<pre><code>     ((cause == GCCause::_gc_locker &amp;&amp; GCLockerInvokesConcurrent) ||
      (cause == GCCause::_java_lang_system_gc &amp;&amp; ExplicitGCInvokesConcurrent));
</code></pre>

<p>}
```
collect里一开头就有个判断，如果should_do_concurrent_full_gc返回true，那会执行collect_mostly_concurrent做并行的回收</p>

<p>其中should_do_concurrent_full_gc中的逻辑是如果使用CMS GC，并且是system gc且ExplicitGCInvokesConcurrent==true，那就做并行full gc，当我们设置-XX:+ ExplicitGCInvokesConcurrent的时候，就意味着应该做并行Full GC了，不过要注意千万不要设置-XX:+DisableExplicitGC，不然走不到这个逻辑里来了</p>

<h2>并行Full GC相对正常的Full GC效率高在哪里</h2>

<h3>stop the world</h3>

<p>说到GC，这里要先提到VMThread，在jvm里有这么一个线程不断轮询它的队列，这个队列里主要是存一些VM_operation的动作，比如最常见的就是内存分配失败要求做GC操作的请求等，在对gc这些操作执行的时候会先将其他业务线程都进入到安全点，也就是这些线程从此不再执行任何字节码指令，只有当出了安全点的时候才让他们继续执行原来的指令，因此这其实就是我们说的stop the world(STW)，整个进程相当于静止了</p>

<h3>CMS GC</h3>

<p>这里必须提到CMS GC，因为这是解释并行Full GC和正常Full GC的关键所在，CMS GC我们分为两种模式background和foreground，其中background顾名思义是在后台做的，也就是可以不影响正常的业务线程跑，触发条件比如说old的内存占比超过多少的时候就可能触发一次background式的cms gc，这个过程会经历CMS GC的所有阶段，该暂停的暂停，该并行的并行，效率相对来说还比较高，毕竟有和业务线程并行的gc阶段；而foreground则不然，它发生的场景比如业务线程请求分配内存，但是内存不够了，于是可能触发一次cms gc，这个过程就必须是要等内存分配到了线程才能继续往下面走的，因此整个过程必须是STW的，因此CMS GC整个过程都是暂停应用的，但是为了提高效率，它并不是每个阶段都会走的，只走其中一些阶段，这些省下来的阶段主要是并行阶段，Precleaning、AbortablePreclean，Resizing这几个阶段都不会经历，其中sweep阶段是同步的，但不管怎么说如果走了类似foreground的cms gc，那么整个过程业务线程都是不可用的，效率会影响挺大。CMS GC具体的过程后面再写文章详细说，其过程确实非常复杂的</p>

<h3>正常的Full GC</h3>

<p>正常的Full GC其实是整个gc过程包括ygc和cms gc(这里说的是真正意义上的Full GC，还有些场景虽然调用Full GC的接口，但是并不会都做，有些时候只做ygc，有些时候只做cms gc)都是由VMThread来执行的，因此整个时间是ygc+cms gc的时间之和，其中CMS GC是上面提到的foreground式的，因此整个过程会比较长，也是我们要避免的</p>

<h3>并行的Full GC</h3>

<p>并行Full GC也通样会做YGC和CMS GC，但是效率高就搞在CMS GC是走的background的，整个暂停的过程主要是YGC+CMS_initMark+CMS_remark几个阶段</p>

<h2>堆外内存常配合使用System GC</h2>

<p>这里说的堆外内存主要针对java.nio.DirectByteBuffer，这些对象的创建过程会通过Unsafe接口直接通过os::malloc来分配内存，然后将内存的起始地址和大小存到java.nio.DirectByteBuffer对象里，这样就可以直接操作这些内存。这些内存只有在DirectByteBuffer回收掉之后才有机会被回收，因此如果这些对象大部分都移到了old，但是一直没有触发CMS GC或者Full GC，那么悲剧将会发生，因为你的物理内存被他们耗尽了，因此为了避免这种悲剧的发生，通过-XX:MaxDirectMemorySize来指定最大的堆外内存大小，当使用达到了阈值的时候将调用System.gc来做一次full gc，以此来回收掉没有被使用的堆外内存，具体堆外内存是如何回收的，其原理机制又是怎样的，还是后面写篇详细的文章吧</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM Bug:多个线程持有一把锁?]]></title>
    <link href="http://nijiaben.github.io/blog/2014/07/24/jvm-thread-dump-bug/"/>
    <updated>2014-07-24T14:10:26+08:00</updated>
    <id>http://nijiaben.github.io/blog/2014/07/24/jvm-thread-dump-bug</id>
    <content type="html"><![CDATA[<p><code>注:文章首发于InfoQ，</code><a href="http://www.infoq.com/cn/articles/jvm-bug-thread">http://www.infoq.com/cn/articles/jvm-bug-thread</a></p>

<h2>JVM线程dump Bug描述</h2>

<p>&#8195;&#8195;在JAVA语言中，当同步块(<code>Synchronized</code>)被多个线程并发访问时，JVM中会采用基于互斥实现的重量级锁。JVM最多只允许一个线程持有这把锁，如果其它线程想要获得这把锁就必须处于等待状态，也就是说在同步块被并发访问时，最多只会有一个处于<code>RUNNABLE</code>状态的线程持有某把锁，而另外的线程因为竞争不到这把锁而都处于<code>BLOCKED</code>状态。然而有些时候我们会发现处于<code>BLOCKED</code>状态的线程，它的最上面那一帧在打印其正在等待的锁对象时，居然也会出现-locked的信息，这个信息和持有该锁的线程打印出来的结果是一样的(请看下图)，但是对比其他<code>BLOCKED</code>态的线程却并没有都出现这种情况。当我们再次dump线程时又可能出现不一样的结果。测试表明这可能是一个偶发的情况，本文就是针对这种情况对JVM内部的实现做了一个研究以寻找其根源。</p>

<!--more-->


<p><img src="/images/2014/07/thread_dump_bug.jpg"></p>

<h2>JStack命令的整个过程</h2>

<p>&#8195;&#8195;上面提到了线程dump，那么就不得不提执行线程dump的工具---jstack，这个工具是Java自带的工具，和Java处于同一个目录下，主要是用来dump线程的，或许大家也有使用kill -3的命令来dump线程，但这两者最明显的一个区别是，前者的dump内容是由jstack这个进程来输出的，目标JVM进程将dump内容发给jstack进程(注意这是没有加-m参数的场景，指定-m参数就有点不一样了，它使用的是serviceability agent的api来实现的，底层通过ptrace的方式来获取目标进程的内容，执行过程可能会比正常模式更长点)，这意味着可以做文件重定向，将线程dump内容输出到指定文件里；而后者是由目标进程输出的，只会产生在目标进程的标准输出文件里，如果正巧标准输出里本身就有内容的话，看起来会比较乱，比如想通过一些分析工具去分析的话，要是该工具没有做过滤操作，很可能无法分析。因此一般情况我们尽量使用jstack，另外jstack还有很多实用的参数，比如<code>jstack pid &gt;thread_dump.log</code>，该命令会将指定pid的进程的线程dump到当前目录的thread_dump.log文件里。</p>

<p>&#8195;&#8195;jstack是使用Java实现的，它通过给目标JVM进程发送一个threaddump的命令，目标JVM的监听线程（<code>attachListener</code>）会实时监听传过来的命令(其实attachListener线程并不是一启动就创建的，它是lazy创建启动的)，当attachListener收到threaddump命令时会调用thread_dump的方法来处理dump操作(方法在attachListener.cpp里)。</p>

<pre class="prettyPrint">
static jint thread_dump(AttachOperation* op, outputStream* out) {
  bool print_concurrent_locks = false;
  if (op->arg(0) != NULL && strcmp(op->arg(0), "-l") == 0) {
    print_concurrent_locks = true;
  }

  // thread stacks
  VM_PrintThreads op1(out, print_concurrent_locks);
  VMThread::execute(&op1);

  // JNI global handles
  VM_PrintJNI op2(out);
  VMThread::execute(&op2);

  // Deadlock detection
  VM_FindDeadlocks op3(out);
  VMThread::execute(&op3);

  return JNI_OK;
}
</pre>


<p>&#8195;&#8195;从上面的方法可以看到，jstack命令执行了三个操作：</p>

<ul>
<li><code>VM_PrintThreads</code>：打印线程栈</li>
<li><code>VM_PrintJNI</code>：打印JNI</li>
<li><code>VM_FindDeadlocks</code>：打印死锁</li>
</ul>


<p>&#8195;&#8195;三个操作都是交给VMThread线程去执行的，VMThread线程在整个JAVA进程有且只会有一个。可以想象一下VMThread线程的简单执行过程：不断地轮询某个任务列表并在有任务时依次执行任务。任务执行时，它会根据具体的任务决定是否会暂停整个应用，也就是stop the world，这是不是让我们联想到了我们熟悉的GC过程？是的，我们的ygc以及cmsgc的两个暂停应用的阶段(init_mark和remark)都是由这个线程来执行的，并且都要求暂停整个应用。其实上面的三个操作都是要求暂停整个应用的，也就是说jstack触发的线程dump过程也是会暂停应用的，只是这个过程一般很快就结束，不会有明显的感觉。另外内存dump的jmap命令，也是会暂停整个应用的，如果使用了-F的参数，其底层也是使用serviceability agent的api来dump的，但是dump内存的速度会明显慢很多。</p>

<h2>VMThread执行任务的过程</h2>

<p>&#8195;&#8195;VMThread执行的任务称为vm_opration，在JVM中存在两种vm_opration，一种是需要在安全点内执行的(所谓安全点，就是系统处于一个安全的状态，除了VMThread这个线程可以正常运行之外，其他的线程都必须暂停执行，在这种情况下就可以放心执行当前的一系列vm_opration了)，另外一种是不需要在安全点内执行的。而这次我们讨论的线程dump是需要在安全点内执行的。</p>

<p>&#8195;&#8195;以下是VMThread轮询的逻辑:</p>

<pre class="prettyPrint">
void VMThread::loop() {
  assert(_cur_vm_operation == NULL, "no current one should be executing");

  while(true) {
    ...
    //已经获取了一个vm_operation
    if (_cur_vm_operation->evaluate_at_safepoint()) {
        //如果该vm_operation需要在安全点内执行
        _vm_queue->set_drain_list(safepoint_ops); 
        SafepointSynchronize::begin();//进入安全点
        evaluate_operation(_cur_vm_operation);
        do {
          _cur_vm_operation = safepoint_ops;
          if (_cur_vm_operation != NULL) {
            do {
              VM_Operation* next = _cur_vm_operation->next();
              _vm_queue->set_drain_list(next);
              evaluate_operation(_cur_vm_operation);
              _cur_vm_operation = next;
              if (PrintSafepointStatistics) {
                SafepointSynchronize::inc_vmop_coalesced_count();
              }
            } while (_cur_vm_operation != NULL);
          }
          if (_vm_queue->peek_at_safepoint_priority()) {
            MutexLockerEx mu_queue(VMOperationQueue_lock,
                                     Mutex::_no_safepoint_check_flag);
            safepoint_ops = _vm_queue->drain_at_safepoint_priority();
          } else {
            safepoint_ops = NULL;
          }
        } while(safepoint_ops != NULL);
        _vm_queue->set_drain_list(NULL);
        SafepointSynchronize::end();//退出安全点
      } else {  // not a safepoint operation
        if (TraceLongCompiles) {
          elapsedTimer t;
          t.start();
          evaluate_operation(_cur_vm_operation);
          t.stop();
          double secs = t.seconds();
          if (secs * 1e3 > LongCompileThreshold) {
            tty->print_cr("vm %s: %3.7f secs]", _cur_vm_operation->name(), secs);
          }
        } else {
            evaluate_operation(_cur_vm_operation);
        }
        _cur_vm_operation = NULL;
      }
    }
    ...
  }
</pre>


<p></p>

<p>&#8195;&#8195;在这里重点解释下在安全点内执行的vm_opration的过程，VMThread通过不断循环从_vm_queue中获取一个或者几个需要在安全点内执行的vm_opertion，然后在准备执行这些vm_opration之前先通过调用<code>SafepointSynchronize::begin()</code>进入到安全点状态，在执行完这些vm_opration之后，调用<code>SafepointSynchronize::end()</code>，退出安全点模式，恢复之前暂停的所有线程让他们继续运行。对于安全点这块的逻辑挺复杂的，仅仅需要记住在进入安全点模式的时候会持有Threads_lock这把线程互斥锁，对线程的操作都需要获取到这把锁才能继续执行，并且还会设置安全点的状态，如果正在进入安全点过程中设置_state为_synchronizing，当所有线程都完全进入了安全点之后设置_state为_synchronized状态，退出的时候设置为_not_synchronized状态。</p>

<pre class="prettyPrint">
void SafepointSynchronize::begin() {
  ...
  Threads_lock->lock();
  ...
  _state            = _synchronizing;
  ...
   _state = _synchronized;
...
}

void SafepointSynchronize::end() {
    assert(Threads_lock->owned_by_self(), "must hold Threads_lock");
    ...
    _state = _not_synchronized;
    ...
    Threads_lock->unlock();
}
</pre>


<h2>线程Dump中的VM_PrintThreads过程</h2>

<p>&#8195;&#8195;回到开头提到的JVM线程Dump时的Bug，从我们打印的结果来看也基本猜到了这个过程：遍历每个Java线程，然后再遍历每一帧，打印该帧的一些信息(包括类，方法名，行数等)，在打印完每一帧之后然后打印这帧已经关联了的锁信息，下面代码就是打印每个线程的过程:</p>

<pre class="prettyPrint">
void JavaThread::print_stack_on(outputStream* st) {
  if (!has_last_Java_frame()) return;
  ResourceMark rm;
  HandleMark   hm;

  RegisterMap reg_map(this);
  vframe* start_vf = last_java_vframe(®_map);
  int count = 0;
  for (vframe* f = start_vf; f; f = f->sender() ) {
    if (f->is_java_frame()) {
      javaVFrame* jvf = javaVFrame::cast(f);
      java_lang_Throwable::print_stack_element(st, jvf->method(), jvf->bci());
      if (JavaMonitorsInStackTrace) {
        jvf->print_lock_info_on(st, count);
      }
    } else {
      // Ignore non-Java frames
    }
    count++;
    if (MaxJavaStackTraceDepth == count) return;
  }
}
</pre>


<p>&#8195;&#8195;和我们这次问题相关的逻辑，也就是打印<code>"-locked"</code>的信息是正好是在<code>jvf-&gt;print_lock_info_on(st, count)</code>这行里面，请看具体实现:</p>

<pre class="prettyPrint">
void javaVFrame::print_lock_info_on(outputStream* st, int frame_count) {
  ResourceMark rm;
  if (frame_count == 0) {
    if (method()->name() == vmSymbols::wait_name() &&
        instanceKlass::cast(method()->method_holder())->name() == vmSymbols::java_lang_Object()) {
      StackValueCollection* locs = locals();
      if (!locs->is_empty()) {
        StackValue* sv = locs->at(0);
        if (sv->type() == T_OBJECT) {
          Handle o = locs->at(0)->get_obj();
          print_locked_object_class_name(st, o, "waiting on");
        }
      }
    } else if (thread()->current_park_blocker() != NULL) {
      oop obj = thread()->current_park_blocker();
      Klass* k = Klass::cast(obj->klass());
      st->print_cr("\t- %s <" INTPTR_FORMAT "> (a %s)", "parking to wait for ", (address)obj, k->external_name());
    }
  }

  GrowableArray<MonitorInfo*>* mons = monitors();
  if (!mons->is_empty()) {
    bool found_first_monitor = false;
    for (int index = (mons->length()-1); index >= 0; index--) {
      MonitorInfo* monitor = mons->at(index);
      if (monitor->eliminated() && is_compiled_frame()) {
        if (monitor->owner_is_scalar_replaced()) {
          Klass* k = Klass::cast(monitor->owner_klass());
          st->print("\t- eliminated <owner is scalar replaced> (a %s)", k->external_name());
        } else {
          oop obj = monitor->owner();
          if (obj != NULL) {
            print_locked_object_class_name(st, obj, "eliminated");
          }
        }
        continue;
      }
      if (monitor->owner() != NULL) {
        const char *lock_state = "locked";
        if (!found_first_monitor && frame_count == 0) {
          markOop mark = monitor->owner()->mark();
          if (mark->has_monitor() &&
              mark->monitor() == thread()->current_pending_monitor()) {
            lock_state = "waiting to lock";
          }
        }
        found_first_monitor = true;
        print_locked_object_class_name(st, monitor->owner(), lock_state);
      }
    }
  }
}
</pre>


<p>&#8195;&#8195;看到上面的方法，再对比线程dump的结果，我们会发现很多熟悉的东西，比如<code>waiting on</code>，<code>parking to wait for</code>，<code>locked</code>，<code>waiting to lock</code>，而且也清楚了它们分别是在什么情况下会打印的。</p>

<p>&#8195;&#8195;那为什么我们的例子中BLOCKED状态的线程本应该打印<code>waiting to lock</code>,但是为什么却打印了<code>locked</code>呢，那说明<code>if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor() == thread()-&gt;current_pending_monitor())</code> 这个条件肯定不成立，那这个在什么情况下不成立呢？在验证此问题前，有必要先了解下markOop是什么东西，它是用来干什么的？</p>

<h2>markOop是什么</h2>

<p>&#8195;&#8195;markOop描述了一个对象(也包括了Class)的状态信息，Java语法层面的每个对象或者Class在JVM的结构表示中都会包含一个markOop作为Header，当然还有一些其他的JVM数据结构也用它做Header。markOop由32位或者64位构成，具体位数根据运行环境而定。</p>

<p>&#8195;&#8195;下面的结构图包含markOop每一位所代表的含义，markOop的值根据所描述的对象的类型(比如是锁对象还是正常的对象)以及作用的不同而不同。就算在同一个对象里，它的值也是可能会不断变化的，比如锁对象，在一开始创建的时候其实并不知道是锁对象，会当成一个正常对象来创建(在对象的类型并没有设置偏向锁的情况下，其markOop值可能是0x1)，但是随着我们执行到synchronized的代码逻辑时，就知道其实它是一个锁对象了，它的值就不再是0x1了，而是一个新的值，该值是对应栈帧结构里的监控对象列表里的某一个内存地址。</p>

<pre class="prettyPrint">
//  32 bits:
//  --------
//             hash:25 ------------>| age:4    biased_lock:1 lock:2 (normal object)
//             JavaThread*:23 epoch:2 age:4    biased_lock:1 lock:2 (biased object)
//             size:32 ------------------------------------------>| (CMS free block)
//             PromotedObject*:29 ---------->| promo_bits:3 ----->| (CMS promoted object)
//
//  64 bits:
//  --------
//  unused:25 hash:31 -->| unused:1   age:4    biased_lock:1 lock:2 (normal object)
//  JavaThread*:54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased object)
//  PromotedObject*:61 --------------------->| promo_bits:3 ----->| (CMS promoted object)
//  size:64 ----------------------------------------------------->| (CMS free block)
//
//  unused:25 hash:31 -->| cms_free:1 age:4    biased_lock:1 lock:2 (COOPs && normal object)
//  JavaThread*:54 epoch:2 cms_free:1 age:4    biased_lock:1 lock:2 (COOPs && biased object)
//  narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 ----->| (COOPs && CMS promoted object)
//  unused:21 size:35 -->| cms_free:1 unused:7 ------------------>| (COOPs && CMS free block)
</pre>


<p>&#8195;&#8195;就最后的3位而言，其不同的值代表不同的含义：</p>

<pre class="prettyPrint">
 enum { locked_value             = 0,//00
         unlocked_value           = 1,//01
         monitor_value            = 2,//10
         marked_value             = 3,//11      
         biased_lock_pattern      = 5 //101
  };
</pre>


<p></p>

<p>&#8195;&#8195;上面的判断条件<code>“mark-&gt;has_monitor()”</code>其实就是判断最后的2位是不是10，如果是，则说明这个对象是一个监控对象，可以通过<code>mark-&gt;monitor()</code>方法获取到对应的结构体：</p>

<pre class="prettyPrint">
bool has_monitor() const {
    return ((value() & monitor_value) != 0);
  }
  ObjectMonitor* monitor() const {
    assert(has_monitor(), "check");
    // Use xor instead of &~ to provide one extra tag-bit check.
    return (ObjectMonitor*) (value() ^ monitor_value);
  }
</pre>


<p></p>

<p>&#8195;&#8195;将一个普通对象转换为一个monitor对象的过程(就是替换markOop的值)请参考为<code>ObjectSynchronizer::inflate</code>方法，能进入到该方法说明该锁为重量级锁，也就是说这把锁其实是被多个线程竞争的。</p>

<p>&#8195;&#8195;了解了markOop之后，还要了解下上面那个条件里的<code>thread()-&gt;current_pending_monitor()</code>，也就是这个值是什么时候设置进去的呢?</p>

<h2>线程设置等待的监控对象的时机</h2>

<p>&#8195;&#8195;设置的逻辑在<code>ObjectMonitor::enter</code>里，关键代码如下：</p>

<pre class="prettyPrint">
...
{
    JavaThreadBlockedOnMonitorEnterState jtbmes(jt, this);
    DTRACE_MONITOR_PROBE(contended__enter, this, object(), jt);
    if (JvmtiExport::should_post_monitor_contended_enter()) {
      JvmtiExport::post_monitor_contended_enter(jt, this);
    }
    OSThreadContendState osts(Self->osthread());
    ThreadBlockInVM tbivm(jt);
    Self->set_current_pending_monitor(this);//设置当前monitor对象为当前线程等待的monitor对象
    for (;;) {
      jt->set_suspend_equivalent();
      EnterI (THREAD) ;
      if (!ExitSuspendEquivalent(jt)) break ;
          _recursions = 0 ;
      _succ = NULL ;
      exit (false, Self) ;

      jt->java_suspend_self();
    }
    Self->set_current_pending_monitor(NULL);
  }
 ... 
</pre>


<p></p>

<p>&#8195;&#8195;设置当前线程等待的monitorObject是在有中文注释的那一行设置的，那么出现Bug的原因是不是正好在设置之前进行了线程dump呢？</p>

<h2>水落石出</h2>

<p>&#8195;&#8195;在JVM中只会有一个处于RUNNBALE状态的线程，也就是说另外一个打印<code>"-locked"</code>信息的线程是处于BLOCKED状态的。上面的第一行代码：</p>

<pre class="prettyPrint">
JavaThreadBlockedOnMonitorEnterState jtbmes(jt, this);
</pre>


<p>&#8195;&#8195;找到其实现位置：</p>

<pre class="prettyPrint">
 JavaThreadBlockedOnMonitorEnterState(JavaThread *java_thread, ObjectMonitor *obj_m) :
    JavaThreadStatusChanger(java_thread) {
    assert((java_thread != NULL), "Java thread should not be null here");
    _active = false;
    if (is_alive() && ServiceUtil::visible_oop((oop)obj_m->object()) && obj_m->contentions() > 0) {
      _stat = java_thread->get_thread_stat();
      _active = contended_enter_begin(java_thread);//关键处
    }
  }

 static bool contended_enter_begin(JavaThread *java_thread) {
    set_thread_status(java_thread, java_lang_Thread::BLOCKED_ON_MONITOR_ENTER);//关键处
    ThreadStatistics* stat = java_thread->get_thread_stat();
    stat->contended_enter();
    bool active = ThreadService::is_thread_monitoring_contention();
    if (active) {
      stat->contended_enter_begin();
    }
    return active;
  } 
</pre>


<p></p>

<p>&#8195;&#8195;上面的contended_enter_begin方法会设置java线程的状态为<code>java_lang_Thread::BLOCKED_ON_MONITOR_ENTER</code>，而线程dump时根据这个状态打印的结果如下：</p>

<pre class="prettyPrint">
const char* java_lang_Thread::thread_status_name(oop java_thread) {
  assert(JDK_Version::is_gte_jdk15x_version() && _thread_status_offset != 0, "Must have thread status");
  ThreadStatus status = (java_lang_Thread::ThreadStatus)java_thread->int_field(_thread_status_offset);
  switch (status) {
    case NEW                      : return "NEW";
    case RUNNABLE                 : return "RUNNABLE";
    case SLEEPING                 : return "TIMED_WAITING (sleeping)";
    case IN_OBJECT_WAIT           : return "WAITING (on object monitor)";
    case IN_OBJECT_WAIT_TIMED     : return "TIMED_WAITING (on object monitor)";
    case PARKED                   : return "WAITING (parking)";
    case PARKED_TIMED             : return "TIMED_WAITING (parking)";
    case BLOCKED_ON_MONITOR_ENTER : return "BLOCKED (on object monitor)";
    case TERMINATED               : return "TERMINATED";
    default                       : return "UNKNOWN";
  };
}
</pre>


<p>&#8195;&#8195;正好对应我们dump日志中的信息<code>"BLOCKED (on object monitor)"</code>也就是说这行代码被正常执行了，那问题就可能出在<code>JavaThreadBlockedOnMonitorEnterState jtbmes(jt, this)</code>和<code>Self-&gt;set_current_pending_monitor(this)</code>这两行代码之间的逻辑里了：</p>

<pre class="prettyPrint">
    JavaThreadBlockedOnMonitorEnterState jtbmes(jt, this);
    DTRACE_MONITOR_PROBE(contended__enter, this, object(), jt);
    if (JvmtiExport::should_post_monitor_contended_enter()) {
      JvmtiExport::post_monitor_contended_enter(jt, this);
    }
    OSThreadContendState osts(Self->osthread());
    ThreadBlockInVM tbivm(jt);
    Self->set_current_pending_monitor(this);//设置当前monitor对象为当前线程等待的monitor对象
</pre>


<p>&#8195;&#8195;于是检查每一行的实现，前面几行都基本可以排除了，因为它们都是很简单的操作，下面来分析下<code>ThreadBlockInVM tbivm(jt)</code>这一行的实现：</p>

<pre class="prettyPrint">
ThreadBlockInVM(JavaThread *thread)
  : ThreadStateTransition(thread) {
    thread->frame_anchor()->make_walkable(thread);
    trans_and_fence(_thread_in_vm, _thread_blocked);
  }

 void trans_and_fence(JavaThreadState from, JavaThreadState to) { 
    transition_and_fence(_thread, from, to); 
 }

 static inline void transition_and_fence(JavaThread *thread, JavaThreadState from, JavaThreadState to) {
    assert(thread->thread_state() == from, "coming from wrong thread state");
    assert((from & 1) == 0 && (to & 1) == 0, "odd numbers are transitions states");
    thread->set_thread_state((JavaThreadState)(from + 1));
    if (os::is_MP()) {
      if (UseMembar) {
        OrderAccess::fence();
      } else {
        InterfaceSupport::serialize_memory(thread);
      }
    }

    if (SafepointSynchronize::do_call_back()) {
      SafepointSynchronize::block(thread);
    }
    thread->set_thread_state(to);
    CHECK_UNHANDLED_OOPS_ONLY(thread->clear_unhandled_oops();)
  }
 ...
 } 
 </pre>


<p>&#8195;&#8195;也许我们看到可能造成问题的代码了：</p>

<pre class="prettyPrint">
if (SafepointSynchronize::do_call_back()) {
      SafepointSynchronize::block(thread);
}
</pre>


<p>  <br/>
&#8195;&#8195;想象一下，当这个线程正好执行到这个条件判断，然后进去了，从方法名上来说是不是意味着这个线程会block住，并且不往后走了呢？这样一来设置当前线程的pending_monitor对象的操作就不会被执行了，从而在打印这个线程栈的时候就会打印"-locked"信息了，那么纠结是否正如我们想的那样呢？</p>

<p>首先来看条件<code>SafepointSynchronize::do_call_back()</code>是否一定会成立：</p>

<pre class="prettyPrint">
inline static bool do_call_back() {
    return (_state != _not_synchronized);
}
</pre>


<p>&#8195;&#8195;上面的VMThread执行任务的过程中说到了这个状态，当vmThread执行完了<code>SafepointSynchronize::begin()</code>之后，这个状态是设置为_synchronized的。如果正在执行，那么状态是_synchronizing，因此，当我们触发了jvm的线程dump之后，VMThread执行该操作，而且还在执行线程dump过程前，但是还只是_synchronizing的状态，那么do_call_back()将会返回true，那么将执行接下来的SafepointSynchronize::block(thread)方法：</p>

<pre class="prettyPrint">
void SafepointSynchronize::block(JavaThread *thread) {
  assert(thread != NULL, "thread must be set");
  assert(thread->is_Java_thread(), "not a Java thread");

  ttyLocker::break_tty_lock_for_safepoint(os::current_thread_id());

  if (thread->is_terminated()) {
     thread->block_if_vm_exited();
     return;
  }

  JavaThreadState state = thread->thread_state();
  thread->frame_anchor()->make_walkable(thread);

  switch(state) {
    case _thread_in_vm_trans:
    case _thread_in_Java:        // From compiled code
      thread->set_thread_state(_thread_in_vm);

      if (is_synchronizing()) {
         Atomic::inc (&TryingToBlock) ;
      }
      Safepoint_lock->lock_without_safepoint_check();
      if (is_synchronizing()) {
        assert(_waiting_to_block > 0, "sanity check");
        _waiting_to_block--;
        thread->safepoint_state()->set_has_called_back(true);

        DEBUG_ONLY(thread->set_visited_for_critical_count(true));
        if (thread->in_critical()) {
          increment_jni_active_count();
        }
        if (_waiting_to_block == 0) {
          Safepoint_lock->notify_all();
        }
      }
      thread->set_thread_state(_thread_blocked);
      Safepoint_lock->unlock();
      Threads_lock->lock_without_safepoint_check();//关键代码
      thread->set_thread_state(state);
      Threads_lock->unlock();
      break;
   ...
  }
  if (state != _thread_blocked_trans &&
      state != _thread_in_vm_trans &&
      thread->has_special_runtime_exit_condition()) {
    thread->handle_special_runtime_exit_condition(
      !thread->is_at_poll_safepoint() && (state != _thread_in_native_trans));
  }
}

void Monitor::lock_without_safepoint_check (Thread * Self) {
  assert (_owner != Self, "invariant") ;
  ILock (Self) ;
  assert (_owner == NULL, "invariant");
  set_owner (Self);
}

void Monitor::lock_without_safepoint_check () {
  lock_without_safepoint_check (Thread::current()) ;
}
</pre>


<p>&#8195;&#8195;看到上面的实现可以确定，Java线程执行时会调用<code>Threads_lock-&gt;lock_without_safepoint_check()</code>，而Threads_lock因为被VMThread持有，将一直卡死在<code>ILock (Self)</code>这个逻辑里，从而没有设置current_monitor属性，由此验证了我们的想法。</p>

<h2>Bug修复</h2>

<p>&#8195;&#8195;在了解了原因之后，我们可以简单的修复这个Bug。将下面两行代码调换下位置即可：</p>

<pre class="prettyPrint">
 ThreadBlockInVM tbivm(jt);
 Self->set_current_pending_monitor(this);//设置当前monitor对象为当前线程等待的monitor对象
</pre>


<p>
&#8195;&#8195;该Bug不会对生产环境产生影响，本文主要是和大家分享分析问题的过程，希望大家碰到疑惑都能有一查到底的劲儿，带着问题，不断提出自己的猜想，然后不断验证自己的猜想，最终解决问题。</p>
]]></content>
  </entry>
  
</feed>
