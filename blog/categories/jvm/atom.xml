<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: JVM | 你假笨]]></title>
  <link href="http://nijiaben.github.io/blog/categories/jvm/atom.xml" rel="self"/>
  <link href="http://nijiaben.github.io/"/>
  <updated>2015-10-21T19:05:55+08:00</updated>
  <id>http://nijiaben.github.io/</id>
  <author>
    <name><![CDATA[你假笨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[消失的死锁]]></title>
    <link href="http://nijiaben.github.io/blog/2015/10/21/deadlock/"/>
    <updated>2015-10-21T18:54:01+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/10/21/deadlock</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>如果java层面发生了死锁，当我们使用<code>jstack</code>命令的时候其实是可以将死锁的信息给dump出来的，在dump结果的最后会有类似<code>Found one Java-level deadlock:</code>的关键字，接着会把发生死锁的线程的堆栈及对应的同步锁给打印出来，这次碰到一个系统就发生类似的问题，不过这个dump文档里虽然提到了如下的死锁信息：</p>

<!--more-->


<p>```</p>

<h1>Found one Java-level deadlock:</h1>

<p>"worker-1-thread-121":
  waiting to lock monitor 0x00007f3758209dc8 (object 0x0000000764cd2b20, a java.util.concurrent.ConcurrentHashMap),
  which is held by "HSFBizProcessor-4-thread-4"
"HSFBizProcessor-4-thread-4":
  waiting to lock monitor 0x00007f3758289260 (object 0x000000076073ddc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-5"
"HSFBizProcessor-4-thread-5":
  waiting to lock monitor 0x00007f3758253420 (object 0x00000007608e6fc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-4"
```</p>

<p>但是我们在堆栈里搜索对应的锁的时候并没发现，也就是上面提到的<code>object 0x00000007608e6fc8 which is held by "HSFBizProcessor-4-thread-4"</code>，我们在<code>HSFBizProcessor-4-thread-4</code>这个线程的堆栈里并没有看到对应的持锁信息。</p>

<p>附上线程dump详情</p>

<p>```</p>

<h1>Found one Java-level deadlock:</h1>

<p>"worker-1-thread-121":
  waiting to lock monitor 0x00007f3758209dc8 (object 0x0000000764cd2b20, a java.util.concurrent.ConcurrentHashMap),
  which is held by "HSFBizProcessor-4-thread-4"
"HSFBizProcessor-4-thread-4":
  waiting to lock monitor 0x00007f3758289260 (object 0x000000076073ddc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-5"
"HSFBizProcessor-4-thread-5":
  waiting to lock monitor 0x00007f3758253420 (object 0x00000007608e6fc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader),
  which is held by "HSFBizProcessor-4-thread-4"</p>

<h1>Java stack information for the threads listed above:</h1>

<p>"worker-1-thread-121":</p>

<pre><code>at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:180)
- waiting to lock &lt;0x0000000764cd2b20&gt; (a java.util.concurrent.ConcurrentHashMap)
at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:455)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:317)
......
at java.util.concurrent.FutureTask.run(FutureTask.java:138)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)
</code></pre>

<p>"HSFBizProcessor-4-thread-4":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x000000076073ddc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at org.springframework.scripting.groovy.GroovyScriptFactory.executeScript(GroovyScriptFactory.java:238)
......
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)
</code></pre>

<p>"HSFBizProcessor-4-thread-5":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x00000007608e6fc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.DependentPolicy.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.PolicyHandler.doBuddyClassLoading(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:169)
at groovy.lang.MetaClassRegistry$MetaClassCreationHandle.createWithCustomLookup(MetaClassRegistry.java:127)
at groovy.lang.MetaClassRegistry$MetaClassCreationHandle.create(MetaClassRegistry.java:122)
......
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)
</code></pre>

<p>Found 1 deadlock.
```</p>

<h2>类加载的问题？</h2>

<p>首先应该怀疑类加载的问题，因为我们看到导致死锁的对象是一个classloader对象：</p>

<p><code>
waiting to lock monitor 0x00007f3758289260 (object 0x000000076073ddc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
</code></p>

<p>然后我们再来分析下堆栈</p>

<h3>HSFBizProcessor-4-thread-4</h3>

<p>```
"HSFBizProcessor-4-thread-4":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x000000076073ddc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at org.springframework.scripting.groovy.GroovyScriptFactory.executeScript(GroovyScriptFactory.java:238)
at org.springframework.scripting.groovy.GroovyScriptFactory.getScriptedObject(GroovyScriptFactory.java:185)
</code></pre>

<p>```</p>

<p>我这里只把关键的线程栈贴出来，从栈顶知道正在等一把锁：</p>

<p>```</p>

<pre><code>- waiting to lock &lt;0x000000076073ddc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
</code></pre>

<p>```</p>

<p>这把锁的对象是一个ClassLoader对象，我们找到对应的代码，确实存在synchronized的操作：</p>

<p>```
private Class&lt;?> findLoadedClass(String classname) {</p>

<pre><code>if ((LOCK_CLASSNAME) || (this.isParallelClassLoader)) {
  boolean initialLock = lockClassName(classname);
  try {
    return this.classloader.publicFindLoaded(classname);
  } finally {
    if (initialLock)
      unlockClassName(classname);
  }
}
synchronized (this.classloader) {
  return this.classloader.publicFindLoaded(classname);
}
</code></pre>

<p>  }</p>

<p>```</p>

<p>另外我们还知道它正在执行loadClass的动作，并且是从groovy调用来的，同样找到对应的代码：</p>

<p>```
protected Object executeScript(ScriptSource scriptSource, Class scriptClass)</p>

<pre><code>throws ScriptCompilationException
</code></pre>

<p>  {</p>

<pre><code>try
{
  GroovyObject goo = (GroovyObject)scriptClass.newInstance();//line 238

  if (this.groovyObjectCustomizer != null)
  {
    this.groovyObjectCustomizer.customize(goo);
  }

  if ((goo instanceof Script))
  {
    return ((Script)goo).run();
  }

  return goo;
}
catch (InstantiationException ex)
{
  throw new ScriptCompilationException(
    scriptSource, "Could not instantiate Groovy script class: " + scriptClass.getName(), ex);
}
catch (IllegalAccessException ex) {
  throw new ScriptCompilationException(
    scriptSource, "Could not access Groovy script constructor: " + scriptClass.getName(), ex);
}
</code></pre>

<p>  }
```</p>

<p>执行到第238行的时候</p>

<p><code>
GroovyObject goo = (GroovyObject)scriptClass.newInstance();//line 238
</code></p>

<p>突然发现调用了</p>

<p><code>
java.lang.ClassLoader.loadClass(ClassLoader.java:247)
</code></p>

<p>而我们看到上面第238行的逻辑其实就是实例化一个对象，然后进行强转，我们看看对应的字节码：</p>

<p><code>
 0: aload_2
 1: invokevirtual #164                // Method java/lang/Class.newInstance:()Ljava/lang/Object;
 4: checkcast     #168                // class groovy/lang/GroovyObject
 7: astore_3
</code></p>

<p>其实就对应这么几条字节码指令，其实在jvm里当我们执行checkcast指令的时候会触发类加载的动作：</p>

<p>```
void TemplateTable::checkcast() {</p>

<pre><code>...
call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::quicken_io_cc));
...
</code></pre>

<p>}</p>

<p>IRT_ENTRY(void, InterpreterRuntime::quicken_io_cc(JavaThread* thread))
  // Force resolving; quicken the bytecode
  int which = get_index_u2(thread, Bytecodes::_checkcast);
  constantPoolOop cpool = method(thread)->constants();
  // We'd expect to assert that we're only here to quicken bytecodes, but in a multithreaded
  // program we might have seen an unquick'd bytecode in the interpreter but have another
  // thread quicken the bytecode before we get here.
  // assert( cpool->tag_at(which).is_unresolved_klass(), "should only come here to quicken bytecodes" );
  klassOop klass = cpool->klass_at(which, CHECK);
  thread->set_vm_result(klass);
IRT_END</p>

<p>klassOop klass_at(int which, TRAPS) {</p>

<pre><code>constantPoolHandle h_this(THREAD, this);
return klass_at_impl(h_this, which, CHECK_NULL);
</code></pre>

<p>}</p>

<p>klassOop constantPoolOopDesc::klass_at_impl(constantPoolHandle this_oop, int which, TRAPS) {</p>

<pre><code>...
klassOop k_oop = SystemDictionary::resolve_or_fail(name, loader, h_prot, true, THREAD);
...
</code></pre>

<p>}</p>

<p>//SystemDictionary::resolve_or_fail最终会调用到下面这个方法
klassOop SystemDictionary::resolve_instance_class_or_null(Symbol* name, Handle class_loader, Handle protection_domain, TRAPS) {
  ...
  // Class is not in SystemDictionary so we have to do loading.
  // Make sure we are synchronized on the class loader before we proceed
  Handle lockObject = compute_loader_lock_object(class_loader, THREAD);
  check_loader_lock_contention(lockObject, THREAD);
  ObjectLocker ol(lockObject, THREAD, DoObjectLock);
  ...
  //此时会调用ClassLoader.loadClass来加载类了
  ...
}</p>

<p>Handle SystemDictionary::compute_loader_lock_object(Handle class_loader, TRAPS) {
  // If class_loader is NULL we synchronize on _system_loader_lock_obj
  if (class_loader.is_null()) {</p>

<pre><code>return Handle(THREAD, _system_loader_lock_obj);
</code></pre>

<p>  } else {</p>

<pre><code>return class_loader;
</code></pre>

<p>  }
}
```</p>

<p><code>SystemDictionary::resolve_instance_class_or_null</code>这个方法非常关键了，在里面我们看到会获取一把锁ObjectLocker，其相当于我们java代码里的<code>synchronized</code>关键字，而对象对应的是lockObject，这个对象是上面的<code>SystemDictionary::compute_loader_lock_object</code>方法返回的，从代码可知只要不是bootstrapClassloader加载的类就会返回当前classloader对象，也就是说当我们在加载一个类的时候其实是会持有当前类加载对象的锁的，在获取了这把锁之后就会调用ClassLoader.loadClass来加载类了。这其实就解释了<code>HSFBizProcessor-4-thread-4</code>这个线程为什么持有了<code>object 0x00000007608e6fc8, a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader</code>这个类加载的锁，不过遗憾的是因为这把锁不是java层面来显示加载的，因此我们在<code>jstack</code>线程dump的输出里居然看不到这把锁的存在.</p>

<h3>HSFBizProcessor-4-thread-5</h3>

<p>先上堆栈：</p>

<p>```
"HSFBizProcessor-4-thread-5":</p>

<pre><code>at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLoadedClass(Unknown Source)
- waiting to lock &lt;0x00000007608e6fc8&gt; (a com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader)
at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.DependentPolicy.loadClass(Unknown Source)
at org.eclipse.osgi.internal.loader.buddy.PolicyHandler.doBuddyClassLoading(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.loader.BundleLoader.findClass(Unknown Source)
at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(Unknown Source)
at com.alipay.cloudengine.extensions.equinox.KernelBundleClassLoader.loadClass(KernelBundleClassLoader.java:121)
at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:169)
</code></pre>

<p>```</p>

<p>这个线程栈其实和之前那个线程差不多，只是等的锁不一样，另外触发类加载的动作是<code>Class.forName</code>，获取大家也猜到了，其实是在下面两行堆栈之间同样获取了一把类加载器的锁</p>

<p>```</p>

<pre><code>at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
at java.lang.Class.forName0(Native Method)
</code></pre>

<p>```</p>

<p>这里的代码我也不细贴了，最终调用的jvm里的方法都是一样的，获取锁的逻辑也是一样的</p>

<h2>总结</h2>

<p>这个问题到目前为止应该挺清楚了，我们上面疑惑的锁对象为什么在堆栈里没有体现出来，但是其实线程已经持有了该锁，至于死锁发生的原因稍稍看看堆栈就明白了</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之javaagent原理完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/09/14/javaagent/"/>
    <updated>2015-09-14T13:17:50+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/09/14/javaagent</id>
    <content type="html"><![CDATA[<p><code>注:文章首发于InfoQ：</code><a href="http://www.infoq.com/cn/articles/javaagent-illustrated">JVM源码分析之javaagent原理完全解读</a></p>

<h2>概述</h2>

<p>本文重点讲述javaagent的具体实现，因为它面向的是我们java程序员，而且agent都是用java编写的，不需要太多的c/c++编程基础，不过这篇文章里也会讲到JVMTIAgent(c实现的)，因为javaagent的运行还是依赖于一个特殊的JVMTIAgent。</p>

<!-- more -->


<p>对于javaagent或许大家都听过，甚至使用过，常见的用法大致如下：</p>

<p><code>
java -javaagent:myagent.jar=mode=test Test
</code></p>

<p>我们通过-javaagent来指定我们编写的agent的jar路径（./myagent.jar）及要传给agent的参数（mode=test），这样在启动的时候这个agent就可以做一些我们想要它做的事了。</p>

<p>javaagent的主要的功能如下：</p>

<ul>
<li>可以在加载class文件之前做拦截把字节码做修改</li>
<li>可以在运行期将已经加载的类的字节码做变更，但是这种情况下会有很多的限制，后面会详细说</li>
<li>还有其他的一些小众的功能

<ul>
<li>获取所有已经被加载过的类</li>
<li>获取所有已经被初始化过了的类（执行过了clinit方法，是上面的一个子集）</li>
<li>获取某个对象的大小</li>
<li>将某个jar加入到bootstrapclasspath里作为高优先级被bootstrapClassloader加载</li>
<li>将某个jar加入到classpath里供AppClassloard去加载</li>
<li>设置某些native方法的前缀，主要在查找native方法的时候做规则匹配</li>
</ul>
</li>
</ul>


<p>想象一下可以让程序按照我们预期的逻辑去执行，听起来是不是挺酷的。</p>

<h2>JVMTI</h2>

<p><a href="http://docs.oracle.com/javase/7/docs/platform/jvmti/jvmti.html">JVMTI</a>全称JVM Tool Interface，是jvm暴露出来的一些供用户扩展的接口集合，JVMTI是基于事件驱动的，JVM每执行到一定的逻辑就会调用一些事件的回调接口（如果有的话），这些接口可以供开发者去扩展自己的逻辑。</p>

<p>比如说我们最常见的想在某个类的字节码文件读取之后类定义之前能修改相关的字节码，从而使创建的class对象是我们修改之后的字节码内容，那我们就可以实现一个回调函数赋给JvmtiEnv（JVMTI的运行时，通常一个JVMTIAgent对应一个jvmtiEnv，但是也可以对应多个）的回调方法集合里的ClassFileLoadHook，这样在接下来的类文件加载过程中都会调用到这个函数里来了，大致实现如下:</p>

<p>```</p>

<pre><code>jvmtiEventCallbacks callbacks;
jvmtiEnv *          jvmtienv = jvmti(agent);
jvmtiError          jvmtierror;
memset(&amp;callbacks, 0, sizeof(callbacks));
callbacks.ClassFileLoadHook = &amp;eventHandlerClassFileLoadHook;
jvmtierror = (*jvmtienv)-&gt;SetEventCallbacks( jvmtienv,
                                             &amp;callbacks,
                                             sizeof(callbacks));
</code></pre>

<p>```</p>

<h2>JVMTIAgent</h2>

<p>JVMTIAgent其实就是一个动态库，利用JVMTI暴露出来的一些接口来干一些我们想做但是正常情况下又做不到的事情，不过为了和普通的动态库进行区分，它一般会实现如下的一个或者多个函数：</p>

<p>```
JNIEXPORT jint JNICALL
Agent_OnLoad(JavaVM <em>vm, char </em>options, void *reserved);</p>

<p>JNIEXPORT jint JNICALL
Agent_OnAttach(JavaVM<em> vm, char</em> options, void* reserved);</p>

<p>JNIEXPORT void JNICALL
Agent_OnUnload(JavaVM *vm);</p>

<p>```</p>

<ul>
<li><code>Agent_OnLoad</code>函数，如果agent是在启动的时候加载的，也就是在vm参数里通过-agentlib来指定，那在启动过程中就会去执行这个agent里的<code>Agent_OnLoad</code>函数。</li>
<li><code>Agent_OnAttach</code>函数，如果agent不是在启动的时候加载的，是我们先attach到目标进程上，然后给对应的目标进程发送load命令来加载agent，在加载过程中就会调用<code>Agent_OnAttach</code>函数。</li>
<li><code>Agent_OnUnload</code>函数，在agent做卸载的时候调用，不过貌似基本上很少实现它。</li>
</ul>


<p>其实我们每天都在和JVMTIAgent打交道，只是你可能没有意识到而已，比如我们经常使用eclipse等工具对java代码做调试，其实就利用了jre自带的jdwp agent来实现的，只是由于eclipse等工具在没让你察觉的情况下将相关参数(类似<code>-agentlib:jdwp=transport=dt_socket,suspend=y,address=localhost:61349</code>)给自动加到程序启动参数列表里了，其中agentlib参数就是用来跟要加载的agent的名字，比如这里的jdwp(不过这不是动态库的名字，而JVM是会做一些名称上的扩展，比如在linux下会去找<code>libjdwp.so</code>的动态库进行加载，也就是在名字的基础上加前缀<code>lib</code>,再加后缀<code>.so</code>)，接下来会跟一堆相关的参数，会将这些参数传给<code>Agent_OnLoad</code>或者<code>Agent_OnAttach</code>函数里对应的<code>options</code>参数。</p>

<h2>javaagent</h2>

<p>说到javaagent必须要讲的是一个叫做instrument的JVMTIAgent（linux下对应的动态库是libinstrument.so），因为就是它来实现javaagent的功能的，另外instrument agent还有个别名叫JPLISAgent(Java Programming Language Instrumentation Services Agent)，从这名字里也完全体现了其最本质的功能：就是专门为java语言编写的插桩服务提供支持的。</p>

<h3>instrument agent</h3>

<p>instrument agent实现了<code>Agent_OnLoad</code>和<code>Agent_OnAttach</code>两方法，也就是说我们在用它的时候既支持启动的时候来加载agent，也支持在运行期来动态来加载这个agent，其中启动时加载agent还可以通过类似<code>-javaagent:myagent.jar</code>的方式来间接加载instrument agent，运行期动态加载agent依赖的是jvm的attach机制<a href="http://lovestblog.cn/blog/2014/06/18/jvm-attach/">JVM Attach机制实现</a>，通过发送load命令来加载agent。</p>

<p>instrument agent的核心数据结构如下：
```
struct _JPLISAgent {</p>

<pre><code>JavaVM *                mJVM;                   /* handle to the JVM */
JPLISEnvironment        mNormalEnvironment;     /* for every thing but retransform stuff */
JPLISEnvironment        mRetransformEnvironment;/* for retransform stuff only */
jobject                 mInstrumentationImpl;   /* handle to the Instrumentation instance */
jmethodID               mPremainCaller;         /* method on the InstrumentationImpl that does the premain stuff (cached to save lots of lookups) */
jmethodID               mAgentmainCaller;       /* method on the InstrumentationImpl for agents loaded via attach mechanism */
jmethodID               mTransform;             /* method on the InstrumentationImpl that does the class file transform */
jboolean                mRedefineAvailable;     /* cached answer to "does this agent support redefine" */
jboolean                mRedefineAdded;         /* indicates if can_redefine_classes capability has been added */
jboolean                mNativeMethodPrefixAvailable; /* cached answer to "does this agent support prefixing" */
jboolean                mNativeMethodPrefixAdded;     /* indicates if can_set_native_method_prefix capability has been added */
char const *            mAgentClassName;        /* agent class name */
char const *            mOptionsString;         /* -javaagent options string */
</code></pre>

<p>};</p>

<p>struct _JPLISEnvironment {</p>

<pre><code>jvmtiEnv *              mJVMTIEnv;              /* the JVM TI environment */
JPLISAgent *            mAgent;                 /* corresponding agent */
jboolean                mIsRetransformer;       /* indicates if special environment */
</code></pre>

<p>};</p>

<p>```</p>

<p>这里解释下几个重要项：
* mNormalEnvironment：主要提供正常的类transform及redefine功能的。
* mRetransformEnvironment：主要提供类retransform功能的。
* mInstrumentationImpl：这个对象非常重要，也是我们java agent和JVM进行交互的入口，或许写过javaagent的人在写<code>premain</code>以及<code>agentmain</code>方法的时候注意到了有个Instrumentation的参数，这个参数其实就是这里的对象。
* mPremainCaller：指向<code>sun.instrument.InstrumentationImpl.loadClassAndCallPremain</code>方法，如果agent是在启动的时候加载的，那该方法会被调用。
* mAgentmainCaller：指向<code>sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain</code>方法，该方法在通过attach的方式动态加载agent的时候调用。
* mTransform：指向<code>sun.instrument.InstrumentationImpl.transform</code>方法。
* mAgentClassName：在我们javaagent的MANIFEST.MF里指定的<code>Agent-Class</code>。
* mOptionsString：传给agent的一些参数。
* mRedefineAvailable：是否开启了redefine功能，在javaagent的MANIFEST.MF里设置<code>Can-Redefine-Classes:true</code>。
* mNativeMethodPrefixAvailable：是否支持native方法前缀设置，通样在javaagent的MANIFEST.MF里设置<code>Can-Set-Native-Method-Prefix:true</code>。
* mIsRetransformer：如果在javaagent的MANIFEST.MF文件里定义了<code>Can-Retransform-Classes:true</code>，那将会设置mRetransformEnvironment的mIsRetransformer为true。</p>

<h3>启动时加载instrument agent</h3>

<p>正如『概述』里提到的方式，就是启动的时候加载instrument agent，具体过程都在<code>InvocationAdapter.c</code>的<code>Agent_OnLoad</code>方法里，简单描述下过程：</p>

<ul>
<li>创建并初始化JPLISAgent</li>
<li>监听VMInit事件，在vm初始化完成之后做下面的事情：

<ul>
<li>创建InstrumentationImpl对象</li>
<li>监听ClassFileLoadHook事件</li>
<li>调用InstrumentationImpl的<code>loadClassAndCallPremain</code>方法，在这个方法里会去调用javaagent里MANIFEST.MF里指定的<code>Premain-Class</code>类的premain方法</li>
</ul>
</li>
<li>解析javaagent里MANIFEST.MF里的参数，并根据这些参数来设置JPLISAgent里的一些内容</li>
</ul>


<h3>运行时加载instrument agent</h3>

<p>运行时加载的方式，大致按照下面的方式来操作：
<code>
VirtualMachine vm = VirtualMachine.attach(pid);
vm.loadAgent(agentPath, agentArgs);
</code></p>

<p>上面会通过jvm的attach机制来请求目标jvm加载对应的agent，过程大致如下：</p>

<ul>
<li>创建并初始化JPLISAgent</li>
<li>解析javaagent里MANIFEST.MF里的参数</li>
<li>创建InstrumentationImpl对象</li>
<li>监听ClassFileLoadHook事件</li>
<li>调用InstrumentationImpl的<code>loadClassAndCallAgentmain</code>方法，在这个方法里会去调用javaagent里MANIFEST.MF里指定的<code>Agent-Class</code>类的<code>agentmain</code>方法</li>
</ul>


<h3>instrument agent的ClassFileLoadHook回调实现</h3>

<p>不管是启动时还是运行时加载的instrument agent都关注着同一个jvmti事件---<code>ClassFileLoadHook</code>，这个事件是在读取字节码文件之后回调时用的，这样可以对原来的字节码做修改，那这里面究竟是怎样实现的呢？</p>

<p>```
void JNICALL
eventHandlerClassFileLoadHook(  jvmtiEnv *              jvmtienv,</p>

<pre><code>                            JNIEnv *                jnienv,
                            jclass                  class_being_redefined,
                            jobject                 loader,
                            const char*             name,
                            jobject                 protectionDomain,
                            jint                    class_data_len,
                            const unsigned char*    class_data,
                            jint*                   new_class_data_len,
                            unsigned char**         new_class_data) {
JPLISEnvironment * environment  = NULL;

environment = getJPLISEnvironment(jvmtienv);

/* if something is internally inconsistent (no agent), just silently return without touching the buffer */
if ( environment != NULL ) {
    jthrowable outstandingException = preserveThrowable(jnienv);
    transformClassFile( environment-&gt;mAgent,
                        jnienv,
                        loader,
                        name,
                        class_being_redefined,
                        protectionDomain,
                        class_data_len,
                        class_data,
                        new_class_data_len,
                        new_class_data,
                        environment-&gt;mIsRetransformer);
    restoreThrowable(jnienv, outstandingException);
}
</code></pre>

<p>}
```</p>

<p>先根据jvmtiEnv取得对应的JPLISEnvironment，因为上面我已经说到其实有两个JPLISEnvironment（并且有两个jvmtiEnv），其中一个专门做retransform的，而另外一个用来做其他的事情，根据不同的用途我们在注册具体的ClassFileTransformer的时候也是分开的，对于作为retransform用的ClassFileTransformer我们会注册到一个单独的TransformerManager里。</p>

<p>接着调用transformClassFile方法，由于函数实现比较长，我这里就不贴代码了，大致意思就是调用InstrumentationImpl对象的transform方法，根据最后那个参数来决定选哪个TransformerManager里的ClassFileTransformer对象们做transform操作。</p>

<p>```
 private byte[]</p>

<pre><code>transform(  ClassLoader         loader,
            String              classname,
            Class               classBeingRedefined,
            ProtectionDomain    protectionDomain,
            byte[]              classfileBuffer,
            boolean             isRetransformer) {
    TransformerManager mgr = isRetransformer?
                                    mRetransfomableTransformerManager :
                                    mTransformerManager;
    if (mgr == null) {
        return null; // no manager, no transform
    } else {
        return mgr.transform(   loader,
                                classname,
                                classBeingRedefined,
                                protectionDomain,
                                classfileBuffer);
    }
}
</code></pre>

<p>  public byte[]</p>

<pre><code>transform(  ClassLoader         loader,
            String              classname,
            Class               classBeingRedefined,
            ProtectionDomain    protectionDomain,
            byte[]              classfileBuffer) {
    boolean someoneTouchedTheBytecode = false;

    TransformerInfo[]  transformerList = getSnapshotTransformerList();

    byte[]  bufferToUse = classfileBuffer;

    // order matters, gotta run 'em in the order they were added
    for ( int x = 0; x &lt; transformerList.length; x++ ) {
        TransformerInfo         transformerInfo = transformerList[x];
        ClassFileTransformer    transformer = transformerInfo.transformer();
        byte[]                  transformedBytes = null;

        try {
            transformedBytes = transformer.transform(   loader,
                                                        classname,
                                                        classBeingRedefined,
                                                        protectionDomain,
                                                        bufferToUse);
        }
        catch (Throwable t) {
            // don't let any one transformer mess it up for the others.
            // This is where we need to put some logging. What should go here? FIXME
        }

        if ( transformedBytes != null ) {
            someoneTouchedTheBytecode = true;
            bufferToUse = transformedBytes;
        }
    }

    // if someone modified it, return the modified buffer.
    // otherwise return null to mean "no transforms occurred"
    byte [] result;
    if ( someoneTouchedTheBytecode ) {
        result = bufferToUse;
    }
    else {
        result = null;
    }

    return result;
}   
</code></pre>

<p>```</p>

<p>以上是最终调到的java代码，可以看到已经调用到我们自己编写的javaagent代码里了，我们一般是实现一个ClassFileTransformer类，然后创建一个对象注册了对应的TransformerManager里。</p>

<h2>Class Transform的实现</h2>

<p>这里说的class transform其实是狭义的，主要是针对第一次类文件加载的时候就要求被transform的场景，在加载类文件的时候发出ClassFileLoad的事件，然后交给instrumenat agent来调用javaagent里注册的ClassFileTransformer实现字节码的修改。</p>

<h2>Class Redefine的实现</h2>

<p>类重新定义，这是Instrumentation提供的基础功能之一，主要用在已经被加载过的类上，想对其进行修改，要做这件事，我们必须要知道两个东西，一个是要修改哪个类，另外一个是那个类你想修改成怎样的结构，有了这两信息之后于是你就可以通过InstrumentationImpl的下面的redefineClasses方法去操作了：</p>

<p>```
public void</p>

<pre><code>redefineClasses(ClassDefinition[]   definitions)
        throws  ClassNotFoundException {
    if (!isRedefineClassesSupported()) {
        throw new UnsupportedOperationException("redefineClasses is not supported in this environment");
    }
    if (definitions == null) {
        throw new NullPointerException("null passed as 'definitions' in redefineClasses");
    }
    for (int i = 0; i &lt; definitions.length; ++i) {
        if (definitions[i] == null) {
            throw new NullPointerException("element of 'definitions' is null in redefineClasses");
        }
    }
    if (definitions.length == 0) {
        return; // short-circuit if there are no changes requested
    }

    redefineClasses0(mNativeAgent, definitions);
}
</code></pre>

<p>```</p>

<p>在JVM里对应的实现是创建一个<code>VM_RedefineClasses</code>的<code>VM_Operation</code>，注意执行它的时候会stop the world的：</p>

<p><code>
jvmtiError
JvmtiEnv::RedefineClasses(jint class_count, const jvmtiClassDefinition* class_definitions) {
//TODO: add locking
  VM_RedefineClasses op(class_count, class_definitions, jvmti_class_load_kind_redefine);
  VMThread::execute(&amp;op);
  return (op.check_error());
} /* end RedefineClasses */
</code></p>

<p>这个过程我尽量用语言来描述清楚，不详细贴代码了，因为代码量实在有点大：</p>

<ul>
<li>挨个遍历要批量重定义的jvmtiClassDefinition</li>
<li>然后读取新的字节码，如果有关注ClassFileLoadHook事件的，还会走对应的transform来对新的字节码再做修改</li>
<li>字节码解析好，创建一个klassOop对象</li>
<li>对比新老类，并要求如下：

<ul>
<li>父类是同一个</li>
<li>实现的接口数也要相同，并且是相同的接口</li>
<li>类访问符必须一致</li>
<li>字段数和字段名要一致</li>
<li>新增或删除的方法必须是private static/final的</li>
<li>可以修改方法</li>
</ul>
</li>
<li>对新类做字节码校验</li>
<li>合并新老类的常量池</li>
<li>如果老类上有断点，那都清除掉</li>
<li>对老类做jit去优化</li>
<li>对新老方法匹配的方法的jmethodid做更新，将老的jmethodId更新到新的method上</li>
<li>新类的常量池的holer指向老的类</li>
<li>将新类和老类的一些属性做交换，比如常量池，methods，内部类</li>
<li>初始化新的vtable和itable</li>
<li>交换annotation的method,field,paramenter</li>
<li>遍历所有当前类的子类，修改他们的vtable及itable</li>
</ul>


<p>上面是基本的过程，总的来说就是只更新了类里内容，相当于只更新了指针指向的内容，并没有更新指针，避免了遍历大量已有类对象对它们进行更新带来的开销。</p>

<h2>Class Retransform的实现</h2>

<p>retransform class可以简单理解为回滚操作，具体回滚到哪个版本，这个需要看情况而定，下面不管那种情况都有一个前提，那就是javaagent已经要求要有retransform的能力了：</p>

<ul>
<li>如果类是在第一次加载的的时候就做了transform，那么做retransform的时候会将代码回滚到transform之后的代码</li>
<li>如果类是在第一次加载的的时候没有任何变化，那么做retransform的时候会将代码回滚到最原始的类文件里的字节码</li>
<li>如果类已经被加载了，期间类可能做过多次redefine(比如被另外一个agent做过)，但是接下来加载一个新的agent要求有retransform的能力了，然后对类做redefine的动作，那么retransform的时候会将代码回滚到上一个agent最后一次做redefine后的字节码</li>
</ul>


<p>我们从InstrumentationImpl的<code>retransformClasses</code>方法参数看猜到应该是做回滚操作，因为我们只指定了class</p>

<p>```</p>

<pre><code>public void
retransformClasses(Class&lt;?&gt;[] classes) {
    if (!isRetransformClassesSupported()) {
        throw new UnsupportedOperationException(
          "retransformClasses is not supported in this environment");
    }
    retransformClasses0(mNativeAgent, classes);
}
</code></pre>

<p>```</p>

<p>不过retransform的实现其实也是通过redefine的功能来实现，在类加载的时候有比较小的差别，主要体现在究竟会走哪些transform上，如果当前是做retransform的话，那将忽略那些注册到正常的TransformerManager里的ClassFileTransformer，而只会走专门为retransform而准备的TransformerManager的ClassFileTransformer，不然想象一下字节码又被无声无息改成某个中间态了。</p>

<p>```
private:
  void post_all_envs() {</p>

<pre><code>if (_load_kind != jvmti_class_load_kind_retransform) {
  // for class load and redefine,
  // call the non-retransformable agents
  JvmtiEnvIterator it;
  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {
    if (!env-&gt;is_retransformable() &amp;&amp; env-&gt;is_enabled(JVMTI_EVENT_CLASS_FILE_LOAD_HOOK)) {
      // non-retransformable agents cannot retransform back,
      // so no need to cache the original class file bytes
      post_to_env(env, false);
    }
  }
}
JvmtiEnvIterator it;
for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {
  // retransformable agents get all events
  if (env-&gt;is_retransformable() &amp;&amp; env-&gt;is_enabled(JVMTI_EVENT_CLASS_FILE_LOAD_HOOK)) {
    // retransformable agents need to cache the original class file
    // bytes if changes are made via the ClassFileLoadHook
    post_to_env(env, true);
  }
}
</code></pre>

<p>  }
```</p>

<h2>javaagent的其他小众功能</h2>

<p>javaagent除了做字节码上面的修改之外，其实还有一些小功能，有时候还是挺有用的</p>

<ul>
<li><p>获取所有已经被加载的类
<code>
  Class[] getAllLoadedClasses();
</code></p></li>
<li><p>获取所有已经被初始化过了的类
<code>
Class[] getInitiatedClasses(ClassLoader loader);
</code></p></li>
<li><p>获取某个对象的大小
<code>
long getObjectSize(Object objectToSize);
</code></p></li>
<li><p>将某个jar加入到bootstrapclasspath里优先其他jar被加载
<code>
void appendToBootstrapClassLoaderSearch(JarFile jarfile);
</code></p></li>
<li><p>将某个jar加入到classpath里供appclassloard去加载
<code>
void appendToSystemClassLoaderSearch(JarFile jarfile);
</code></p></li>
<li>设置某些native方法的前缀，主要在找native方法的时候做规则匹配
<code>
void setNativeMethodPrefix(ClassFileTransformer transformer, String prefix);
</code></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[进程物理内存远大于Xmx的问题分析]]></title>
    <link href="http://nijiaben.github.io/blog/2015/08/21/rssxmx/"/>
    <updated>2015-08-21T18:58:53+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/08/21/rssxmx</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>最近经常被问到一个问题，"为什么我们系统进程占用的物理内存(Res/Rss)会远远大于设置的Xmx值"，比如Xmx设置1.7G，但是top看到的Res的值却达到了3.0G，随着进程的运行，Res的值还在递增，直到达到某个值，被OS当做bad process直接被kill掉了。</p>

<!-- more -->


<p>```
top - 16:57:47 up 73 days,  4:12,  8 users,  load average: 6.78, 9.68, 13.31
Tasks: 130 total,   1 running, 123 sleeping,   6 stopped,   0 zombie
Cpu(s): 89.9%us,  5.6%sy,  0.0%ni,  2.0%id,  0.7%wa,  0.7%hi,  1.2%si,  0.0%st</p>

<pre><code>...
</code></pre>

<p>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
22753 admin     20   0 4252m 3.0g  17m S 192.8 52.7 151:47.59 /opt/taobao/java/bin/java -server -Xms1700m -Xmx1700m -Xmn680m -Xss256k -XX:PermSize=128m -XX:MaxPermSize=128m -XX:+UseStringCache -XX:+
   40 root      20   0     0    0    0 D  0.3  0.0   5:53.07 [kswapd0]
```</p>

<h2>物理内存大于Xmx可能吗</h2>

<p>先说下Xmx，这个vm配置只包括我们熟悉的新生代和老生代的最大值，不包括持久代，也不包括CodeCache，还有我们常听说的堆外内存从名字上一看也知道没有包括在内，当然还有其他内存也不会算在内等，因此理论上我们看到物理内存大于Xmx也是可能的，不过超过太多估计就可能有问题了。</p>

<h2>物理内存和虚拟内存间的映射关系</h2>

<p>我们知道os在内存上面的设计是花了心思的，为了让资源得到最大合理利用，在物理内存之上搞一层虚拟地址，同一台机器上每个进程可访问的虚拟地址空间大小都是一样的，为了屏蔽掉复杂的到物理内存的映射，该工作os直接做了，当需要物理内存的时候，当前虚拟地址又没有映射到物理内存上的时候，就会发生缺页中断，由内核去为之准备一块物理内存，所以即使我们分配了一块1G的虚拟内存，物理内存上不一定有一块1G的空间与之对应，那到底这块虚拟内存块到底映射了多少物理内存呢，这个我们在linux下可以通过<code>/proc/&lt;pid&gt;/smaps</code>这个文件看到，其中的Size表示虚拟内存大小，而Rss表示的是物理内存，所以从这层意义上来说和虚拟内存块对应的物理内存块不应该超过此虚拟内存块的空间范围</p>

<p><code>
8dc00000-100000000 rwxp 00000000 00:00 0
Size:            1871872 kB
Rss:             1798444 kB
Pss:             1798444 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:   1798444 kB
Referenced:      1798392 kB
Anonymous:       1798444 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
</code>
此次为了排查这个问题，我特地写了个简单的分析工具来分析这个问题，将连续的虚拟内存块合并做统计，一般来说连续分配的内存块还是有一定关系的，当然也不能完全肯定这种关系，得到的效果大致如下：</p>

<p>```
from->to    vs rss rss_percentage(rss/total_rss) merge_block_count</p>

<p>0x8dc00000->0x30c9a20000      1871872      1487480      53.77%     1
0x7faf7a4c5000->0x7fffa7dd9000      1069464      735996      26.60%     440
0x7faf50c75000->0x7faf6c02a000      445996      226860      8.20%     418
0x7faf6c027000->0x7faf78010000      196452      140640      5.08%     492
0x418e8000->0x100000000      90968      90904      3.29%     1
0x7faf48000000->0x7faf50c78000      131072      35120      1.27%     4
0x7faf28000000->0x7faf3905e000      196608      20708      0.75%     6
0x7faf38000000->0x7faf4ad83000      196608      17036      0.62%     6
0x7faf78009000->0x7faf7a4c6000      37612      10440      0.38%     465
0x30c9e00000->0x30ca202000      3656      716      0.03%     5
0x7faf20000000->0x7faf289c7000      65536      132      0.00%     2
0x30c9a00000->0x30c9c20000      128      108      0.00%     1
0x30ca600000->0x30cae83000      2164      76      0.00%     5
0x30cbe00000->0x30cca16000      2152      68      0.00%     5
0x7fffa7dc3000->0x7fffa7e00000      92      48      0.00%     1
0x30cca00000->0x7faf21dba000      2148      32      0.00%     5
0x30cb200000->0x30cbe16000      2080      28      0.00%     4
0x30cae00000->0x30cb207000      2576      20      0.00%     4
0x30ca200000->0x30ca617000      2064      16      0.00%     4
0x40000000->0x4010a000      36      12      0.00%     2
0x30c9c1f000->0x30c9f89000      12      12      0.00%     3
0x40108000->0x471be000      8      8      0.00%     1
0x7fffa7dff000->0x0      4      4      0.00%     0
```</p>

<p>当然这只是一个简单的分析，如果更有价值需要我们挖掘更多的点出来，比如每个内存块是属于哪块memory pool，到底是什么地方分配的等，不过需要jvm支持(<code>注：上面的第一条，其实就是new+old+perm对应的虚拟内存及其物理内存映射情况</code>)。</p>

<h2>进程满足什么条件会被os因为oom而被kill</h2>

<p>当一个进程无故消失的时候，我们一般看<code>/var/log/message</code>里是否有<code>Out of memory: Kill process</code>关键字(如果是java进程我们先看是否有crash日志)，如果有就说明是被os因为oom而被kill了：</p>

<p>```
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238016] java invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238022] java cpuset=/ mems_allowed=0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238024] Pid: 25371, comm: java Not tainted 2.6.32-220.23.2.ali878.el6.x86_64 #1
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238026] Call Trace:
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238039]  [<ffffffff810c35e1>] ? cpuset_print_task_mems_allowed+0x91/0xb0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238068]  [<ffffffff81114d70>] ? dump_header+0x90/0x1b0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238074]  [<ffffffff810e1b2e>] ? <strong>delayacct_freepages_end+0x2e/0x30
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238079]  [<ffffffff81213ffc>] ? security_real_capable_noaudit+0x3c/0x70
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238082]  [<ffffffff811151fa>] ? oom_kill_process+0x8a/0x2c0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238084]  [<ffffffff81115131>] ? select_bad_process+0xe1/0x120
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238087]  [<ffffffff81115650>] ? out_of_memory+0x220/0x3c0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238093]  [<ffffffff81125929>] ? </strong>alloc_pages_nodemask+0x899/0x930
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238099]  [<ffffffff81159b6a>] ? alloc_pages_current+0xaa/0x110
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238102]  [<ffffffff81111ea7>] ? <strong>page_cache_alloc+0x87/0x90
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238105]  [<ffffffff81127f4b>] ? </strong>do_page_cache_readahead+0xdb/0x270
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238108]  [<ffffffff81128101>] ? ra_submit+0x21/0x30
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238110]  [<ffffffff81113e17>] ? filemap_fault+0x5b7/0x600
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238113]  [<ffffffff8113ca64>] ? <strong>do_fault+0x54/0x510
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238116]  [<ffffffff811140a0>] ? </strong>generic_file_aio_write+0x240/0x470
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238118]  [<ffffffff8113d017>] ? handle_pte_fault+0xf7/0xb50
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238121]  [<ffffffff8111438e>] ? generic_file_aio_write+0xbe/0xe0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238133]  [<ffffffffa008a171>] ? ext4_file_write+0x61/0x1e0 [ext4]
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238135]  [<ffffffff8113dc54>] ? handle_mm_fault+0x1e4/0x2b0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238138]  [<ffffffff81177c7a>] ? do_sync_write+0xfa/0x140
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238143]  [<ffffffff81042c69>] ? __do_page_fault+0x139/0x480
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238147]  [<ffffffff8118ad22>] ? vfs_ioctl+0x22/0xa0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238151]  [<ffffffff814e4f8e>] ? do_page_fault+0x3e/0xa0
Aug 19 08:32:38 mybank-ant kernel: : [6176841.238154]  [<ffffffff814e2345>] ? page_fault+0x25/0x30</p>

<p>...</p>

<p>Aug 19 08:32:38 mybank-ant kernel: : [6176841.247969] [24673]  1801 24673  1280126   926068   1       0             0 java
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247971] [25084]  1801 25084     3756      101   0       0             0 top
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247973] [25094]  1801 25094    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247975] [25098]  1801 25098    25233       31   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247977] [25100]  1801 25100    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247979] [25485]  1801 25485    25233       30   1       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247981] [26055]  1801 26055    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247984] [26069]  1801 26069    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247986] [26081]  1801 26081    25233       30   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247988] [26147]  1801 26147    25233       32   0       0             0 tail
Aug 19 08:32:38 mybank-ant kernel: : [6176841.247990] Out of memory: Kill process 24673 (java) score 946 or sacrifice child
Aug 19 08:32:38 mybank-ant kernel: : [6176841.249016] Killed process 24673, UID 1801, (java) total-vm:5120504kB, anon-rss:3703788kB, file-rss:484kB
```</p>

<p>从上面我们看到了一个堆栈，也就是内核里选择被kill进程的过程，这个过程会对进程进行一系列的计算，每个进程都会给它们计算一个score，这个分数会记录在<code>/proc/&lt;pid&gt;/oom_score</code>里，通常这个分数越高，就越危险，被kill的可能性就越大，下面将内核相关的代码贴出来，有兴趣的可以看看，其中代码注释上也写了挺多相关的东西了：</p>

<p>```
/<em>
 * Simple selection loop. We chose the process with the highest
 * number of 'points'. We expect the caller will lock the tasklist.
 *
 * (not docbooked, we don't want this one cluttering up the manual)
 </em>/
static struct task_struct <em>select_bad_process(unsigned long </em>ppoints,</p>

<pre><code>                    struct mem_cgroup *mem)
</code></pre>

<p>{</p>

<pre><code>struct task_struct *p;
struct task_struct *chosen = NULL;
struct timespec uptime;
*ppoints = 0;

do_posix_clock_monotonic_gettime(&amp;uptime);
for_each_process(p) {
    unsigned long points;

    /*
     * skip kernel threads and tasks which have already released
     * their mm.
     */
    if (!p-&gt;mm)
        continue;
    /* skip the init task */
    if (is_global_init(p))
        continue;
    if (mem &amp;&amp; !task_in_mem_cgroup(p, mem))
        continue;

    /*
     * This task already has access to memory reserves and is
     * being killed. Don't allow any other task access to the
     * memory reserve.
     *
     * Note: this may have a chance of deadlock if it gets
     * blocked waiting for another task which itself is waiting
     * for memory. Is there a better alternative?
     */
    if (test_tsk_thread_flag(p, TIF_MEMDIE))
        return ERR_PTR(-1UL);

    /*
     * This is in the process of releasing memory so wait for it
     * to finish before killing some other task by mistake.
     *
     * However, if p is the current task, we allow the 'kill' to
     * go ahead if it is exiting: this will simply set TIF_MEMDIE,
     * which will allow it to gain access to memory reserves in
     * the process of exiting and releasing its resources.
     * Otherwise we could get an easy OOM deadlock.
     */
    if (p-&gt;flags &amp; PF_EXITING) {
        if (p != current)
            return ERR_PTR(-1UL);

        chosen = p;
        *ppoints = ULONG_MAX;
    }

    if (p-&gt;signal-&gt;oom_adj == OOM_DISABLE)
        continue;

    points = badness(p, uptime.tv_sec);
    if (points &gt; *ppoints || !chosen) {
        chosen = p;
        *ppoints = points;
    }
}

return chosen;
</code></pre>

<p>}</p>

<p>/<em>*
 * badness - calculate a numeric value for how bad this task has been
 * @p: task struct of which task we should calculate
 * @uptime: current uptime in seconds
 *
 * The formula used is relatively simple and documented inline in the
 * function. The main rationale is that we want to select a good task
 * to kill when we run out of memory.
 *
 * Good in this context means that:
 * 1) we lose the minimum amount of work done
 * 2) we recover a large amount of memory
 * 3) we don't kill anything innocent of eating tons of memory
 * 4) we want to kill the minimum amount of processes (one)
 * 5) we try to kill the process the user expects us to kill, this
 *    algorithm has been meticulously tuned to meet the principle
 *    of least surprise ... (be careful when you change it)
 </em>/</p>

<p>unsigned long badness(struct task_struct *p, unsigned long uptime)
{</p>

<pre><code>unsigned long points, cpu_time, run_time;
struct mm_struct *mm;
struct task_struct *child;
int oom_adj = p-&gt;signal-&gt;oom_adj;
struct task_cputime task_time;
unsigned long utime;
unsigned long stime;

if (oom_adj == OOM_DISABLE)
    return 0;

task_lock(p);
mm = p-&gt;mm;
if (!mm) {
    task_unlock(p);
    return 0;
}

/*
 * The memory size of the process is the basis for the badness.
 */
points = mm-&gt;total_vm;

/*
 * After this unlock we can no longer dereference local variable `mm'
 */
task_unlock(p);

/*
 * swapoff can easily use up all memory, so kill those first.
 */
if (p-&gt;flags &amp; PF_OOM_ORIGIN)
    return ULONG_MAX;

/*
 * Processes which fork a lot of child processes are likely
 * a good choice. We add half the vmsize of the children if they
 * have an own mm. This prevents forking servers to flood the
 * machine with an endless amount of children. In case a single
 * child is eating the vast majority of memory, adding only half
 * to the parents will make the child our kill candidate of choice.
 */
list_for_each_entry(child, &amp;p-&gt;children, sibling) {
    task_lock(child);
    if (child-&gt;mm != mm &amp;&amp; child-&gt;mm)
        points += child-&gt;mm-&gt;total_vm/2 + 1;
    task_unlock(child);
}

/*
 * CPU time is in tens of seconds and run time is in thousands
     * of seconds. There is no particular reason for this other than
     * that it turned out to work very well in practice.
 */
thread_group_cputime(p, &amp;task_time);
utime = cputime_to_jiffies(task_time.utime);
stime = cputime_to_jiffies(task_time.stime);
cpu_time = (utime + stime) &gt;&gt; (SHIFT_HZ + 3);


if (uptime &gt;= p-&gt;start_time.tv_sec)
    run_time = (uptime - p-&gt;start_time.tv_sec) &gt;&gt; 10;
else
    run_time = 0;

if (cpu_time)
    points /= int_sqrt(cpu_time);
if (run_time)
    points /= int_sqrt(int_sqrt(run_time));

/*
 * Niced processes are most likely less important, so double
 * their badness points.
 */
if (task_nice(p) &gt; 0)
    points *= 2;

/*
 * Superuser processes are usually more important, so we make it
 * less likely that we kill those.
 */
if (has_capability_noaudit(p, CAP_SYS_ADMIN) ||
    has_capability_noaudit(p, CAP_SYS_RESOURCE))
    points /= 4;

/*
 * We don't want to kill a process with direct hardware access.
 * Not only could that mess up the hardware, but usually users
 * tend to only have this flag set on applications they think
 * of as important.
 */
if (has_capability_noaudit(p, CAP_SYS_RAWIO))
    points /= 4;

/*
 * If p's nodes don't overlap ours, it may still help to kill p
 * because p may have allocated or otherwise mapped memory on
 * this node before. However it will be less likely.
 */
if (!has_intersects_mems_allowed(p))
    points /= 8;

/*
 * Adjust the score by oom_adj.
 */
if (oom_adj) {
    if (oom_adj &gt; 0) {
        if (!points)
            points = 1;
        points &lt;&lt;= oom_adj;
    } else
        points &gt;&gt;= -(oom_adj);
}
</code></pre>

<h1>ifdef DEBUG</h1>

<pre><code>printk(KERN_DEBUG "OOMkill: task %d (%s) got %lu points\n",
p-&gt;pid, p-&gt;comm, points);
</code></pre>

<h1>endif</h1>

<pre><code>return points;
</code></pre>

<p>}
```</p>

<h2>物理内存到底去哪了？</h2>

<h3>DirectByteBuffer冰山对象？</h3>

<p>这是我们查这个问题首先要想到的一个地方，是否是因为什么地方不断创建DirectByteBuffer对象，但是由于没有被回收导致了内存泄露呢，之前有篇文章已经详细介绍了这种特殊对象<a href="http://lovestblog.cn/blog/2015/05/12/direct-buffer/">JVM源码分析之堆外内存完全解读</a>，对阿里内部的童鞋，可以直接使用zprofiler的heap视图里的堆外内存分析功能拿到统计结果，知道后台到底绑定了多少堆外内存还没有被回收：</p>

<p><code>
object  position    limit   capacity
 java.nio.DirectByteBuffer @ 0x760afaed0    133 133 6380562
 java.nio.DirectByteBuffer @ 0x790d51ae0    0   262144  262144
 java.nio.DirectByteBuffer @ 0x790d20b80    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x790d20b40    0   262144  262144
 java.nio.DirectByteBuffer @ 0x790d20b00    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x771ba3608    0   262144  262144
 java.nio.DirectByteBuffer @ 0x771ba35c8    133934  133934  262144
 java.nio.DirectByteBuffer @ 0x7c5c9e250    0   131072  131072
 java.nio.DirectByteBuffer @ 0x7c5c9e210    74670   74670   131072
 java.nio.DirectByteBuffer @ 0x7c185cd10    0   131072  131072
 java.nio.DirectByteBuffer @ 0x7c185ccd0    98965   98965   131072
 java.nio.DirectByteBuffer @ 0x7b181c980    65627   65627   131072
 java.nio.DirectByteBuffer @ 0x7a40d6e40    0   131072  131072
 java.nio.DirectByteBuffer @ 0x794ac3320    0   131072  131072
 java.nio.DirectByteBuffer @ 0x794a7a418    80490   80490   131072
 java.nio.DirectByteBuffer @ 0x77279e1d8    0   131072  131072
 java.nio.DirectByteBuffer @ 0x77279dde8    65627   65627   131072
 java.nio.DirectByteBuffer @ 0x76ea84000    0   131072  131072
 java.nio.DirectByteBuffer @ 0x76ea83fc0    82549   82549   131072
 java.nio.DirectByteBuffer @ 0x764d8d678    0   0   131072
 java.nio.DirectByteBuffer @ 0x764d8d638    0   0   131072
 java.nio.DirectByteBuffer @ 0x764d8d5f8    0   0   131072
 java.nio.DirectByteBuffer @ 0x761a76340    0   131072  131072
 java.nio.DirectByteBuffer @ 0x761a76300    74369   74369   131072
 java.nio.DirectByteBuffer @ 0x7607423d0    0   131072  131072
 总共: 25 / 875 条目; 还有850条,双击展开 1267762 3826551 12083282
</code></p>

<h3>某个动态库里频繁分配？</h3>

<p>对于动态库里频繁分配的问题，主要得使用google的perftools工具了，该工具网上介绍挺多的，就不对其用法做详细介绍了，通过该工具我们能得到native方法分配内存的情况，该工具主要利用了unix的一个环境变量LD_PRELOAD，它允许你要加载的动态库优先加载起来，相当于一个Hook了，于是可以针对同一个函数可以选择不同的动态库里的实现了，比如googleperftools就是将malloc方法替换成了tcmalloc的实现，这样就可以跟踪内存分配路径了，得到的效果类似如下：</p>

<p>```
Total: 1670.0 MB
  1616.3  96.8%  96.8%   1616.3  96.8% zcalloc</p>

<pre><code>40.3   2.4%  99.2%     40.3   2.4% os::malloc
 9.4   0.6%  99.8%      9.4   0.6% init
 1.6   0.1%  99.9%      1.7   0.1% readCEN
 1.3   0.1%  99.9%      1.3   0.1% ObjectSynchronizer::omAlloc
 0.5   0.0% 100.0%   1591.0  95.3% Java_java_util_zip_Deflater_init
 0.1   0.0% 100.0%      0.1   0.0% _dl_allocate_tls
 0.1   0.0% 100.0%      0.2   0.0% addMetaName
 0.1   0.0% 100.0%      0.2   0.0% allocZip
 0.1   0.0% 100.0%      0.1   0.0% instanceKlass::add_dependent_nmethod
 0.1   0.0% 100.0%      0.1   0.0% newEntry
 0.0   0.0% 100.0%      0.0   0.0% strdup
 0.0   0.0% 100.0%     25.8   1.5% Java_java_util_zip_Inflater_init
 0.0   0.0% 100.0%      0.0   0.0% growMetaNames
 0.0   0.0% 100.0%      0.0   0.0% _dl_new_object
 0.0   0.0% 100.0%      0.0   0.0% pthread_cond_wait@GLIBC_2.2.5
 0.0   0.0% 100.0%      1.4   0.1% Thread::Thread
 0.0   0.0% 100.0%      0.0   0.0% pthread_cond_timedwait@GLIBC_2.2.5
 0.0   0.0% 100.0%      0.0   0.0% JLI_MemAlloc
 0.0   0.0% 100.0%      0.0   0.0% read_alias_file
 0.0   0.0% 100.0%      0.0   0.0% _nl_intern_locale_data
 0.0   0.0% 100.0%      0.0   0.0% nss_parse_service_list
 0.0   0.0% 100.0%      0.0   0.0% getprotobyname
 0.0   0.0% 100.0%      0.0   0.0% getpwuid
 0.0   0.0% 100.0%      0.0   0.0% _dl_check_map_versions
 0.0   0.0% 100.0%   1590.5  95.2% deflateInit2_
</code></pre>

<p>```</p>

<p>从上面的输出中我们看到了<code>zcalloc</code>函数总共分配了1616.3M的内存，还有<code>Java_java_util_zip_Deflater_init</code>分配了1591.0M内存，<code>deflateInit2_</code>分配了1590.5M，然而总共才分配了1670.0M内存，所以这几个函数肯定是调用者和被调用者的关系：</p>

<p>```
JNIEXPORT jlong JNICALL
Java_java_util_zip_Deflater_init(JNIEnv *env, jclass cls, jint level,</p>

<pre><code>                             jint strategy, jboolean nowrap)
</code></pre>

<p>{</p>

<pre><code>z_stream *strm = calloc(1, sizeof(z_stream));

if (strm == 0) {
    JNU_ThrowOutOfMemoryError(env, 0);
    return jlong_zero;
} else {
    char *msg;
    switch (deflateInit2(strm, level, Z_DEFLATED,
                         nowrap ? -MAX_WBITS : MAX_WBITS,
                         DEF_MEM_LEVEL, strategy)) {
      case Z_OK:
        return ptr_to_jlong(strm);
      case Z_MEM_ERROR:
        free(strm);
        JNU_ThrowOutOfMemoryError(env, 0);
        return jlong_zero;
      case Z_STREAM_ERROR:
        free(strm);
        JNU_ThrowIllegalArgumentException(env, 0);
        return jlong_zero;
      default:
        msg = strm-&gt;msg;
        free(strm);
        JNU_ThrowInternalError(env, msg);
        return jlong_zero;
    }
}
</code></pre>

<p>}</p>

<p>int ZEXPORT deflateInit2_(strm, level, method, windowBits, memLevel, strategy,</p>

<pre><code>              version, stream_size)
z_streamp strm;
int  level;
int  method;
int  windowBits;
int  memLevel;
int  strategy;
const char *version;
int stream_size;
</code></pre>

<p>{</p>

<pre><code>deflate_state *s;
int wrap = 1;
static const char my_version[] = ZLIB_VERSION;

ushf *overlay;
/* We overlay pending_buf and d_buf+l_buf. This works since the average
 * output size for (length,distance) codes is &lt;= 24 bits.
 */

if (version == Z_NULL || version[0] != my_version[0] ||
    stream_size != sizeof(z_stream)) {
    return Z_VERSION_ERROR;
}
if (strm == Z_NULL) return Z_STREAM_ERROR;

strm-&gt;msg = Z_NULL;
if (strm-&gt;zalloc == (alloc_func)0) {
    strm-&gt;zalloc = zcalloc;
    strm-&gt;opaque = (voidpf)0;
}
if (strm-&gt;zfree == (free_func)0) strm-&gt;zfree = zcfree;
</code></pre>

<h1>ifdef FASTEST</h1>

<pre><code>if (level != 0) level = 1;
</code></pre>

<h1>else</h1>

<pre><code>if (level == Z_DEFAULT_COMPRESSION) level = 6;
</code></pre>

<h1>endif</h1>

<pre><code>if (windowBits &lt; 0) { /* suppress zlib wrapper */
    wrap = 0;
    windowBits = -windowBits;
}
</code></pre>

<h1>ifdef GZIP</h1>

<pre><code>else if (windowBits &gt; 15) {
    wrap = 2;       /* write gzip wrapper instead */
    windowBits -= 16;
}
</code></pre>

<h1>endif</h1>

<pre><code>if (memLevel &lt; 1 || memLevel &gt; MAX_MEM_LEVEL || method != Z_DEFLATED ||
    windowBits &lt; 8 || windowBits &gt; 15 || level &lt; 0 || level &gt; 9 ||
    strategy &lt; 0 || strategy &gt; Z_FIXED) {
    return Z_STREAM_ERROR;
}
if (windowBits == 8) windowBits = 9;  /* until 256-byte window bug fixed */
s = (deflate_state *) ZALLOC(strm, 1, sizeof(deflate_state));
if (s == Z_NULL) return Z_MEM_ERROR;
strm-&gt;state = (struct internal_state FAR *)s;
s-&gt;strm = strm;

s-&gt;wrap = wrap;
s-&gt;gzhead = Z_NULL;
s-&gt;w_bits = windowBits;
s-&gt;w_size = 1 &lt;&lt; s-&gt;w_bits;
s-&gt;w_mask = s-&gt;w_size - 1;

s-&gt;hash_bits = memLevel + 7;
s-&gt;hash_size = 1 &lt;&lt; s-&gt;hash_bits;
s-&gt;hash_mask = s-&gt;hash_size - 1;
s-&gt;hash_shift =  ((s-&gt;hash_bits+MIN_MATCH-1)/MIN_MATCH);

s-&gt;window = (Bytef *) ZALLOC(strm, s-&gt;w_size, 2*sizeof(Byte));
s-&gt;prev   = (Posf *)  ZALLOC(strm, s-&gt;w_size, sizeof(Pos));
s-&gt;head   = (Posf *)  ZALLOC(strm, s-&gt;hash_size, sizeof(Pos));

s-&gt;lit_bufsize = 1 &lt;&lt; (memLevel + 6); /* 16K elements by default */

overlay = (ushf *) ZALLOC(strm, s-&gt;lit_bufsize, sizeof(ush)+2);
s-&gt;pending_buf = (uchf *) overlay;
s-&gt;pending_buf_size = (ulg)s-&gt;lit_bufsize * (sizeof(ush)+2L);

if (s-&gt;window == Z_NULL || s-&gt;prev == Z_NULL || s-&gt;head == Z_NULL ||
    s-&gt;pending_buf == Z_NULL) {
    s-&gt;status = FINISH_STATE;
    strm-&gt;msg = (char*)ERR_MSG(Z_MEM_ERROR);
    deflateEnd (strm);
    return Z_MEM_ERROR;
}
s-&gt;d_buf = overlay + s-&gt;lit_bufsize/sizeof(ush);
s-&gt;l_buf = s-&gt;pending_buf + (1+sizeof(ush))*s-&gt;lit_bufsize;

s-&gt;level = level;
s-&gt;strategy = strategy;
s-&gt;method = (Byte)method;

return deflateReset(strm);
</code></pre>

<p>}
```</p>

<p>上述代码也验证了他们这种关系。</p>

<p>那现在的问题就是找出哪里调用<code>Java_java_util_zip_Deflater_init</code>了，从这方法的命名上知道它是一个java的native方法实现，对应的是<code>java.util.zip.Deflater</code>这个类的<code>init</code>方法，所以要知道<code>init</code>方法哪里被调用了，跟踪调用栈我们会想到btrace工具，但是btrace是通过插桩的方式来实现的，对于native方法是无法插桩的，于是我们看调用它的地方，找到对应的方法，然后进行btrace脚本编写：</p>

<p>```
import com.sun.btrace.annotations.<em>;
import static com.sun.btrace.BTraceUtils.</em>;</p>

<p>@BTrace public class Test {</p>

<pre><code>@OnMethod(
    clazz="java.util.zip.Deflater",
    method="&lt;init&gt;"
)
public static void onnewThread(int i,boolean b) {
    jstack();
 }
</code></pre>

<p>}</p>

<p>```</p>

<p>于是跟踪对应的进程，我们能抓到调用Deflater构造函数的堆栈</p>

<p><code>
org.apache.commons.compress.compressors.deflate.DeflateCompressorOutputStream.&lt;init&gt;(DeflateCompressorOutputStream.java:47)
com.xxx.unimsg.parse.util.CompressUtil.deflateCompressAndEncode(CompressUtil.java:199)
com.xxx.unimsg.parse.util.CompressUtil.compress(CompressUtil.java:80)
com.xxx.unimsg.UnifyMessageHelper.compressXml(UnifyMessageHelper.java:65)
com.xxx.core.model.utils.UnifyMessageUtil.compressXml(UnifyMessageUtil.java:56)
com.xxx.repository.convert.BatchInDetailConvert.convertDO(BatchInDetailConvert.java:57)
com.xxx.repository.impl.IncomingDetailRepositoryImpl$1.store(IncomingDetailRepositoryImpl.java:43)
com.xxx.repository.helper.IdempotenceHelper.store(IdempotenceHelper.java:27)
com.xxx.repository.impl.IncomingDetailRepositoryImpl.store(IncomingDetailRepositoryImpl.java:40)
sun.reflect.GeneratedMethodAccessor274.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
java.lang.reflect.Method.invoke(Method.java:597)
org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:309)
org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
com.alipay.finsupport.component.monitor.MethodMonitorInterceptor.invoke(MethodMonitorInterceptor.java:45)
org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
...
</code></p>

<p>从上面的堆栈我们找出了调用<code>java.util.zip.Deflate.init()</code>的地方</p>

<h2>问题解决</h2>

<p>上面已经定位了具体的代码了，于是再细致跟踪了下对应的代码，其实并不是代码实现上的问题，而是代码设计上没有考虑到流量很大的场景，当流量很大的时候，不管自己系统是否能承受这么大的压力，都来者不拒，拿到数据就做deflate，而这个过程是需要分配堆外内存的，当量达到一定程度的时候此时会发生oom killer，另外我们在分析过程中发现其实物理内存是有下降的</p>

<p><code>
30071.txt:     0.0   0.0% 100.0%     96.7  57.0% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    196.0  72.6% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    290.3  78.5% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    392.7  83.6% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    592.8  88.5% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    700.7  91.0% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    799.1  91.9% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    893.9  92.2% Java_java_util_zip_Deflater_init
30071.txt:     0.0   0.0%  99.9%    114.2  63.7% Java_java_util_zip_Deflater_init
30071.txt:     0.0   0.0% 100.0%    105.1  52.1% Java_java_util_zip_Deflater_init
30071.txt:     0.2   0.0%  99.9%    479.7  87.4% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    782.2  90.1% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    986.9  92.3% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1086.3  92.9% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1185.1  93.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    941.5  92.1% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0% 100.0%   1288.8  94.1% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1394.8  94.9% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1492.5  95.1% Java_java_util_zip_Deflater_init
30071.txt:     0.5   0.0% 100.0%   1591.0  95.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    874.6  90.0% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    950.7  92.8% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    858.4  92.3% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    818.4  91.9% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    858.7  91.2% Java_java_util_zip_Deflater_init
30071.txt:     0.1   0.0%  99.9%    271.5  77.9% Java_java_util_zip_Deflater_init
30071.txt:     0.4   0.0%  99.9%   1260.4  93.1% Java_java_util_zip_Deflater_init
30071.txt:     0.3   0.0%  99.9%    976.4  90.6% Java_java_util_zip_Deflater_init
</code></p>

<p>这也就说明了其实代码使用上并没有错，因此建议将deflate放到队列里去做，比如限制队列大小是100，每次最多100个数据可以被deflate，处理一个放进一个，以至于不会被活活撑死。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之FinalReference完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/07/09/final-reference/"/>
    <updated>2015-07-09T14:35:31+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/07/09/final-reference</id>
    <content type="html"><![CDATA[<p><code>注:文章首发于InfoQ：</code><a href="" title="http://www.infoq.com/cn/articles/jvm-source-code-analysis-finalreference">JVM源码分析之FinalReference</a></p>

<h2>概述</h2>

<p>JAVA对象引用体系除了强引用之外，出于对性能、可扩展性等方面考虑还特地实现了四种其他引用：SoftReference、WeakReference、PhantomReference、FinalReference，本文主要想讲的是FinalReference，因为我们在使用内存分析工具比如zprofiler、mat等在分析一些oom的heap的时候，经常能看到 <code>java.lang.ref.Finalizer</code>占用的内存大小远远排在前面，而这个类占用的内存大小又和我们这次的主角<code>FinalReference</code>有着密不可分的关系。</p>

<!--more-->


<p>对于FinalReference及关联的内容，我们可能有如下印象：
* 自己代码里从没有使用过
* 线程dump之后，我们能看到一个叫做<code>Finalizer</code>的java线程
* 偶尔能注意到<code>java.lang.ref.Finalizer</code>的存在
* 我们在类里可能会写finalize方法</p>

<p>那FinalReference到底存在的意义是什么，以怎样的形式和我们的代码相关联呢，这是本文要理清的问题。</p>

<h2>JDK中的FinalReference</h2>

<p>首先我们看看FinalReference在JDK里的实现：</p>

<p>```
class FinalReference<T> extends Reference<T> {</p>

<pre><code>public FinalReference(T referent, ReferenceQueue&lt;? super T&gt; q) {
    super(referent, q);
}
</code></pre>

<p>}
```</p>

<p>大家应该注意到了类访问权限是package的，这也就意味着我们不能直接去对其进行扩展，但是JDK里对此类进行了扩展实现<code>java.lang.ref.Finalizer</code>，这个类也是我们在概述里提到的，而此类的访问权限也是package的，并且是final的，意味着真的不能被扩展了，接下来的重点我们围绕<code>java.lang.ref.Finalizer</code>展开(PS：后续讲Finalizer相关的其实也就是在说FinalReference)</p>

<p>```
final class Finalizer extends FinalReference { /* Package-private; must be in</p>

<pre><code>                                              same package as the Reference
                                              class */

/* A native method that invokes an arbitrary object's finalize method is
   required since the finalize method is protected
 */
static native void invokeFinalizeMethod(Object o) throws Throwable;

private static ReferenceQueue queue = new ReferenceQueue();
private static Finalizer unfinalized = null;
private static final Object lock = new Object();

private Finalizer
    next = null,
    prev = null;

private Finalizer(Object finalizee) {
    super(finalizee, queue);
    add();
}

/* Invoked by VM */
static void register(Object finalizee) {
    new Finalizer(finalizee);
}  

private void add() {
    synchronized (lock) {
        if (unfinalized != null) {
            this.next = unfinalized;
            unfinalized.prev = this;
        }
        unfinalized = this;
    }
}

...
</code></pre>

<p>   }</p>

<p>```</p>

<h3>Finalizer的构造函数</h3>

<p>从构造函数上我们获得下面的几个关键信息
* private：意味着我们在外面无法自己构建这类对象
* finalizee参数：FinalReference指向的对象引用
* 调用add方法：将当前对象插入到Finalizer对象链里，链里的对象和Finalizer类静态相关联，言外之意是在这个链里的对象都无法被gc掉，除非将这种引用关系剥离掉（因为Finalizer类无法被unload）</p>

<p>虽然外面无法创建Finalizer对象，但是注意到有一个register的静态方法，在方法里会创建这种对象，同时将这个对象加入到Finalizer对象链里，这个方法是被vm调用的，那么问题来了，vm在什么情况下会调用这个方法呢？</p>

<h2>Finalizer对象何时被注册到Finalizer对象链里</h2>

<p>类其实有挺多的修饰，比如final，abstract，public等等，如果一个类有final修饰，我们就说这个类是一个final类，上面列的都是语法层面我们可以显示标记的，在jvm里其实还给类标记其他一些符号，比如finalizer，表示这个类是一个finalizer类（为了和java.lang.ref.Fianlizer类进行区分，下文要提到的finalizer类的地方都说成f类），gc在处理这种类的对象的时候要做一些特殊的处理，如在这个对象被回收之前会调用一下它的finalize方法。</p>

<h3>如何判断一个类是不是一个f类</h3>

<p>在讲这个问题之前，我们先来看下<code>java.lang.Object</code>里的一个方法</p>

<p>```</p>

<pre><code>protected void finalize() throws Throwable { }
</code></pre>

<p>```</p>

<p>在Object类里定义了一个名为finalize的空方法，这意味着Java世界里的所有类都会继承这个方法，甚至可以覆写该方法，并且根据方法覆写原则，如果子类覆盖此方法，方法访问权限都是至少是protected级别的，这样其子类就算没有覆写此方法也会继承此方法。</p>

<p>而判断当前类是否是一个f类的标准并不仅仅是当前类是否含有一个参数为空，返回值为void的名为finalize的方法，而另外一个要求是<code>finalize方法必须非空</code>，因此我们的Object类虽然含有一个finalize方法，但是并不是一个f类，Object的对象在被gc回收的时候其实并不会去调用它的finalize方法。</p>

<p>需要注意的是我们的类在被加载过程中其实就已经被标记为是否为f类了（遍历所有方法，包括父类的方法，只要有一个非空的参数为空返回void的finalize方法就认为是一个f类）。</p>

<h3>f类的对象何时传到Finalizer.register方法</h3>

<p>对象的创建其实是被拆分成多个步骤的，比如<code>A a=new A(2)</code>这样一条语句对应的字节码如下：</p>

<p><code>
0: new           #1                  // class A
3: dup
4: iconst_2
5: invokespecial #11                 // Method "&lt;init&gt;":(I)V
</code>
先执行new分配好对象空间，然后再执行invokespecial调用构造函数，jvm里其实可以让用户选择在这两个时机中的任意一个将当前对象传递给Finalizer.register方法来注册到Finalizer对象链里，这个选择依赖于RegisterFinalizersAtInit这个vm参数是否被设置，默认值为true，也就是在调用构造函数返回之前调用Finalizer.register方法，如果通过-XX:-RegisterFinalizersAtInit关闭了该参数，那将在对象空间分配好之后就将这个对象注册进去。</p>

<p>另外需要提一点的是当我们通过clone的方式复制一个对象的时候，如果当前类是一个f类，那么在clone完成的时候将调用Finalizer.register方法进行注册。</p>

<h3>hotspot如何实现f类对象在构造函数执行完毕后调用Finalizer.register</h3>

<p>这个实现比较有意思，在这里简单提一下，我们知道一个构造函数执行的时候，会去调用父类的构造函数，主要是为了能对继承自父类的属性也能做初始化，那么任何一个对象的初始化最终都会调用到Object的空构造函数里（任何空的构造函数其实并不空，会含有三条字节码指令，如下代码所示），为了不对所有的类的构造函数都做埋点调用Finalizer.register方法，hotspot的实现是在Object这个类在做初始化的时候将构造函数里的<code>return</code>指令替换为<code>_return_register_finalizer</code>指令，该指令并不是标准的字节码指令，是hotspot扩展的指令，这样在处理该指令的时候调用Finalizer.register方法，这样就在侵入性很小的情况下完美地解决了这个问题。</p>

<p><code>
0: aload_0
1: invokespecial #21                 // Method java/lang/Object."&lt;init&gt;":()V
4: return
</code></p>

<h2>f类对象的GC回收</h2>

<h3>FinalizerThread线程</h3>

<p>在Finalizer类的clinit方法（静态块）里我们看到它会创建了一个FinalizerThread的守护线程，这个线程的优先级并不是最高的，意味着在cpu很紧张的情况下其被调度的优先级可能会受到影响</p>

<p>```
  private static class FinalizerThread extends Thread {</p>

<pre><code>    private volatile boolean running;
    FinalizerThread(ThreadGroup g) {
        super(g, "Finalizer");
    }
    public void run() {
        if (running)
            return;
        running = true;
        for (;;) {
            try {
                Finalizer f = (Finalizer)queue.remove();
                f.runFinalizer();
            } catch (InterruptedException x) {
                continue;
            }
        }
    }
}

static {
    ThreadGroup tg = Thread.currentThread().getThreadGroup();
    for (ThreadGroup tgn = tg;
         tgn != null;
         tg = tgn, tgn = tg.getParent());
    Thread finalizer = new FinalizerThread(tg);
    finalizer.setPriority(Thread.MAX_PRIORITY - 2);
    finalizer.setDaemon(true);
    finalizer.start();
}
</code></pre>

<p>```
这个线程主要就是从queue里取Finalizer对象，然后执行该对象的runFinalizer方法，这个方法主要是将Finalizer对象从Finalizer对象链里剥离出来，这样意味着下次gc发生的时候就可能将其关联的f对象gc掉了，最后将这个Finalizer对象关联的f对象传给了一个native方法invokeFinalizeMethod</p>

<p>```
private void runFinalizer() {</p>

<pre><code>    synchronized (this) {
        if (hasBeenFinalized()) return;
        remove();
    }
    try {
        Object finalizee = this.get();
        if (finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) {
            invokeFinalizeMethod(finalizee);
            /* Clear stack slot containing this variable, to decrease
               the chances of false retention with a conservative GC */
            finalizee = null;
        }
    } catch (Throwable x) { }
    super.clear();
}
</code></pre>

<p> static native void invokeFinalizeMethod(Object o) throws Throwable;</p>

<p>```
其实invokeFinalizeMethod方法就是调了这个f对象的finalize方法，看到这里大家应该恍然大悟了，整个过程都串起来了</p>

<p>```
JNIEXPORT void JNICALL
Java_java_lang_ref_Finalizer_invokeFinalizeMethod(JNIEnv *env, jclass clazz,</p>

<pre><code>                                              jobject ob)
</code></pre>

<p>{</p>

<pre><code>jclass cls;
jmethodID mid;

cls = (*env)-&gt;GetObjectClass(env, ob);
if (cls == NULL) return;
mid = (*env)-&gt;GetMethodID(env, cls, "finalize", "()V");
if (mid == NULL) return;
(*env)-&gt;CallVoidMethod(env, ob, mid);
</code></pre>

<p>}
```</p>

<h3>f对象的finalize方法抛出异常会导致FinalizeThread退出吗</h3>

<p>不知道大家有没有想过如果f对象的finalize方法抛了一个没捕获的异常，这个FinalizerThread会不会退出呢，细心的读者看上面的代码其实就可以找到答案，在runFinalizer方法里对Throwable的异常都进行了捕获，因此不可能出现FinalizerThread因异常未捕获而退出的情况。</p>

<h3>f对象的finalize方法会执行多次吗</h3>

<p>如果我们在f对象的finalize方法里重新将当前对象赋值出去，变成可达对象，当这个f对象再次变成不可达的时候还会被执行finalize方法吗？答案是否定的，因为在执行完第一次finalize方法之后，这个f对象已经和之前的Finalizer对象关系剥离了，也就是下次gc的时候不会再发现Finalizer对象指向该f对象了，自然也就不会调用这个f对象的finalize方法了。</p>

<h3>Finalizer对象何时被放到ReferenceQueue里</h3>

<p>除了这里要说的环节之外，整个过程大家应该都比较清楚了。</p>

<p>当gc发生的时候，gc算法会判断f类对象是不是只被Finalizer类引用（f类对象被Finalizer对象引用，然后放到Finalizer对象链里），如果这个类仅仅被Finalizer对象引用的时候，说明这个对象在不久的将来会被回收了现在可以执行它的finalize方法了，于是会将这个Finalizer对象放到Finalizer类的ReferenceQueue里，但是这个f类对象其实并没有被回收，因为Finalizer这个类还对他们持有引用，在gc完成之前，jvm会调用ReferenceQueue里的lock对象的notify方法（当ReferenceQueue为空的时候，FinalizerThread线程会调用ReferenceQueue的lock对象的wait方法直到被jvm唤醒），此时就会执行上面FinalizeThread线程里看到的其他逻辑了。</p>

<h2>Finalizer导致的内存泄露</h2>

<p>这里举一个简单的例子，我们使用挺广的socket通信，SocksSocketImpl的父类其实就实现了finalize方法:
```
/<em>*
 * Cleans up if the user forgets to close it.
 </em>/
protected void finalize() throws IOException {</p>

<pre><code>close();
</code></pre>

<p>}
```
其实这么做的主要目的是万一用户忘记关闭socket了，那么在这个对象被回收的时候能主动关闭socket来释放一些系统资源，但是如果真的是用户忘记关闭了，那这些socket对象可能因为FinalizeThread迟迟没有执行到这些socket对象的finalize方法，而导致内存泄露，这种问题我们碰到过多次，因此对于这类情况除了大家好好注意貌似没有什么更好的方法了，该做的事真不能省.</p>

<h2>Finalizer的客观评价</h2>

<p>上面的过程基本对Finalizer的实现细节进行完整剖析了，java里我们看到有构造函数，但是并没有看到析构函数一说，Finalizer其实是实现了析构函数的概念，我们在对象被回收前可以执行一些『收拾性』的逻辑，应该说是一个特殊场景的补充，但是这种概念的实现给我们的f对象生命周期以及gc等带来了一些影响：
* f对象因为Finalizer的引用而变成了一个临时的强引用，即使没有其他的强引用了，还是无法立即被回收
* f对象至少经历两次GC才能被回收，因为只有在FinalizerThread执行完了f对象的finalize方法的情况下才有可能被下次gc回收，而有可能期间已经经历过多次gc了，但是一直还没执行f对象的finalize方法
* cpu资源比较稀缺的情况下FinalizerThread线程有可能因为优先级比较低而延迟执行f对象的finalize方法
* 因为f对象的finalize方法迟迟没有执行，有可能会导致大部分f对象进入到old分代，此时容易引发old分代的gc，甚至fullgc，gc暂停时间明显变长
* f对象的finalize方法被调用了，但是这个对象其实还并没有被回收，虽然可能在不久的将来会被回收</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之堆外内存完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2015/05/12/direct-buffer/"/>
    <updated>2015-05-12T13:49:57+08:00</updated>
    <id>http://nijiaben.github.io/blog/2015/05/12/direct-buffer</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<h3>广义的堆外内存</h3>

<p>说到堆外内存，那大家肯定想到堆内内存，这也是我们大家接触最多的，我们在jvm参数里通常设置-Xmx来指定我们的堆的最大值，不过这还不是我们理解的Java堆，-Xmx的值是新生代和老生代的和的最大值，我们在jvm参数里通常还会加一个参数-XX:MaxPermSize来指定持久代的最大值，那么我们认识的Java堆的最大值其实是-Xmx和-XX:MaxPermSize的总和，在分代算法下，新生代，老生代和持久代是连续的虚拟地址，因为它们是一起分配的，那么剩下的都可以认为是堆外内存(广义的)了，这些包括了jvm本身在运行过程中分配的内存，codecache，jni里分配的内存，DirectByteBuffer分配的内存等等</p>

<h3>狭义的堆外内存</h3>

<p>而作为java开发者，我们常说的堆外内存溢出了，其实是狭义的堆外内存，这个主要是指java.nio.DirectByteBuffer在创建的时候分配内存，我们这篇文章里也主要是讲狭义的堆外内存，因为它和我们平时碰到的问题比较密切</p>

<!--more-->


<h2>JDK/JVM里DirectByteBuffer的实现</h2>

<p>DirectByteBuffer通常用在通信过程中做缓冲池，在mina，netty等nio框架中屡见不鲜，先来看看JDK里的实现：</p>

<p>```</p>

<pre><code>DirectByteBuffer(int cap) {                   // package-private

    super(-1, 0, cap, cap);
    boolean pa = VM.isDirectMemoryPageAligned();
    int ps = Bits.pageSize();
    long size = Math.max(1L, (long)cap + (pa ? ps : 0));
    Bits.reserveMemory(size, cap);

    long base = 0;
    try {
        base = unsafe.allocateMemory(size);
    } catch (OutOfMemoryError x) {
        Bits.unreserveMemory(size, cap);
        throw x;
    }
    unsafe.setMemory(base, size, (byte) 0);
    if (pa &amp;&amp; (base % ps != 0)) {
        // Round up to page boundary
        address = base + ps - (base &amp; (ps - 1));
    } else {
        address = base;
    }
    cleaner = Cleaner.create(this, new Deallocator(base, size, cap));
    att = null;



}
</code></pre>

<p>```
通过上面的构造函数我们知道，真正的内存分配是使用的Bits.reserveMemory方法</p>

<p>```</p>

<pre><code>static void reserveMemory(long size, int cap) {
    synchronized (Bits.class) {
        if (!memoryLimitSet &amp;&amp; VM.isBooted()) {
            maxMemory = VM.maxDirectMemory();
            memoryLimitSet = true;
        }
        // -XX:MaxDirectMemorySize limits the total capacity rather than the
        // actual memory usage, which will differ when buffers are page
        // aligned.
        if (cap &lt;= maxMemory - totalCapacity) {
            reservedMemory += size;
            totalCapacity += cap;
            count++;
            return;
        }
    }

    System.gc();
    try {
        Thread.sleep(100);
    } catch (InterruptedException x) {
        // Restore interrupt status
        Thread.currentThread().interrupt();
    }
    synchronized (Bits.class) {
        if (totalCapacity + cap &gt; maxMemory)
            throw new OutOfMemoryError("Direct buffer memory");
        reservedMemory += size;
        totalCapacity += cap;
        count++;
    }

}
</code></pre>

<p>```
通过上面的代码我们知道可以通过-XX:MaxDirectMemorySize来指定最大的堆外内存，那么我们首先引入两个问题</p>

<ul>
<li>堆外内存默认是多大</li>
<li>为什么要主动调用System.gc()</li>
</ul>


<h3>堆外内存默认是多大</h3>

<p>如果我们没有通过-XX:MaxDirectMemorySize来指定最大的堆外内存，那么默认的最大堆外内存是多少呢，我们还是通过代码来分析</p>

<p>上面的代码里我们看到调用了sun.misc.VM.maxDirectMemory()</p>

<p>```
 private static long directMemory = 64 * 1024 * 1024;</p>

<pre><code>// Returns the maximum amount of allocatable direct buffer memory.
// The directMemory variable is initialized during system initialization
// in the saveAndRemoveProperties method.
//
public static long maxDirectMemory() {
    return directMemory;
}
</code></pre>

<p>```
看到上面的代码之后是不是误以为默认的最大值是64M？其实不是的，说到这个值得从java.lang.System这个类的初始化说起</p>

<p>```
 /**</p>

<pre><code> * Initialize the system class.  Called after thread initialization.
 */
private static void initializeSystemClass() {

    // VM might invoke JNU_NewStringPlatform() to set those encoding
    // sensitive properties (user.home, user.name, boot.class.path, etc.)
    // during "props" initialization, in which it may need access, via
    // System.getProperty(), to the related system encoding property that
    // have been initialized (put into "props") at early stage of the
    // initialization. So make sure the "props" is available at the
    // very beginning of the initialization and all system properties to
    // be put into it directly.
    props = new Properties();
    initProperties(props);  // initialized by the VM

    // There are certain system configurations that may be controlled by
    // VM options such as the maximum amount of direct memory and
    // Integer cache size used to support the object identity semantics
    // of autoboxing.  Typically, the library will obtain these values
    // from the properties set by the VM.  If the properties are for
    // internal implementation use only, these properties should be
    // removed from the system properties.
    //
    // See java.lang.Integer.IntegerCache and the
    // sun.misc.VM.saveAndRemoveProperties method for example.
    //
    // Save a private copy of the system properties object that
    // can only be accessed by the internal implementation.  Remove
    // certain system properties that are not intended for public access.
    sun.misc.VM.saveAndRemoveProperties(props);

     ......

    sun.misc.VM.booted();
}
</code></pre>

<p><code>``
上面这个方法在jvm启动的时候对System这个类做初始化的时候执行的，因此执行时间非常早，我们看到里面调用了</code>sun.misc.VM.saveAndRemoveProperties(props)`:</p>

<p>```</p>

<pre><code>public static void saveAndRemoveProperties(Properties props) {
    if (booted)
        throw new IllegalStateException("System initialization has completed");

    savedProps.putAll(props);

    // Set the maximum amount of direct memory.  This value is controlled
    // by the vm option -XX:MaxDirectMemorySize=&lt;size&gt;.
    // The maximum amount of allocatable direct buffer memory (in bytes)
    // from the system property sun.nio.MaxDirectMemorySize set by the VM.
    // The system property will be removed.
    String s = (String)props.remove("sun.nio.MaxDirectMemorySize");
    if (s != null) {
        if (s.equals("-1")) {
            // -XX:MaxDirectMemorySize not given, take default
            directMemory = Runtime.getRuntime().maxMemory();
        } else {
            long l = Long.parseLong(s);
            if (l &gt; -1)
                directMemory = l;
        }
    }

    // Check if direct buffers should be page aligned
    s = (String)props.remove("sun.nio.PageAlignDirectMemory");
    if ("true".equals(s))
        pageAlignDirectMemory = true;

    // Set a boolean to determine whether ClassLoader.loadClass accepts
    // array syntax.  This value is controlled by the system property
    // "sun.lang.ClassLoader.allowArraySyntax".
    s = props.getProperty("sun.lang.ClassLoader.allowArraySyntax");
    allowArraySyntax = (s == null
                           ? defaultAllowArraySyntax
                           : Boolean.parseBoolean(s));

    // Remove other private system properties
    // used by java.lang.Integer.IntegerCache
    props.remove("java.lang.Integer.IntegerCache.high");

    // used by java.util.zip.ZipFile
    props.remove("sun.zip.disableMemoryMapping");

    // used by sun.launcher.LauncherHelper
    props.remove("sun.java.launcher.diag");
}
</code></pre>

<p>```</p>

<p>如果我们通过-Dsun.nio.MaxDirectMemorySize指定了这个属性，只要它不等于-1，那效果和加了-XX:MaxDirectMemorySize一样的，如果两个参数都没指定，那么最大堆外内存的值来自于<code>directMemory = Runtime.getRuntime().maxMemory()</code>，这是一个native方法</p>

<p>```
JNIEXPORT jlong JNICALL
Java_java_lang_Runtime_maxMemory(JNIEnv *env, jobject this)
{</p>

<pre><code>return JVM_MaxMemory();
</code></pre>

<p>}</p>

<p>JVM_ENTRY_NO_ENV(jlong, JVM_MaxMemory(void))
  JVMWrapper("JVM_MaxMemory");
  size_t n = Universe::heap()->max_capacity();
  return convert_size_t_to_jlong(n);
JVM_END</p>

<p>```
其中在我们使用CMS GC的情况下的实现如下，其实是新生代的最大值-一个survivor的大小+老生代的最大值，也就是我们设置的-Xmx的值里除去一个survivor的大小就是默认的堆外内存的大小了</p>

<p>```
size_t GenCollectedHeap::max_capacity() const {
  size_t res = 0;
  for (int i = 0; i &lt; _n_gens; i++) {</p>

<pre><code>res += _gens[i]-&gt;max_capacity();
</code></pre>

<p>  }
  return res;
}</p>

<p>size_t DefNewGeneration::max_capacity() const {
  const size_t alignment = GenCollectedHeap::heap()->collector_policy()->min_alignment();
  const size_t reserved_bytes = reserved().byte_size();
  return reserved_bytes - compute_survivor_size(reserved_bytes, alignment);
}</p>

<p>size_t Generation::max_capacity() const {
  return reserved().byte_size();
}
```</p>

<h3>为什么要主动调用System.gc</h3>

<p>既然要调用System.gc，那肯定是想通过触发一次gc操作来回收堆外内存，不过我想先说的是堆外内存不会对gc造成什么影响(这里的System.gc除外)，但是堆外内存的回收其实依赖于我们的gc机制，首先我们要知道在java层面和我们在堆外分配的这块内存关联的只有与之关联的DirectByteBuffer对象了，它记录了这块内存的基地址以及大小，那么既然和gc也有关，那就是gc能通过操作DirectByteBuffer对象来间接操作对应的堆外内存了。DirectByteBuffer对象在创建的时候关联了一个PhantomReference，说到PhantomReference它其实主要是用来跟踪对象何时被回收的，它不能影响gc决策，但是gc过程中如果发现某个对象除了只有PhantomReference引用它之外，并没有其他的地方引用它了，那将会把这个引用放到java.lang.ref.Reference.pending队列里，在gc完毕的时候通知ReferenceHandler这个守护线程去执行一些后置处理，而DirectByteBuffer关联的PhantomReference是PhantomReference的一个子类，在最终的处理里会通过Unsafe的free接口来释放DirectByteBuffer对应的堆外内存块</p>

<p>JDK里ReferenceHandler的实现：</p>

<p>```
 private static class ReferenceHandler extends Thread {</p>

<pre><code>    ReferenceHandler(ThreadGroup g, String name) {
        super(g, name);
    }

    public void run() {
        for (;;) {

            Reference r;
            synchronized (lock) {
                if (pending != null) {
                    r = pending;
                    Reference rn = r.next;
                    pending = (rn == r) ? null : rn;
                    r.next = r;
                } else {
                    try {
                        lock.wait();
                    } catch (InterruptedException x) { }
                    continue;
                }
            }

            // Fast path for cleaners
            if (r instanceof Cleaner) {
                ((Cleaner)r).clean();
                continue;
            }

            ReferenceQueue q = r.queue;
            if (q != ReferenceQueue.NULL) q.enqueue(r);
        }
    }
}
</code></pre>

<p>```</p>

<p>可见如果pending为空的时候，会通过lock.wait()一直等在那里，其中唤醒的动作是在jvm里做的，当gc完成之后会调用如下的方法VM_GC_Operation::doit_epilogue()，在方法末尾会调用lock的notify操作，至于pending队列什么时候将引用放进去的，其实是在gc的引用处理逻辑中放进去的，针对引用的处理后面可以专门写篇文章来介绍</p>

<p>```
void VM_GC_Operation::doit_epilogue() {
  assert(Thread::current()->is_Java_thread(), "just checking");
  // Release the Heap_lock first.
  SharedHeap* sh = SharedHeap::heap();
  if (sh != NULL) sh->_thread_holds_heap_lock_for_gc = false;
  Heap_lock->unlock();
  release_and_notify_pending_list_lock();
}</p>

<p>void VM_GC_Operation::release_and_notify_pending_list_lock() {
instanceRefKlass::release_and_notify_pending_list_lock(&amp;_pending_list_basic_lock);
}</p>

<p>```</p>

<p>对于System.gc的实现，之前写了一篇文章来重点介绍，<a href="http://lovestblog.cn/blog/2015/05/07/system-gc/">JVM源码分析之SystemGC完全解读</a>，它会对新生代的老生代都会进行内存回收，这样会比较彻底地回收DirectByteBuffer对象以及他们关联的堆外内存，我们dump内存发现DirectByteBuffer对象本身其实是很小的，但是它后面可能关联了一个非常大的堆外内存，因此我们通常称之为『冰山对象』，我们做ygc的时候会将新生代里的不可达的DirectByteBuffer对象及其堆外内存回收了，但是无法对old里的DirectByteBuffer对象及其堆外内存进行回收，这也是我们通常碰到的最大的问题，如果有大量的DirectByteBuffer对象移到了old，但是又一直没有做cms gc或者full gc，而只进行ygc，那么我们的物理内存可能被慢慢耗光，但是我们还不知道发生了什么，因为heap明明剩余的内存还很多(前提是我们禁用了System.gc)。</p>

<h2>为什么要使用堆外内存</h2>

<p>DirectByteBuffer在创建的时候会通过Unsafe的native方法来直接使用malloc分配一块内存，这块内存是heap之外的，那么自然也不会对gc造成什么影响(System.gc除外)，因为gc耗时的操作主要是操作heap之内的对象，对这块内存的操作也是直接通过Unsafe的native方法来操作的，相当于DirectByteBuffer仅仅是一个壳，还有我们通信过程中如果数据是在Heap里的，最终也还是会copy一份到堆外，然后再进行发送，所以为什么不直接使用堆外内存呢。对于需要频繁操作的内存，并且仅仅是临时存在一会的，都建议使用堆外内存，并且做成缓冲池，不断循环利用这块内存。</p>

<h2>为什么不能大面积使用堆外内存</h2>

<p>如果我们大面积使用堆外内存并且没有限制，那迟早会导致内存溢出，毕竟程序是跑在一台资源受限的机器上，因为这块内存的回收不是你直接能控制的，当然你可以通过别的一些途径，比如反射，直接使用Unsafe接口等，但是这些务必给你带来了一些烦恼，Java与生俱来的优势被你完全抛弃了---开发不需要关注内存的回收，由gc算法自动去实现。另外上面的gc机制与堆外内存的关系也说了，如果一直触发不了cms gc或者full gc，那么后果可能很严重。</p>
]]></content>
  </entry>
  
</feed>
