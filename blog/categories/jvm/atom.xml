<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: jvm | 你假笨]]></title>
  <link href="http://nijiaben.github.io/blog/categories/jvm/atom.xml" rel="self"/>
  <link href="http://nijiaben.github.io/"/>
  <updated>2016-11-10T09:42:31+08:00</updated>
  <id>http://nijiaben.github.io/</id>
  <author>
    <name><![CDATA[你假笨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之String.intern()导致的YGC不断变长]]></title>
    <link href="http://nijiaben.github.io/blog/2016/11/06/string-intern/"/>
    <updated>2016-11-06T09:37:18+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/11/06/string-intern</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>之所以想写这篇文章，是因为YGC过程对我们来说太过于黑盒，如果对YGC过程不是很熟悉，这类问题基本很难定位，我们就算开了GC日志，也最多能看到类似下面的日志</p>

<pre><code>[GC (Allocation Failure) [ParNew: 91807K-&gt;10240K(92160K), 0.0538384 secs] 91807K-&gt;21262K(2086912K), 0.0538680 secs] [Times: user=0.16 sys=0.06, real=0.06 secs] 
</code></pre>

<p>只知道耗了多长时间，但是具体耗在了哪个阶段，是基本看不出来的，所以要么就是靠经验来定位，要么就是对代码相当熟悉，脑袋里过一遍整个过程，看哪个阶段最可能，今天要讲的这个大家可以当做今后排查这类问题的一个经验来使，这个当然不是唯一导致YGC过长的一个原因，但却是最近我帮忙定位碰到的发生相对来说比较多的一个场景</p>

<!--more-->


<p>具体的定位是通过在JVM代码里进行了日志埋点确定的，这个问题其实最早的时候，是帮助毕玄毕大师定位到这块的问题，他也在公众号里对这个问题写了相关的一篇文章<a href="" title="http://mp.weixin.qq.com/s?__biz=MjM5MzYzMzkyMQ==&amp;mid=2649826309&amp;idx=1&amp;sn=13518f7f693d78fd19f8dc5d21c7eb4b&amp;scene=0#wechat_redirect">YGC越来越慢，为什么</a>，大家可以关注下毕大师的公众号<code>HelloJava</code>，经常会发一些在公司碰到的诡异问题的排查，相信会让你涨姿势的，当然如果你还没有关注我的公众号<code>你假笨</code>，欢迎关注下，后续会时不时写点或许正巧你感兴趣的JVM系列文章。</p>

<h2>Demo</h2>

<p>先上一个demo，来描述下问题的情况，代码很简单，就是不断创建UUID，其实就是一个字符串，并将这个字符串调用下intern方法</p>

<pre><code>import java.util.UUID;

public class StringTableTest {
    public static void main(String args[]) {
        for (int i = 0; i &lt; 10000000; i++) {
            uuid();
        }
    }

    public static void uuid() {
        UUID.randomUUID().toString().intern();
    }
}
</code></pre>

<p>我们使用的JVM参数如下：</p>

<pre><code>-XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -Xmx2G -Xms2G -Xmn100M
</code></pre>

<p>这里特意将新生代设置比较小，老生代设置比较大，让代码在执行过程中更容易突出问题来，大量做ygc，期间不做CMS GC，于是我们得到的输出结果类似下面的</p>

<pre><code>[GC (Allocation Failure) [ParNew: 81920K-&gt;9887K(92160K), 0.0096027 secs] 81920K-&gt;9887K(2086912K), 0.0096428 secs] [Times: user=0.06 sys=0.01, real=0.01 secs] 
[GC (Allocation Failure) [ParNew: 91807K-&gt;10240K(92160K), 0.0538384 secs] 91807K-&gt;21262K(2086912K), 0.0538680 secs] [Times: user=0.16 sys=0.06, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0190535 secs] 103182K-&gt;32655K(2086912K), 0.0190965 secs] [Times: user=0.12 sys=0.01, real=0.02 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0198259 secs] 114575K-&gt;44124K(2086912K), 0.0198558 secs] [Times: user=0.13 sys=0.01, real=0.02 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0213643 secs] 126044K-&gt;55592K(2086912K), 0.0213930 secs] [Times: user=0.14 sys=0.01, real=0.02 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0234291 secs] 137512K-&gt;67061K(2086912K), 0.0234625 secs] [Times: user=0.16 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10238K(92160K), 0.0243691 secs] 148981K-&gt;78548K(2086912K), 0.0244041 secs] [Times: user=0.15 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0235310 secs] 160468K-&gt;89998K(2086912K), 0.0235587 secs] [Times: user=0.17 sys=0.01, real=0.02 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0255960 secs] 171918K-&gt;101466K(2086912K), 0.0256264 secs] [Times: user=0.18 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10238K(92160K), 0.0287876 secs] 183386K-&gt;113770K(2086912K), 0.0288188 secs] [Times: user=0.20 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0298405 secs] 195690K-&gt;125267K(2086912K), 0.0298823 secs] [Times: user=0.20 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0310182 secs] 207187K-&gt;136742K(2086912K), 0.0311156 secs] [Times: user=0.22 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0321647 secs] 218662K-&gt;148210K(2086912K), 0.0321938 secs] [Times: user=0.22 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0338090 secs] 230130K-&gt;159686K(2086912K), 0.0338446 secs] [Times: user=0.24 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0326612 secs] 241606K-&gt;171159K(2086912K), 0.0326912 secs] [Times: user=0.23 sys=0.01, real=0.03 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0350578 secs] 253079K-&gt;182627K(2086912K), 0.0351077 secs] [Times: user=0.26 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0346946 secs] 264547K-&gt;194096K(2086912K), 0.0347274 secs] [Times: user=0.25 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0384091 secs] 276016K-&gt;205567K(2086912K), 0.0384401 secs] [Times: user=0.27 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0394017 secs] 287487K-&gt;217035K(2086912K), 0.0394312 secs] [Times: user=0.29 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0411447 secs] 298955K-&gt;228504K(2086912K), 0.0411748 secs] [Times: user=0.30 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0393449 secs] 310424K-&gt;239972K(2086912K), 0.0393743 secs] [Times: user=0.29 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0444541 secs] 321892K-&gt;251441K(2086912K), 0.0444887 secs] [Times: user=0.32 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0449196 secs] 333361K-&gt;262910K(2086912K), 0.0449557 secs] [Times: user=0.33 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0497517 secs] 344830K-&gt;274382K(2086912K), 0.0497946 secs] [Times: user=0.34 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0475741 secs] 356302K-&gt;285851K(2086912K), 0.0476130 secs] [Times: user=0.35 sys=0.01, real=0.04 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0461098 secs] 367771K-&gt;297320K(2086912K), 0.0461421 secs] [Times: user=0.34 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0508071 secs] 379240K-&gt;308788K(2086912K), 0.0508428 secs] [Times: user=0.38 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0494472 secs] 390708K-&gt;320257K(2086912K), 0.0494938 secs] [Times: user=0.36 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0531527 secs] 402177K-&gt;331725K(2086912K), 0.0531845 secs] [Times: user=0.39 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0543701 secs] 413645K-&gt;343194K(2086912K), 0.0544025 secs] [Times: user=0.41 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0528003 secs] 425114K-&gt;354663K(2086912K), 0.0528283 secs] [Times: user=0.39 sys=0.01, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0565080 secs] 436583K-&gt;366131K(2086912K), 0.0565394 secs] [Times: user=0.42 sys=0.01, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0597181 secs] 448051K-&gt;377600K(2086912K), 0.0597653 secs] [Times: user=0.44 sys=0.01, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0606671 secs] 459520K-&gt;389068K(2086912K), 0.0607423 secs] [Times: user=0.46 sys=0.01, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0590389 secs] 470988K-&gt;400539K(2086912K), 0.0590679 secs] [Times: user=0.43 sys=0.01, real=0.05 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0600462 secs] 482459K-&gt;412008K(2086912K), 0.0600757 secs] [Times: user=0.44 sys=0.01, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0608772 secs] 493928K-&gt;423476K(2086912K), 0.0609170 secs] [Times: user=0.45 sys=0.01, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0622107 secs] 505396K-&gt;434945K(2086912K), 0.0622391 secs] [Times: user=0.46 sys=0.00, real=0.06 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0626555 secs] 516865K-&gt;446413K(2086912K), 0.0626872 secs] [Times: user=0.47 sys=0.01, real=0.07 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0647713 secs] 528333K-&gt;457882K(2086912K), 0.0648013 secs] [Times: user=0.47 sys=0.00, real=0.07 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0747113 secs] 539802K-&gt;469353K(2086912K), 0.0747446 secs] [Times: user=0.51 sys=0.01, real=0.07 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0727498 secs] 551273K-&gt;480832K(2086912K), 0.0727899 secs] [Times: user=0.52 sys=0.01, real=0.07 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0734084 secs] 562752K-&gt;492300K(2086912K), 0.0734402 secs] [Times: user=0.54 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0766368 secs] 574220K-&gt;503769K(2086912K), 0.0766673 secs] [Times: user=0.55 sys=0.01, real=0.07 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0778940 secs] 585689K-&gt;515237K(2086912K), 0.0779250 secs] [Times: user=0.56 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0815513 secs] 597157K-&gt;526712K(2086912K), 0.0815824 secs] [Times: user=0.57 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0812080 secs] 608632K-&gt;538181K(2086912K), 0.0812406 secs] [Times: user=0.58 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0818790 secs] 620101K-&gt;549651K(2086912K), 0.0819155 secs] [Times: user=0.60 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0840677 secs] 631571K-&gt;561122K(2086912K), 0.0841000 secs] [Times: user=0.61 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0842462 secs] 643042K-&gt;572593K(2086912K), 0.0842785 secs] [Times: user=0.61 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0875011 secs] 654513K-&gt;584076K(2086912K), 0.0875416 secs] [Times: user=0.62 sys=0.01, real=0.08 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0887645 secs] 665996K-&gt;595532K(2086912K), 0.0887956 secs] [Times: user=0.64 sys=0.01, real=0.09 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10240K(92160K), 0.0921844 secs] 677452K-&gt;607001K(2086912K), 0.0922153 secs] [Times: user=0.65 sys=0.01, real=0.09 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10238K(92160K), 0.0930053 secs] 688921K-&gt;618471K(2086912K), 0.0930380 secs] [Times: user=0.67 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0955379 secs] 700391K-&gt;629942K(2086912K), 0.0955873 secs] [Times: user=0.69 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0919127 secs] 711862K-&gt;641411K(2086912K), 0.0919528 secs] [Times: user=0.68 sys=0.01, real=0.09 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0942291 secs] 723331K-&gt;652879K(2086912K), 0.0942611 secs] [Times: user=0.70 sys=0.00, real=0.09 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.0951904 secs] 734799K-&gt;664348K(2086912K), 0.0952265 secs] [Times: user=0.71 sys=0.00, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.0963585 secs] 746268K-&gt;675816K(2086912K), 0.0963909 secs] [Times: user=0.72 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0969504 secs] 757736K-&gt;687285K(2086912K), 0.0969843 secs] [Times: user=0.72 sys=0.01, real=0.09 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.0999066 secs] 769205K-&gt;698753K(2086912K), 0.0999376 secs] [Times: user=0.75 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10240K(92160K), 0.0998371 secs] 780673K-&gt;710222K(2086912K), 0.0998835 secs] [Times: user=0.75 sys=0.00, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92160K-&gt;10239K(92160K), 0.1024616 secs] 792142K-&gt;721691K(2086912K), 0.1024927 secs] [Times: user=0.77 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92159K-&gt;10238K(92160K), 0.1015041 secs] 803611K-&gt;733159K(2086912K), 0.1015378 secs] [Times: user=0.76 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.1058214 secs] 815079K-&gt;744628K(2086912K), 0.1058532 secs] [Times: user=0.80 sys=0.01, real=0.10 secs] 
[GC (Allocation Failure) [ParNew: 92158K-&gt;10238K(92160K), 0.1061273 secs] 826548K-&gt;756096K(2086912K), 0.1061620 secs] [Times: user=0.80 sys=0.01, real=0.10 secs] 
</code></pre>

<p>有没有发现YGC不断发生，并且发生的时间不断在增长，从10ms慢慢增长到了100ms，甚至还会继续涨下去</p>

<h2>String.intern方法</h2>

<p>从上面的demo我们能挖掘到的可能就是intern这个方法了，那我们先来了解下intern方法的实现，这是String提供的一个方法，jvm提供这个方法的目的是希望对于某个同名字符串使用非常多的场景，在jvm里只保留一份，比如我们不断new String(&ldquo;a&rdquo;)，其实在java heap里会有多个String的对象，并且值都是a，如果我们只希望内存里只保留一个a，或者希望我接下来用到的地方都返回同一个a，那就可以用String.intern这个方法了，用法如下</p>

<pre><code>String a = "a".intern();
...
String b = a.intern();
</code></pre>

<p>这样b和a都是指向内存里的同一个String对象，那JVM里到底怎么做到的呢？</p>

<p>我们看到intern这个方法其实是一个native方法，具体对应到JVM里的逻辑是</p>

<pre><code>
oop StringTable::intern(oop string, TRAPS)
{
  if (string == NULL) return NULL;
  ResourceMark rm(THREAD);
  int length;
  Handle h_string (THREAD, string);
  jchar* chars = java_lang_String::as_unicode_string(string, length);
  oop result = intern(h_string, chars, length, CHECK_NULL);
  return result;
}

oop StringTable::intern(Handle string_or_null, jchar* name,
                        int len, TRAPS) {
  unsigned int hashValue = hash_string(name, len);
  int index = the_table()-&gt;hash_to_index(hashValue);
  oop found_string = the_table()-&gt;lookup(index, name, len, hashValue);

  // Found
  if (found_string != NULL) return found_string;

  debug_only(StableMemoryChecker smc(name, len * sizeof(name[0])));
  assert(!Universe::heap()-&gt;is_in_reserved(name) || GC_locker::is_active(),
         "proposed name of symbol must be stable");

  Handle string;
  // try to reuse the string if possible
  if (!string_or_null.is_null() &amp;&amp; (!JavaObjectsInPerm || string_or_null()-&gt;is_perm())) {
    string = string_or_null;
  } else {
    string = java_lang_String::create_tenured_from_unicode(name, len, CHECK_NULL);
  }

  // Grab the StringTable_lock before getting the_table() because it could
  // change at safepoint.
  MutexLocker ml(StringTable_lock, THREAD);

  // Otherwise, add to symbol to table
  return the_table()-&gt;basic_add(index, string, name, len,
                                hashValue, CHECK_NULL);
}
</code></pre>

<p>也就是说是其实在JVM里存在一个叫做StringTable的数据结构，这个数据结构是一个Hashtable，在我们调用String.intern的时候其实就是先去这个StringTable里查找是否存在一个同名的项，如果存在就直接返回对应的对象，否则就往这个table里插入一项，指向这个String对象，那么再下次通过intern再来访问同名的String对象的时候，就会返回上次插入的这一项指向的String对象</p>

<p>至此大家应该知道其原理了，另外我这里还想说个题外话，记得几年前tomcat里爆发的一个HashMap导致的hash碰撞的问题，这里其实也是一个Hashtable，所以也还是存在类似的风险，不过JVM里提供一个参数专门来控制这个table的size，<code>-XX:StringTableSize</code>，这个参数的默认值如下</p>

<pre><code>product(uintx, StringTableSize, NOT_LP64(1009) LP64_ONLY(60013),          \
          "Number of buckets in the interned String table")                 \
</code></pre>

<p>另外JVM还会根据hash碰撞的情况来决定是否做rehash，比如你从这个StringTable里查找某个字符串是否存在，如果对其对应的桶挨个遍历，超过了100个还是没有找到对应的同名的项，那就会设置一个flag，让下次进入到safepoint的时候做一次rehash动作，尽量减少碰撞的发生，但是当恶化到一定程度的时候，其实也没啥办法啦，因为你的数据量实在太大，桶子数就那么多，那每个桶再怎么均匀也会带着一个很长的链表，所以此时我们通过修改上面的StringTableSize将桶数变大，可能会一定程度上缓解，但是如果是java代码的问题导致泄露，那就只能定位到具体的代码进行改造了。</p>

<h2>StringTable为什么会影响YGC</h2>

<p>YGC的过程我不打算再这篇文章里细说，因为我希望尽量保持每篇文章的内容不过于臃肿，有机会可以单独写篇文章来介绍，我这里将列出ygc过程里StringTable这块的具体代码</p>

<pre><code>  if (!_process_strong_tasks-&gt;is_task_claimed(SH_PS_StringTable_oops_do)) {
    if (so &amp; SO_Strings || (!collecting_perm_gen &amp;&amp; !JavaObjectsInPerm)) {
      StringTable::oops_do(roots);
    }
    if (JavaObjectsInPerm) {
      // Verify the string table contents are in the perm gen
      NOT_PRODUCT(StringTable::oops_do(&amp;assert_is_perm_closure));
    }
  }
</code></pre>

<p>因为YGC过程不涉及到对perm做回收，因此<code>collecting_perm_gen</code>是false，而<code>JavaObjectsInPerm</code>默认情况下也是false，表示String.intern返回的字符串是不是在perm里分配，如果是false，表示是在heap里分配的，因此StringTable指向的字符串是在heap里分配的，所以ygc过程需要对StringTable做扫描，以保证处于新生代的String代码不会被回收掉</p>

<p>至此大家应该明白了为什么YGC过程会对StringTable扫描</p>

<p>有了这一层意思之后，YGC的时间长短和扫描StringTable有关也可以理解了，设想一下如果StringTable非常庞大，那是不是意味着YGC过程扫描的时间也会变长呢</p>

<h2>YGC过程扫描StringTable对CPU影响大吗</h2>

<p>这个问题其实是我写这文章的时候突然问自己的一个问题，于是稍微想了下来跟大家解释下，因为大家也可能会问这么个问题</p>

<p>要回答这个问题我首先得问你们的机器到底有多少个核，如果核数很多的话，其实影响不是很大，因为这个扫描的过程是单个GC线程来做的，所以最多消耗一个核，因此看起来对于核数很多的情况，基本不算什么</p>

<h2>StringTable什么时候清理</h2>

<p>YGC过程不会对StringTable做清理，这也就是我们demo里的情况会让Stringtable越来越大，因为到目前为止还只看到YGC过程，但是在Full GC或者CMS GC过程会对StringTable做清理，具体验证很简单，执行下<code>jmap -histo:live &lt;pid&gt;</code>，你将会发现YGC的时候又降下去了</p>

<h2>本文写作时间</h2>

<p>利用午饭前的一点时间写下 2016/11/06 12:00~12:40</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之不保证顺序的Class.getMethods]]></title>
    <link href="http://nijiaben.github.io/blog/2016/11/02/class-getmethods/"/>
    <updated>2016-11-02T09:39:29+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/11/02/class-getmethods</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>本文要说的内容是今天公司有个线上系统踩了一个坑，并且貌似还造成了一定的影响，后来系统相关的人定位到了是<code>java.lang.Class.getMethods</code>返回的顺序可能不同机器不一样，有问题的机器和没问题的机器这个返回的方法列表是不一样的，后面他们就来找到我求证是否jdk里有这潜规则</p>

<p>本来这个问题简单一句话就可以说明白，所以在晚上推送的消息里也将这个事实告诉了大家，大家知道就好，以后不要再掉到坑里去了，但是这个要细说起来其实也值得一说，于是在消息就附加了征求大家意见的内容，看大家是否有兴趣或者是否踩到过此坑，没想到有这么多人响应，表示对这个话题很感兴趣，并且总结了大家问得最多的两个问题是</p>

<ul>
<li>为什么有代码需要依赖这个顺序</li>
<li>jvm里为什么不保证顺序</li>
</ul>


<p>那这篇文章主要就针对这两个问题展开说一下，另外以后针对此类可写可不写的文章先征求下大家的意见再来写可能效果会更好点，一来可以回答大家的一些疑问（当然有些问题我也可能回答不上来，不过我尽量去通读代码回答好大家），二来希望对我公众号里的文章继续保持<code>不求最多，只求最精</code>的态度。</p>

<p>为了不辜负大家的热情，我连夜赶写了这篇文章，如果大家觉得我写的这些文章对大家有帮助，希望您能将文章分享出去，同时将我的公众号<code>你假笨</code>推荐给您身边更多的技术人，能帮助到更多的人去了解更多的细节，在下在此先谢过。</p>

<!--more-->


<h2>依赖顺序的场景</h2>

<p>如果大家看过或者实现过序列化反序列化的代码，这个问题就不难回答了，今天碰到的这个问题其实是发生在大家可能最常用的<code>fastjson</code>库里的，所以如果大家在使用这个库，请务必检查下你的代码，以免踩到此坑</p>

<h3>对象序列化</h3>

<p>大家都知道当我们序列化好一个对象之后，要反序列回来，那问题就来了，就拿这个json序列化来说吧，我们要将对象序列化成json串，那意味着我们要先取出这个对象的属性，然后写成键值对的形式，那取值就意味着我们要遵循java bean的规范通过getter方法来取，那其实getter方法有两种，一种是boolean类型的，一种是其他类型的，如果是boolean类型的，那我们通常是<code>isXXX()</code>这样的方法，如果是其他类型的，一般是<code>getXXX()</code>这样的方法。那假如说我们的类里针对某个属性a，同时存在两个方法<code>isA()</code>和<code>getA()</code>，那究竟我们会调用哪个来取值？这个就取决于具体的序列化框架实现了，比如导致我们这篇文章诞生的<code>fastjson</code>，就是利用我们这篇文章的主角<code>java.lang.Class.getMethods</code>返回的数组，然后挨个遍历，先找到哪个就是哪个，如果我们的这个数组正好因为jvm本身实现没有保证顺序，那么可能先找到<code>isA()</code>，也可能先找到<code>getA()</code>，如果两个方法都是返回a这个属性其实问题也不大，假如正好是这两个方法返回不同的内容呢？</p>

<pre><code>private A a;

public A getA(){
    return a;
}

public boolean isA(){
    return false;
}

public void setA(A a){
    this.a=a;
}
</code></pre>

<p>如果是上面的内容，那可能就会悲剧了，如果选了<code>isA()</code>，那其实是返回一个boolean类型的，将这个boolean写入到json串里，如果是选了<code>getA()</code>，那就是将A这个类型的对象写到json串里</p>

<h3>对象反序列化</h3>

<p>在完成了序列化过程之后，需要将这个字符串进行反序列化了，于是就会去找json串里对应字段的setter方法，比如上面的<code>setA(A a)</code>，假如我们之前选了<code>isA()</code>序列化好内容，那我们此时的值是一个boolean值false，那就无法通过<code>setA</code>来赋值还原对象了。</p>

<h3>解决方案</h3>

<p>相信大家看完我上面的描述，知道这个问题所在了，要避免类似的问题，方案其实也挺多，比如对方法进行先排序，又比如说优先使用<code>isXXX()</code>方法，不过这种需要和开发者达成共识，和setter要对应得起来</p>

<h2>jvm里为什么不保证顺序</h2>

<p>JDK层面的代码我就暂时不说了，大家都能看到代码，从<code>java.lang.Class.getMethods</code>一层层走下去，相信大家细心点还是能抓住整个脉络的，我这里主要想说大家可能比较难看到的一些实现，比如JVM里的具体实现</p>

<p>正常情况下大家跟代码能跟到调用了<code>java.lang.Class.getDeclaredMethods0</code>这个native方法，其具体实现如下</p>

<pre><code>JVM_ENTRY(jobjectArray, JVM_GetClassDeclaredMethods(JNIEnv *env, jclass ofClass, jboolean publicOnly))
{
  JVMWrapper("JVM_GetClassDeclaredMethods");
  return get_class_declared_methods_helper(env, ofClass, publicOnly,
                                           /*want_constructor*/ false,
                                           SystemDictionary::reflect_Method_klass(), THREAD);
}
JVM_END
</code></pre>

<p>其主要调用了<code>get_class_declared_methods_helper</code>方法</p>

<pre><code>static jobjectArray get_class_declared_methods_helper(
                                  JNIEnv *env,
                                  jclass ofClass, jboolean publicOnly,
                                  bool want_constructor,
                                  Klass* klass, TRAPS) {

  JvmtiVMObjectAllocEventCollector oam;

  // Exclude primitive types and array types
  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(ofClass))
      || java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass))-&gt;oop_is_array()) {
    // Return empty array
    oop res = oopFactory::new_objArray(klass, 0, CHECK_NULL);
    return (jobjectArray) JNIHandles::make_local(env, res);
  }

  instanceKlassHandle k(THREAD, java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass)));

  // Ensure class is linked
  k-&gt;link_class(CHECK_NULL);

  Array&lt;Method*&gt;* methods = k-&gt;methods();
  int methods_length = methods-&gt;length();

  // Save original method_idnum in case of redefinition, which can change
  // the idnum of obsolete methods.  The new method will have the same idnum
  // but if we refresh the methods array, the counts will be wrong.
  ResourceMark rm(THREAD);
  GrowableArray&lt;int&gt;* idnums = new GrowableArray&lt;int&gt;(methods_length);
  int num_methods = 0;

  for (int i = 0; i &lt; methods_length; i++) {
    methodHandle method(THREAD, methods-&gt;at(i));
    if (select_method(method, want_constructor)) {
      if (!publicOnly || method-&gt;is_public()) {
        idnums-&gt;push(method-&gt;method_idnum());
        ++num_methods;
      }
    }
  }

  // Allocate result
  objArrayOop r = oopFactory::new_objArray(klass, num_methods, CHECK_NULL);
  objArrayHandle result (THREAD, r);

  // Now just put the methods that we selected above, but go by their idnum
  // in case of redefinition.  The methods can be redefined at any safepoint,
  // so above when allocating the oop array and below when creating reflect
  // objects.
  for (int i = 0; i &lt; num_methods; i++) {
    methodHandle method(THREAD, k-&gt;method_with_idnum(idnums-&gt;at(i)));
    if (method.is_null()) {
      // Method may have been deleted and seems this API can handle null
      // Otherwise should probably put a method that throws NSME
      result-&gt;obj_at_put(i, NULL);
    } else {
      oop m;
      if (want_constructor) {
        m = Reflection::new_constructor(method, CHECK_NULL);
      } else {
        m = Reflection::new_method(method, UseNewReflection, false, CHECK_NULL);
      }
      result-&gt;obj_at_put(i, m);
    }
  }

  return (jobjectArray) JNIHandles::make_local(env, result());
}
</code></pre>

<p>从上面的<code>k-&gt;method_with_idnum(idnums-&gt;at(i))</code>,我们基本知道方法主要是从klass里来的</p>

<pre><code>Method* InstanceKlass::method_with_idnum(int idnum) {
  Method* m = NULL;
  if (idnum &lt; methods()-&gt;length()) {
    m = methods()-&gt;at(idnum);
  }
  if (m == NULL || m-&gt;method_idnum() != idnum) {
    for (int index = 0; index &lt; methods()-&gt;length(); ++index) {
      m = methods()-&gt;at(index);
      if (m-&gt;method_idnum() == idnum) {
        return m;
      }
    }
    // None found, return null for the caller to handle.
    return NULL;
  }
  return m;
}
</code></pre>

<p>因此InstanceKlass里的methods是关键，而这个methods的创建是在类解析的时候发生的</p>

<pre><code>instanceKlassHandle ClassFileParser::parseClassFile(Symbol* name,
                                                    ClassLoaderData* loader_data,
                                                    Handle protection_domain,
                                                    KlassHandle host_klass,
                                                    GrowableArray&lt;Handle&gt;* cp_patches,
                                                    TempNewSymbol&amp; parsed_name,
                                                    bool verify,
                                                    TRAPS) {


...
 Array&lt;Method*&gt;* methods = parse_methods(access_flags.is_interface(),
                                            &amp;promoted_flags,
                                            &amp;has_final_method,
                                            &amp;declares_default_methods,

...                                            CHECK_(nullHandle));
// sort methods
intArray* method_ordering = sort_methods(methods); 
...
this_klass-&gt;set_methods(_methods);
...
}
</code></pre>

<p>上面的<code>parse_methods</code>就是从class文件里挨个解析出method，并存到_methods字段里，但是接下来做了一次<code>sort_methods</code>的动作，这个动作会对解析出来的方法做排序</p>

<pre><code>intArray* ClassFileParser::sort_methods(Array&lt;Method*&gt;* methods) {
  int length = methods-&gt;length();
  // If JVMTI original method ordering or sharing is enabled we have to
  // remember the original class file ordering.
  // We temporarily use the vtable_index field in the Method* to store the
  // class file index, so we can read in after calling qsort.
  // Put the method ordering in the shared archive.
  if (JvmtiExport::can_maintain_original_method_order() || DumpSharedSpaces) {
    for (int index = 0; index &lt; length; index++) {
      Method* m = methods-&gt;at(index);
      assert(!m-&gt;valid_vtable_index(), "vtable index should not be set");
      m-&gt;set_vtable_index(index);
    }
  }
  // Sort method array by ascending method name (for faster lookups &amp; vtable construction)
  // Note that the ordering is not alphabetical, see Symbol::fast_compare
  Method::sort_methods(methods);

  intArray* method_ordering = NULL;
  // If JVMTI original method ordering or sharing is enabled construct int
  // array remembering the original ordering
  if (JvmtiExport::can_maintain_original_method_order() || DumpSharedSpaces) {
    method_ordering = new intArray(length);
    for (int index = 0; index &lt; length; index++) {
      Method* m = methods-&gt;at(index);
      int old_index = m-&gt;vtable_index();
      assert(old_index &gt;= 0 &amp;&amp; old_index &lt; length, "invalid method index");
      method_ordering-&gt;at_put(index, old_index);
      m-&gt;set_vtable_index(Method::invalid_vtable_index);
    }
  }
  return method_ordering;
}


// This is only done during class loading, so it is OK to assume method_idnum matches the methods() array
// default_methods also uses this without the ordering for fast find_method
void Method::sort_methods(Array&lt;Method*&gt;* methods, bool idempotent, bool set_idnums) {
  int length = methods-&gt;length();
  if (length &gt; 1) {
    {
      No_Safepoint_Verifier nsv;
      QuickSort::sort&lt;Method*&gt;(methods-&gt;data(), length, method_comparator, idempotent);
    }
    // Reset method ordering
    if (set_idnums) {
      for (int i = 0; i &lt; length; i++) {
        Method* m = methods-&gt;at(i);
        m-&gt;set_method_idnum(i);
        m-&gt;set_orig_method_idnum(i);
      }
    }
  }
}
</code></pre>

<p>从上面的<code>Method::sort_methods</code>可以看出其实具体的排序算法是<code>method_comparator</code></p>

<pre><code>// Comparer for sorting an object array containing
// Method*s.
static int method_comparator(Method* a, Method* b) {
  return a-&gt;name()-&gt;fast_compare(b-&gt;name());
}
</code></pre>

<p>比较的是两个方法的名字，但是这个名字不是一个字符串，而是一个Symbol对象，每个类或者方法名字都会对应一个Symbol对象，在这个名字第一次使用的时候构建，并且不是在java heap里分配的，比如jdk7里就是在c heap里通过malloc来分配的，jdk8里会在metaspace里分配</p>

<pre><code>// Note: this comparison is used for vtable sorting only; it doesn't matter
// what order it defines, as long as it is a total, time-invariant order
// Since Symbol*s are in C_HEAP, their relative order in memory never changes,
// so use address comparison for speed
int Symbol::fast_compare(Symbol* other) const {
 return (((uintptr_t)this &lt; (uintptr_t)other) ? -1
   : ((uintptr_t)this == (uintptr_t) other) ? 0 : 1);
}
</code></pre>

<p>从上面的fast_compare方法知道，其实对比的是地址的大小，因为Symbol对象是通过malloc来分配的，因此新分配的Symbol对象的地址就不一定比后分配的Symbol对象地址小，也不一定大，因为期间存在内存free的动作，那地址是不会一直线性变化的，之所以不按照字母排序，主要还是为了速度考虑，根据地址排序是最快的。</p>

<p>综上所述，一个类里的方法经过排序之后，顺序可能会不一样，取决于方法名对应的Symbol对象的地址的先后顺序</p>

<h3>JVM为什么要对方法排序</h3>

<p>其实这个问题很简单，就是为了快速找到方法呢，当我们要找某个名字的方法的时候，根据对应的Symbol对象，能根据对象的地址使用二分排序的算法快速定位到具体的方法。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之Metaspace解密]]></title>
    <link href="http://nijiaben.github.io/blog/2016/10/29/metaspace/"/>
    <updated>2016-10-29T15:38:00+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/10/29/metaspace</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>metaspace，顾名思义，元数据空间，专门用来存元数据的，它是jdk8里特有的数据结构用来替代perm，这块空间很有自己的特点，前段时间公司这块的问题太多了，主要是因为升级了中间件所致，看到大家讨论来讨论去，看得出很多人对metaspace还是模棱两可，不是很了解它，因此我觉得有必要写篇文章来介绍一下它，解开它神秘的面纱，当我们再次碰到它的相关问题的时候不会再感到束手无策。</p>

<p>通过这篇文章，你将可以了解到</p>

<ul>
<li>为什么会有metaspace</li>
<li>metaspace的组成</li>
<li>metaspace的VM参数</li>
<li>jstat里我们应该关注metaspace的哪些值</li>
</ul>


<!--more-->


<h2>为什么会有metaspace</h2>

<p>metaspace的由来民间已有很多传说，不过我这里只谈我自己的理解，因为我不是oracle参与这块的开发者，所以对其真正的由来不怎么了解。</p>

<p>我们都知道jdk8之前有perm这一整块内存来存klass等信息，我们的参数里也必不可少地会配置-XX:PermSize以及-XX:MaxPermSize来控制这块内存的大小，jvm在启动的时候会根据这些配置来分配一块连续的内存块，但是随着动态类加载的情况越来越多，这块内存我们变得不太可控，到底设置多大合适是每个开发者要考虑的问题，如果设置太小了，系统运行过程中就容易出现内存溢出，设置大了又总感觉浪费，尽管不会实质分配这么大的物理内存。基于这么一个可能的原因，于是metaspace出现了，希望内存的管理不再受到限制，也不要怎么关注元数据这块的OOM问题，虽然到目前来看，也并没有完美地解决这个问题。</p>

<p>或许从JVM代码里也能看出一些端倪来，比如<code>MaxMetaspaceSize</code>默认值很大，<code>CompressedClassSpaceSize</code>默认也有1G，从这些参数我们能猜到metaspace的作者不希望出现它相关的OOM问题。</p>

<h2>metaspace的组成</h2>

<p>metaspace其实由两大部分组成</p>

<ul>
<li>Klass Metaspace</li>
<li>NoKlass Metaspace</li>
</ul>


<p>Klass Metaspace就是用来存klass的，klass是我们熟知的class文件在jvm里的运行时数据结构，不过有点要提的是我们看到的类似A.class其实是存在heap里的，是java.lang.Class的一个对象实例。这块内存是紧接着Heap的，和我们之前的perm一样，这块内存大小可通过<code>-XX:CompressedClassSpaceSize</code>参数来控制，这个参数前面提到了默认是1G，但是这块内存也可以没有，假如没有开启压缩指针就不会有这块内存，这种情况下klass都会存在NoKlass Metaspace里，另外如果我们把-Xmx设置大于32G的话，其实也是没有这块内存的，因为会这么大内存会关闭压缩指针开关。还有就是这块内存最多只会存在一块。</p>

<p>NoKlass Metaspace专门来存klass相关的其他的内容，比如method，constantPool等，这块内存是由多块内存组合起来的，所以可以认为是不连续的内存块组成的。这块内存是必须的，虽然叫做NoKlass Metaspace，但是也其实可以存klass的内容，上面已经提到了对应场景。</p>

<p>Klass Metaspace和NoKlass Mestaspace都是所有classloader共享的，所以类加载器们要分配内存，但是每个类加载器都有一个SpaceManager，来管理属于这个类加载的内存小块。如果Klass Metaspace用完了，那就会OOM了，不过一般情况下不会，NoKlass Mestaspace是由一块块内存慢慢组合起来的，在没有达到限制条件的情况下，会不断加长这条链，让它可以持续工作。</p>

<h2>metaspace的几个参数</h2>

<p>如果我们要改变metaspace的一些行为，我们一般会对其相关的一些参数做调整，因为metaspace的参数本身不是很多，所以我这里将涉及到的所有参数都做一个介绍，也许好些参数大家都是有误解的</p>

<ul>
<li>UseLargePagesInMetaspace</li>
<li>InitialBootClassLoaderMetaspaceSize</li>
<li>MetaspaceSize</li>
<li>MaxMetaspaceSize</li>
<li>CompressedClassSpaceSize</li>
<li>MinMetaspaceExpansion</li>
<li>MaxMetaspaceExpansion</li>
<li>MinMetaspaceFreeRatio</li>
<li>MaxMetaspaceFreeRatio</li>
</ul>


<h3>UseLargePagesInMetaspace</h3>

<p>默认false，这个参数是说是否在metaspace里使用LargePage，一般情况下我们使用4KB的page size，这个参数依赖于UseLargePages这个参数开启，不过这个参数我们一般不开。</p>

<h3>InitialBootClassLoaderMetaspaceSize</h3>

<p>64位下默认4M，32位下默认2200K，metasapce前面已经提到主要分了两大块，Klass Metaspace以及NoKlass Metaspace，而NoKlass Metaspace是由一块块内存组合起来的，这个参数决定了NoKlass Metaspace的第一个内存Block的大小，即2*InitialBootClassLoaderMetaspaceSize，同时为bootstrapClassLoader的第一块内存chunk分配了InitialBootClassLoaderMetaspaceSize的大小</p>

<h3>MetaspaceSize</h3>

<p>默认20.8M左右(x86下开启c2模式)，主要是控制metaspaceGC发生的初始阈值，也是最小阈值，但是触发metaspaceGC的阈值是不断变化的，与之对比的主要是指Klass Metaspace与NoKlass Metaspace两块committed的内存和。</p>

<h3>MaxMetaspaceSize</h3>

<p>默认基本是无穷大，但是我还是建议大家设置这个参数，因为很可能会因为没有限制而导致metaspace被无止境使用(一般是内存泄漏)而被OS Kill。这个参数会限制metaspace(包括了Klass Metaspace以及NoKlass Metaspace)被committed的内存大小，会保证committed的内存不会超过这个值，一旦超过就会触发GC，这里要注意和MaxPermSize的区别，MaxMetaspaceSize并不会在jvm启动的时候分配一块这么大的内存出来，而MaxPermSize是会分配一块这么大的内存的。</p>

<h3>CompressedClassSpaceSize</h3>

<p>默认1G，这个参数主要是设置Klass Metaspace的大小，不过这个参数设置了也不一定起作用，前提是能开启压缩指针，假如-Xmx超过了32G，压缩指针是开启不来的。如果有Klass Metaspace，那这块内存是和Heap连着的。</p>

<h3>MinMetaspaceExpansion</h3>

<p>MinMetaspaceExpansion和MaxMetaspaceExpansion这两个参数或许和大家认识的并不一样，也许很多人会认为这两个参数不就是内存不够的时候，然后扩容的最小大小吗？其实不然</p>

<p>这两个参数和扩容其实并没有直接的关系，也就是并不是为了增大committed的内存，而是为了增大触发metaspace GC的阈值</p>

<p>这两个参数主要是在比较特殊的场景下救急使用，比如gcLocker或者<code>should_concurrent_collect</code>的一些场景，因为这些场景下接下来会做一次GC，相信在接下来的GC中可能会释放一些metaspace的内存，于是先临时扩大下metaspace触发GC的阈值，而有些内存分配失败其实正好是因为这个阈值触顶导致的，于是可以通过增大阈值暂时绕过去</p>

<p>默认332.8K，增大触发metaspace GC阈值的最小要求。假如我们要救急分配的内存很小，没有达到MinMetaspaceExpansion，但是我们会将这次触发metaspace GC的阈值提升MinMetaspaceExpansion，之所以要大于这次要分配的内存大小主要是为了防止别的线程也有类似的请求而频繁触发相关的操作，不过如果要分配的内存超过了MaxMetaspaceExpansion，那MinMetaspaceExpansion将会是要分配的内存大小基础上的一个增量</p>

<h3>MaxMetaspaceExpansion</h3>

<p>默认5.2M，增大触发metaspace GC阈值的最大要求。假如说我们要分配的内存超过了MinMetaspaceExpansion但是低于MaxMetaspaceExpansion，那增量是MaxMetaspaceExpansion，如果超过了MaxMetaspaceExpansion，那增量是MinMetaspaceExpansion加上要分配的内存大小</p>

<p>注：每次分配只会给对应的线程一次扩展触发metaspace GC阈值的机会，如果扩展了，但是还不能分配，那就只能等着做GC了</p>

<h3>MinMetaspaceFreeRatio</h3>

<p>MinMetaspaceFreeRatio和下面的MaxMetaspaceFreeRatio，主要是影响触发metaspaceGC的阈值</p>

<p>默认40，表示每次GC完之后，假设我们允许接下来metaspace可以继续被commit的内存占到了被commit之后总共committed的内存量的MinMetaspaceFreeRatio%，如果这个总共被committed的量比当前触发metaspaceGC的阈值要大，那么将尝试做扩容，也就是增大触发metaspaceGC的阈值，不过这个增量至少是MinMetaspaceExpansion才会做，不然不会增加这个阈值</p>

<p>这个参数主要是为了避免触发metaspaceGC的阈值和gc之后committed的内存的量比较接近，于是将这个阈值进行扩大</p>

<p>一般情况下在gc完之后，如果被committed的量还是比较大的时候，换个说法就是离触发metaspaceGC的阈值比较接近的时候，这个调整会比较明显</p>

<p>注：这里不用gc之后used的量来算，主要是担心可能出现committed的量超过了触发metaspaceGC的阈值，这种情况一旦发生会很危险，会不断做gc，这应该是jdk8在某个版本之后才修复的bug</p>

<h3>MaxMetaspaceFreeRatio</h3>

<p>默认70，这个参数和上面的参数基本是相反的，是为了避免触发metaspaceGC的阈值过大，而想对这个值进行缩小。这个参数在gc之后committed的内存比较小的时候并且离触发metaspaceGC的阈值比较远的时候，调整会比较明显</p>

<h2>jstat里的metaspace字段</h2>

<p>我们看GC是否异常，除了通过GC日志来做分析之外，我们还可以通过jstat这样的工具展示的数据来分析，前面我公众号里有篇文章介绍了jstat这块的实现，有兴趣的可以到我的公众号<code>你假笨</code>里去翻阅下jstat的这篇文章。</p>

<p>我们通过jstat可以看到metaspace相关的这么一些指标，分别是<code>M</code>，<code>CCS</code>，<code>MC</code>，<code>MU</code>，<code>CCSC</code>，<code>CCSU</code>，<code>MCMN</code>，<code>MCMX</code>，<code>CCSMN</code>，<code>CCSMX</code></p>

<p>它们的定义如下：</p>

<pre><code class="java">  column {
    header "^M^"    /* Metaspace - Percent Used */
    data (1-((sun.gc.metaspace.capacity - sun.gc.metaspace.used)/sun.gc.metaspace.capacity)) * 100
    align right
    width 6
    scale raw
    format "0.00"
  }
  column {
    header "^CCS^"  /* Compressed Class Space - Percent Used */
    data (1-((sun.gc.compressedclassspace.capacity - sun.gc.compressedclassspace.used)/sun.gc.compressedclassspace.capacity)) * 100
    align right
    width 6
    scale raw
    format "0.00"
  }

  column {
    header "^MC^"   /* Metaspace Capacity - Current */
    data sun.gc.metaspace.capacity
    align center
    width 6
    scale K
    format "0.0"
  }
  column {
    header "^MU^"   /* Metaspae Used */
    data sun.gc.metaspace.used
    align center
    width 6
    scale K
    format "0.0"
  }
   column {
    header "^CCSC^" /* Compressed Class Space Capacity - Current */
    data sun.gc.compressedclassspace.capacity
    width 8
    align right
    scale K
    format "0.0"
  }
  column {
    header "^CCSU^" /* Compressed Class Space Used */
    data sun.gc.compressedclassspace.used
    width 8
    align right
    scale K
    format "0.0"
  }
  column {
    header "^MCMN^" /* Metaspace Capacity - Minimum */
    data sun.gc.metaspace.minCapacity
    scale K
    align right
    width 8
    format "0.0"
  }
  column {
    header "^MCMX^" /* Metaspace Capacity - Maximum */
    data sun.gc.metaspace.maxCapacity
    scale K
    align right
    width 8
    format "0.0"
  }
  column {
    header "^CCSMN^"    /* Compressed Class Space Capacity - Minimum */
    data sun.gc.compressedclassspace.minCapacity
    scale K
    align right
    width 8
    format "0.0"
  }
  column {
    header "^CCSMX^"    /* Compressed Class Space Capacity - Maximum */
    data sun.gc.compressedclassspace.maxCapacity
    scale K
    align right
    width 8
    format "0.0"
  }
</code></pre>

<p>我这里对这些字段分类介绍下</p>

<h3>MC &amp; MU &amp; CCSC &amp; CCSU</h3>

<ul>
<li><p>MC表示Klass Metaspace以及NoKlass Metaspace两者总共committed的内存大小，单位是KB，虽然从上面的定义里我们看到了是capacity，但是实质上计算的时候并不是capacity，而是committed，这个是要注意的</p></li>
<li><p>MU这个无可厚非，说的就是Klass Metaspace以及NoKlass Metaspace两者已经使用了的内存大小</p></li>
<li><p>CCSC表示的是Klass Metaspace的已经被commit的内存大小，单位也是KB</p></li>
<li><p>CCSU表示Klass Metaspace的已经被使用的内存大小</p></li>
</ul>


<h3>M &amp; CCS</h3>

<ul>
<li><p>M表示的是Klass Metaspace以及NoKlass Metaspace两者总共的使用率，其实可以根据上面的四个指标算出来，即(CCSU+MU)/(CCSC+MC)</p></li>
<li><p>CCS表示的是NoKlass Metaspace的使用率，也就是CCSU/CCSC算出来的</p></li>
</ul>


<p>PS：所以我们有时候看到M的值达到了90%以上，其实这个并不一定说明metaspace用了很多了，因为内存是慢慢commit的，所以我们的分母是慢慢变大的，不过当我们committed到一定量的时候就不会再增长了</p>

<h3>MCMN &amp; MCMX &amp; CCSMN &amp; CCSMX</h3>

<ul>
<li><p>MCMN和CCSMN这两个值大家可以忽略，一直都是0</p></li>
<li><p>MCMX表示Klass Metaspace以及NoKlass Metaspace两者总共的reserved的内存大小，比如默认情况下Klass Metaspace是通过CompressedClassSpaceSize这个参数来reserved 1G的内存，NoKlass Metaspace默认reserved的内存大小是2* InitialBootClassLoaderMetaspaceSize</p></li>
<li><p>CCSMX表示Klass Metaspace reserved的内存大小</p></li>
</ul>


<p>综上所述，其实看metaspace最主要的还是看<code>MC</code>，<code>MU</code>，<code>CCSC</code>，<code>CCSU</code>这几个具体的大小来判断metaspace到底用了多少更靠谱</p>

<p>本来还想写metaspace内存分配和GC的内容，不过那块说起来又是一个比较大的话题，因为那块大家看起来可能会比较枯燥，有机会再写</p>

<p>PS:本文最先发布在听云博客</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之临门一脚的OutOfMemoryError完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2016/08/29/oom/"/>
    <updated>2016-08-29T15:35:09+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/08/29/oom</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>OutOfMemoryError，说的是java.lang.OutOfMemoryError，是JDK里自带的异常，顾名思义，说的就是内存溢出，当我们的系统内存严重不足的时候就会抛出这个异常(PS:注意这是一个Error，不是一个Exception，所以当我们要catch异常的时候要注意哦)，这个异常说常见也常见，说不常见其实也见得不多，不过作为Java程序员至少应该都听过吧，如果你对jvm不是很熟，或者对OutOfMemoryError这个异常了解不是很深的话，这篇文章肯定还是可以给你带来一些惊喜的，通过这篇文章你至少可以了解到如下几点：</p>

<ul>
<li>OutOfMemoryError一定会被加载吗</li>
<li>什么时候抛出OutOfMemoryError</li>
<li>会创建无数OutOfMemoryError实例吗</li>
<li>为什么大部分OutOfMemoryError异常是无堆栈的</li>
<li>我们如何去分析这样的异常</li>
</ul>


<!--more-->


<h2>OutOfMemoryError类加载</h2>

<p>既然要说OutOfMemoryError，那就得从这个类的加载说起来，那这个类什么时候被加载呢？你或许会不假思索地说，根据java类的延迟加载机制，这个类一般情况下不会被加载，除非当我们抛出OutOfMemoryError这个异常的时候才会第一次被加载，如果我们的系统一直不抛出这个异常，那这个类将一直不会被加载。说起来好像挺对，不过我这里首先要纠正这个说法，要明确的告诉你这个类在jvm启动的时候就已经被加载了，不信你就执行<code>java -verbose:class -version</code>打印JDK版本看看，看是否有OutOfMemoryError这个类被加载，再输出里你将能找到下面的内容：</p>

<pre><code class="java">[Loaded java.lang.OutOfMemoryError from /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/rt.jar]
</code></pre>

<p>这意味着这个类其实在vm启动的时候就已经被加载了，那JVM里到底在哪里进行加载的呢，且看下面的方法:</p>

<pre><code>bool universe_post_init() {

    ...


    // Setup preallocated OutOfMemoryError errors
    k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_OutOfMemoryError(), true, CHECK_false);
    k_h = instanceKlassHandle(THREAD, k);
    Universe::_out_of_memory_error_java_heap = k_h-&gt;allocate_instance(CHECK_false);
    Universe::_out_of_memory_error_metaspace = k_h-&gt;allocate_instance(CHECK_false);
    Universe::_out_of_memory_error_class_metaspace = k_h-&gt;allocate_instance(CHECK_false);
    Universe::_out_of_memory_error_array_size = k_h-&gt;allocate_instance(CHECK_false);
    Universe::_out_of_memory_error_gc_overhead_limit =
      k_h-&gt;allocate_instance(CHECK_false);
    Universe::_out_of_memory_error_realloc_objects = k_h-&gt;allocate_instance(CHECK_false);


    ...


    if (!DumpSharedSpaces) {
    // These are the only Java fields that are currently set during shared space dumping.
    // We prefer to not handle this generally, so we always reinitialize these detail messages.
    Handle msg = java_lang_String::create_from_str("Java heap space", CHECK_false);
    java_lang_Throwable::set_message(Universe::_out_of_memory_error_java_heap, msg());

    msg = java_lang_String::create_from_str("Metaspace", CHECK_false);
    java_lang_Throwable::set_message(Universe::_out_of_memory_error_metaspace, msg());
    msg = java_lang_String::create_from_str("Compressed class space", CHECK_false);
    java_lang_Throwable::set_message(Universe::_out_of_memory_error_class_metaspace, msg());

    msg = java_lang_String::create_from_str("Requested array size exceeds VM limit", CHECK_false);
    java_lang_Throwable::set_message(Universe::_out_of_memory_error_array_size, msg());

    msg = java_lang_String::create_from_str("GC overhead limit exceeded", CHECK_false);
    java_lang_Throwable::set_message(Universe::_out_of_memory_error_gc_overhead_limit, msg());

    msg = java_lang_String::create_from_str("Java heap space: failed reallocation of scalar replaced objects", CHECK_false);
    java_lang_Throwable::set_message(Universe::_out_of_memory_error_realloc_objects, msg());

    msg = java_lang_String::create_from_str("/ by zero", CHECK_false);
    java_lang_Throwable::set_message(Universe::_arithmetic_exception_instance, msg());

    // Setup the array of errors that have preallocated backtrace
    k = Universe::_out_of_memory_error_java_heap-&gt;klass();
    assert(k-&gt;name() == vmSymbols::java_lang_OutOfMemoryError(), "should be out of memory error");
    k_h = instanceKlassHandle(THREAD, k);

    int len = (StackTraceInThrowable) ? (int)PreallocatedOutOfMemoryErrorCount : 0;
    Universe::_preallocated_out_of_memory_error_array = oopFactory::new_objArray(k_h(), len, CHECK_false);
    for (int i=0; i&lt;len; i++) {
      oop err = k_h-&gt;allocate_instance(CHECK_false);
      Handle err_h = Handle(THREAD, err);
      java_lang_Throwable::allocate_backtrace(err_h, CHECK_false);
      Universe::preallocated_out_of_memory_errors()-&gt;obj_at_put(i, err_h());
    }
    Universe::_preallocated_out_of_memory_error_avail_count = (jint)len;
  }

}
</code></pre>

<p>上面的代码其实就是在vm启动过程中加载了OutOfMemoryError这个类，并且创建了好几个OutOfMemoryError对象，每个OutOfMemoryError对象代表了一种内存溢出的场景，比如说<code>Java heap space</code>不足导致的OutOfMemoryError，抑或<code>Metaspace</code>不足导致的OutOfMemoryError，上面的代码来源于JDK8，所以能看到metaspace的内容，如果是JDK8之前，你将看到Perm的OutOfMemoryError，不过本文metaspace不是重点，所以不展开讨论，如果大家有兴趣，可以专门写一篇文章来介绍metsapce来龙去脉，说来这个坑填起来还挺大的。</p>

<h3>能通过agent拦截到这个类加载吗</h3>

<p>熟悉字节码增强的人，可能会条件反射地想到是否可以拦截到这个类的加载呢，这样我们就可以做一些譬如内存溢出的监控啥的，哈哈，我要告诉你的是<code>NO WAY</code>，因为通过agent的方式来监听类加载过程是在vm初始化完成之后才开始的，而这个类的加载是在vm初始化过程中，因此不可能拦截到这个类的加载，于此类似的还有<code>java.lang.Object</code>,<code>java.lang.Class</code>等。</p>

<h3>为什么要在vm启动过程中加载这个类</h3>

<p>这个问题或许看了后面的内容你会有所体会，先卖个关子。包括为什么要预先创建这几个实例对象后面也会解释。</p>

<h2>何时抛出OutOfMemoryError</h2>

<p>要抛出OutOfMemoryError，那肯定是有地方需要进行内存分配，可能是heap里，也可能是metsapce里（如果是在JDK8之前的会是Perm里），不同地方的分配，其策略也不一样，简单来说就是尝试分配，实在没办法就gc，gc还是不能分配就抛出异常。</p>

<p>不过还是以Heap里的分配为例说一下具体的过程：</p>

<p>正确情况下对象创建需要分配的内存是来自于Heap的Eden区域里，当Eden内存不够用的时候，某些情况下会尝试到Old里进行分配(比如说要分配的内存很大)，如果还是没有分配成功，于是会触发一次ygc的动作，而ygc完成之后我们会再次尝试分配，如果仍不足以分配此时的内存，那会接着做一次full gc(不过此时的soft reference不会被强制回收)，将老生代也回收一下，接着再做一次分配，仍然不够分配那会做一次强制将soft reference也回收的full gc，如果还是不能分配，那这个时候就不得不抛出OutOfMemoryError了。这就是Heap里分配内存抛出OutOfMemoryError的具体过程了。</p>

<h2>OutOfMemoryError对象可能会很多吗</h2>

<p>想象有这么一种场景，我们的代码写得足够烂，并且存在内存泄漏，这意味着系统跑到一定程度之后，只要我们创建对象要分配内存的时候就会进行gc，但是gc没啥效果，进而抛出OutOfMemoryError的异常，那意味着每发生此类情况就应该创建一个OutOfMemoryError对象，并且抛出来，也就是说我们会看到一个带有堆栈的OutOfMemoryError异常被抛出，那事实是如此吗？如果真是如此，那为什么在VM启动的时候会创建那几个OutOfMemoryError对象呢？</p>

<h3>抛出异常的java代码位置需要我们关心吗</h3>

<p>这个问题或许你仔细想想就清楚了，如果没想清楚，请在这里停留一分钟仔细想想再往后面看。</p>

<p>抛出OutOfMemoryError异常的java方法其实只是临门一脚而已，导致内存泄漏的不一定就是这个方法，当然也不排除可能是这个方法，不过这种情况的可能性真的非常小。所以你大可不必去关心抛出这个异常的堆栈。</p>

<p>既然可以不关心其异常堆栈，那意味着这个异常其实没必要每次都创建一个不一样的了，因为不需要堆栈的话，其他的东西都可以完全相同，这样一来回到我们前面提到的那个问题，<code>为什么要在vm启动过程中加载这个类</code>，或许你已经有答案了，在vm启动过程中我们把类加载起来，并创建几个没有堆栈的对象缓存起来，只需要设置下不同的提示信息即可，当需要抛出特定类型的OutOfMemoryError异常的时候，就直接拿出缓存里的这几个对象就可以了。</p>

<p>所以OutOfMemoryError的对象其实并不会太多，哪怕你代码写得再烂，当然，如果你代码里要不断<code>new OutOfMemoryError()</code>，那我就无话可说啦。</p>

<h2>为什么我们有时候还是可以看到有堆栈的OutOfMemoryError</h2>

<p>如果都是用jvm启动的时候创建的那几个OutOfMemoryError对象，那不应该再出现有堆栈的OutOfMemoryError异常，但是实际上我们偶尔还是能看到有堆栈的异常，如果你细心点的话，可能会总结出一个规律，发现最多出现4次有堆栈的OutOfMemoryError异常，当4次过后，你都将看到无堆栈的OutOfMemoryError异常。</p>

<p>这个其实在我们上面贴的代码里也有体现，最后有一个for循环，这个循环里会创建几个OutOfMemoryError对象，如果我们将<code>StackTraceInThrowable</code>设置为true的话(默认就是true的)，意味着我们抛出来的异常正确情况下都将是有堆栈的，那根据<code>PreallocatedOutOfMemoryErrorCount</code>这个参数来决定预先创建几个OutOfMemoryError异常对象，但是这个参数除非在debug版本下可以被设置之外，正常release出来的版本其实是无法设置这个参数的，它会是一个常量，值为4，因此在jvm启动的时候会预先创建4个OutOfMemoryError异常对象，但是这几个异常对象的堆栈，是可以动态设置的，比如说某个地方要抛出OutOfMemoryError异常了，于是先从预存的OutOfMemoryError里取出一个（其他是预存的对象还有），将此时的堆栈填上，然后抛出来，并且这个对象的使用是一次性的，也就是这个对象被抛出之后将不会再次被利用，直到预设的这几个OutOfMemoryError对象被用完了，那接下来抛出的异常都将是一开始缓存的那几个无栈的OutOfMemoryError对象。</p>

<p>这就是我们看到的最多出现4次有堆栈的OutOfMemoryError异常及大部分情况下都将看到没有堆栈的OutOfMemoryError对象的原因。</p>

<h2>如何分析OutOfMemoryError异常</h2>

<p>既然看堆栈也没什么意义，那只能从提示上入手了，我们看到这类异常，首先要确定的到底是哪块内存何种情况导致的内存溢出，比如说是Perm导致的，那抛出来的异常信息里会带有<code>Perm</code>的关键信息，那我们应该重点看Perm的大小，以及Perm里的内容；如果是Heap的，那我们就必须做内存Dump，然后分析为什么会发生这样的情况，内存里到底存了什么对象，至于内存分析的最佳的分析工具自然是MAT啦，不了解的请google之。</p>

<p>PS:本文最先发布在听云博客</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM源码分析之Jstat工具原理完全解读]]></title>
    <link href="http://nijiaben.github.io/blog/2016/07/20/jstat/"/>
    <updated>2016-07-20T15:32:00+08:00</updated>
    <id>http://nijiaben.github.io/blog/2016/07/20/jstat</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>jstat是hotspot自带的工具，和java一样也位于<code>JAVA_HOME/bin</code>下面，我们通过该工具可以实时了解当前进程的gc，compiler，class，memory等相关的情况，具体我们可以通过jstat -options来看我们到底支持哪些类型的数据，譬如JDK8下的结果是：</p>

<pre><code class="java">-class
-compiler
-gc
-gccapacity
-gccause
-gcmetacapacity
-gcnew
-gcnewcapacity
-gcold
-gcoldcapacity
-gcutil
-printcompilation
</code></pre>

<!--more-->


<h2>jstat的输出</h2>

<p>jstat大家用得其实挺多的，最常见的用法是jstat -gcutil，输出如下：</p>

<pre><code>
~ ᐅ jstat -gcutil 692 1000
  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT
  0.00  41.49  59.79  83.66  89.92  78.74    295    5.436    10    3.855    9.291
  0.00  41.49  59.80  83.66  89.92  78.74    295    5.436    10    3.855    9.291
  0.00  41.49  59.80  83.66  89.92  78.74    295    5.436    10    3.855    9.291
  0.00  41.49  59.80  83.66  89.92  78.74    295    5.436    10    3.855    9.291
  0.00  41.49  59.80  83.66  89.92  78.74    295    5.436    10    3.855    9.291
</code></pre>

<p>那每一列是怎么定义，怎么计算的呢，其实在tools.jar里存在一个文件叫做jstat_options，这个文件里定义了上面的每种类型的输出结果，比如说gcutil</p>

<pre><code>option gcutil {
  column {
    header "^S0^"   /* Survivor 0 Space - Percent Used */
    data (1-((sun.gc.generation.0.space.1.capacity - sun.gc.generation.0.space.1.used)/sun.gc.generation.0.space.1.capacity)) * 100
    scale raw
    align right
    width 6
    format "0.00"
  }

  column {
    header "^S1^"   /* Survivor 1 Space - Percent Used */
    data (1-((sun.gc.generation.0.space.2.capacity - sun.gc.generation.0.space.2.used)/sun.gc.generation.0.space.2.capacity)) * 100
    scale raw
    align right
    width 6
    format "0.00"
  }

  column {
    header "^E^"    /* Eden Space - Percent Used */
    data (1-((sun.gc.generation.0.space.0.capacity - sun.gc.generation.0.space.0.used)/sun.gc.generation.0.space.0.capacity)) * 100
    align right
    scale raw
    width 6
    format "0.00"
  }

  column {
    header "^O^"    /* Old Space - Percent Used */
    data (1-((sun.gc.generation.1.space.0.capacity - sun.gc.generation.1.space.0.used)/sun.gc.generation.1.space.0.capacity)) * 100
    align right
    scale raw
    width 6
    format "0.00"
  }

  column {
    header "^M^"    /* Metaspace Space - Percent Used */
    data (1-((sun.gc.metaspace.capacity - sun.gc.metaspace.used)/sun.gc.metaspace.capacity)) * 100
    align right
    width 6
    scale raw
    format "0.00"
  }

  column {
    header "^CCS^"  /* Compressed Class Space Space - Percent Used */
    data (1-((sun.gc.compressedclassspace.capacity - sun.gc.compressedclassspace.used)/sun.gc.compressedclassspace.capacity)) * 100
    align right
    width 6
    scale raw
    format "0.00"
  }

  column {
    header "^YGC^"  /* Young Generation Collections */
    data sun.gc.collector.0.invocations
    align right
    width 6
    format "0"
  }

  column {
    header "^YGCT^" /* Young Generation Collection Time */
    data sun.gc.collector.0.time/sun.os.hrt.frequency
    align right
    scale sec
    width 8
    format "0.000"
  }

  column {
    header "^FGC^"  /* Full Collections */
    data sun.gc.collector.1.invocations
    align right
    width 5
    scale raw
    format "0"
  }

  column {
    header "^FGCT^" /* Full Collection Time */
    data sun.gc.collector.1.time/sun.os.hrt.frequency
    align right
    scale sec
    width 8
    format "0.000"
  }

  column {
    header "^GCT^"  /* Total Garbage Collection Time */
    data (sun.gc.collector.0.time + sun.gc.collector.1.time)/sun.os.hrt.frequency
    align right
    width 8
    scale sec
    format "0.000"
  }
}
</code></pre>

<p>从上面的定义我们知道gcutil的每一列是什么意思，怎么计算出来的，其中类似<code>sun.gc.generation.0.space.0.capacity</code>这样的一些变量是jvm里创建并实时更新的值</p>

<h2>jstat如何获取到这些变量的值</h2>

<p>变量值显然是从目标进程里获取来的，但是是怎样来的？local socket还是memory share？其实是从一个共享文件里来的，这个文件叫PerfData，主要指的是/tmp/hsperfdata_\<user>/\<pid>这个文件</p>

<h3>PerfData文件</h3>

<h4>文件创建</h4>

<p>这个文件是否存在取决于两个参数，一个UsePerfData，另一个是PerfDisableSharedMem，如果设置了-XX:+PerfDisableSharedMem或者-XX:-UsePerfData，那这个文件是不会存在的，默认情况下PerfDisableSharedMem是关闭的，UsePerfData是打开的，所以默认情况下PerfData文件是存在的。对于UsePerfData和PerfDisableSharedMem这两个参数，这里着重讲一下：</p>

<ul>
<li>UsePerfData：如果关闭了UsePerfData这个参数，那么jvm启动过程中perf memory都不会被创建，默认情况是是打开的</li>
<li>PerfDisableSharedMem：该参数决定了存储PerfData的内存是不是可以被共享，也就是说不管这个参数设置没设置，jvm在启动的时候都会分配一块内存来存PerfData，只是说这个PerfData是不是其他进程可见的问题，如果设置了这个参数，说明不能被共享，此时其他进程将访问不了该内存，这样一来，譬如我们jps，jstat等都无法工作。默认这个参数是关闭的，也就是默认支持共享的方式</li>
</ul>


<p>具体代码在PerfMemory::create_memory_region里</p>

<pre><code>  if (PerfDisableSharedMem) {
    // do not share the memory for the performance data.
    _start = create_standard_memory(size);
  } else {
    _start = create_shared_memory(size);
    if (_start == NULL) {
      // creation of the shared memory region failed, attempt
      // to create a contiguous, non-shared memory region instead.
      //
      if (PrintMiscellaneous &amp;&amp; Verbose) {
        warning("Reverting to non-shared PerfMemory region.\n");
      }
      PerfDisableSharedMem = true;
      _start = create_standard_memory(size);
    }
  }
</code></pre>

<h4>文件删除</h4>

<p>那这个文件什么时候删除？正常情况下当进程退出的时候会自动删除，但是某些极端情况下，比如kill -9，这种信号jvm是不能捕获的，所以导致进程直接退出了，而没有做一些收尾性的工作，这个时候你会发现进程虽然没了，但是这个文件其实还是存在的，那这个文件是不是就一直留着，只能等待人为的删除呢，jvm里考虑到了这种情况，会在当前用户接下来的任何一个java进程(比如说我们执行jps)起来的时候会去做一个判断，看/tmp/hsperfdata_\<user>下的进程是不是还存在，如果不存在了就直接删除该文件，判断是否存在的具体操作其实就是发一个kill -0的信号看是否有异常。</p>

<h4>文件更新</h4>

<p>由于这个文件是通过mmap的方式映射到了内存里，而jstat是直接通过DirectByteBuffer的方式从PerfData里读取的，所以只要内存里的值变了，那我们从jstat看到的值就会发生变化，内存里的值什么时候变，取决于-XX:PerfDataSamplingInterval这个参数，默认是50ms，也就是说50ms更新一次值，基本上可以认为是实时的了。</p>

<h4>PerfData其他相关VM参数</h4>

<ul>
<li>-XX:PerfDataMemorySize：指定/tmp/hsperfdata_\<user>下perfData文件的大小，默认是32KB，如果用户设置了该值，jvm里会自动和os的page size对齐，比如linux下pagesize默认是4KB，那如果你设置了31KB，那自动会分配32KB</li>
<li>-XX:+PerfDataSaveToFile：是否在进程退出的时候讲PerfData里的数据保存到一个特定的文件里，文件路径由下面的参数指定，否则就在当前目录下</li>
<li>-XX:PerfDataSaveFile：指定保存PerfData文件的路径</li>
<li>-XX:PerfDataSamplingInterval：指定perfData的采样间隔，默认是50ms，基本算实时采样了</li>
</ul>


<h2>jstat里的坑</h2>

<p>本人暂时想到的两大坑：</p>

<ul>
<li><p>一次正常的Background CMS GC之后，发现FGC的值加了2次，后面发现主要原因是CMS有init mark和remark两个会暂停应用的阶段，同时因为是对old做gc，因此算了两次</p></li>
<li><p>JDK8下metaspace的使用情况不准确，比如说CCSC的值表示的是 Compressed Class Space Capacity，但是发现这个值的计算却不是reserve的值，所以我们可能会发现metaspace其实用了非常少，但是通过jstat看起使用率已经非常大了，因此这种情况最好是通过jmx的方式去取那些值做一个计算</p></li>
</ul>


<pre><code>size_t CompressedClassSpaceCounters::capacity() {
  return MetaspaceAux::committed_bytes(Metaspace::ClassType);
}
</code></pre>
]]></content>
  </entry>
  
</feed>
